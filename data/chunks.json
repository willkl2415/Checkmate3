[
  {
    "id": "ab77445f-59e5-44b8-b3bb-c95e2ccfc663",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Uncategorised",
    "content": "Maritime Acquisition Training Guide (MATG) Part 1: Project Team Guidance Issue Version: 2.0 Dated: 14 Feb 23 © Crown Copyright 2023 Disclaimer This document contains guidance to be used alongside JSP 822. In cases of divergence, JSP 822 is the authoritative document. Intelligent analysis is crucial to acquisition of training, and therefore the application of this guidance may be modified with justification from the Authority. Amendment Record"
  },
  {
    "id": "8fa887a8-73f1-467d-9e6c-91727cf99c2b",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Review Cycle",
    "content": "This document should be reviewed annually or when the key reference documents  or  are updated, whichever is earliest."
  },
  {
    "id": "1584a8e1-0984-4797-ba03-c2635ccd316a",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Point of Contact",
    "content": "For further information on this document or to provide feedback on its contents, please contact"
  },
  {
    "id": "b2920151-ac70-46f7-af0d-52984ce4fafe",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Other Training References",
    "content": "– Accessed through the Defence Gateway Maritime Training Strategy v4 ( and ). – A Generic Process for the Verification and Validation of Modelling and Simulation and Synthetic Environments Systems. – DTEC Modelling and Simulation (M&S) Standards Profile (DMSP). 1 StratCom (through the Defence Simulation Centre) is the Defence Modelling and Simulation Coherence Technical Authority. Contents Annexes: Defence Training Continuum…………………………………………………………………A-1  Indicative Training and Acquisition Phases…..……………………………………………B-1  Initial and Through Life Training Costs………………………………………...................C-1  Cross Defence Lines of Development Dependencies ………...…….……....................D-1  Training Steering Group TORs …........................................……………….……...........E-1"
  },
  {
    "id": "e3bef7e9-a11c-4c8f-98ef-31925e02ef9b",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Context",
    "content": "The full potential of any capability can only be realised with sufficient suitably trained and qualified personnel to operate and sustain it. Therefore, training is a fundamental pillar of the Royal Navy’s Operational Capability. Further, addressing training requirements of new or updated capabilities early with acquisition often results in decreased through-life costs, improved equipment availability, improved safety, and higher morale amongst those with the skills to undertake their role(s). It is the Project Team’s (PT) delegated responsibility to fund, plan, integrate and support the through-life training requirements of any upgraded or new capability as part of the wider support solutions envelope (SSE). Early engagement with the customer through the RN Capability area and Training authorities can help mitigate the risks of unnecessary or significant delay and cost borne from not properly considering the training requirement. The RN provides support, governance and assurance activities to enable the PT to successfully deliver these requirements through the Future Training (FT) and Maritime Acquisition & Training Organisation (MTAO). The MTAO is also able to provide qualified and experienced support for Training Steering Group (TSG) meetings, discussions with Training Needs Analysis (TNA) and Training Solution suppliers, and the QA of deliverables. Defence doctrine defines the PLOD as the provision of sufficient, capable personnel (‘capable’ requires Individual Training (IT) solutions). The Training Line of Development (TLOD) is the rehearsal of military capability and therefore the need for a Team and Collective Training (CT) capability. Within the RN, the PLOD and therefore IT is owned by Director Personnel and Training (Dir P&T) and the TLOD and therefore CT is owned by Director Force Generation (Dir FGEN) as the Training Requirements Authority (TRA) and Commander Fleet Operational Standards and Training (COMFOST) as Training Delivery Authority (TDA), different parts of the organisation with separate management plans and funding lines. The MTAO works for Dir P&T and is charged with assuring the IT aspects of the PLOD, but can signpost PTs to suitable points of contact (PoC) within Dir FGEN and COMFOST’s organisation for TLOD aspects. Although Individual, Team and Collective training are closely linked, and some team elements of training can be covered within IT analysis, design or delivery processes, the delivery structures and governance of Team and CT (the TLOD) differs to those for IT (PLOD). For simplicity, and since a PT is responsible for delivering both IT and CT requirements, both will be referred to as training for the remainder of the document. 2 Project Team refers to the Delivery Agency team (e.g. DE&S, SDA, or DD) responsible for delivering any new or upgraded capability. They are also known as Delivery Teams (DTs) or Design Authorities (DAs)."
  },
  {
    "id": "a15b1de2-d794-435b-8c6f-705b524f2842",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "3",
    "content": "4   Older projects may still be using the legacy SSE which uses Key Support Areas and subordinate Governing Policies. These projects should refer to  It is expected that all projects using the legacy SSE will be complete by May 23, and from then it will be retired. 5 For definitions for the PLOD and TLOD see  For definitions of IT and CT see Personnel Line of Development Trains the people in the workforce Also manages other HR functions Mainly training for individuals and small teams Dir P&T's output is 'Sufficient, capable, motivated people' PLOD TLOD Training Line of Development Receives personnel from the PLOD Trains operational units Mainly collective training for teams COMFOST's output is \"trained and assured formed units\" Fully trained workforce Ready to 'fight and win' as part of a team Delivering Defence Effect in all operational environments Deployed workforce Figure 1: NC PLOD and TLOD Information Failure to adequately address the Training requirements significantly increases the risk that the provision of any individual, team and or collective training will not be fully considered, particularly during the early stages of capability design. There is plenty of evidence that this failure results in: Unnecessary and significant delays in bringing the capability into service, particularly if Approval to Develop or Approval to Embody is delayed until the Training requirements are satisfied by the PT. Delays and increased costs of retrospectively analysing training requirements and supplying an adequate training solution (and/or changing existing training solutions); increased through-life costs (due to the need to supply and support of interim training arrangements until a steady state training solution is ready, and the reduced availability and reliability of platform equipment); and/or an inability of Defence to fully (or, in some cases, even partially) realise the capability once in-service. Lessons learned from DE&S, Defence Digital and SDA projects emphasise that: Adequate consideration of training requirements early in the project offers benefits to performance, cost, and time. Not just to training, but to the bringing into service and the supportability of the capability required from the new, or changed, equipment. A key factor in the effective and efficient consideration of training needs is the and holding an initial Training Steering Group (TSG) meeting in time to adequately inform the Equipment approvals and procurement. The TSG can provide advice and authoritative endorsement of PT decisions in the intelligent application of the Defence Systems Approach to Training (DSAT) process to training needs analysis; and the supply and support of the training solution (if analysis determines a change to training is needed), and the drumbeat of any further TSG involvement required. Aim and Scope The aim of the Maritime Acquisition Training Guide (MATG) is to provide guidance to PTs for the provision of through-life training requirements for a new or updated capability in the maritime domain. It expands on the direction provided in 6 In JSP 822 this is referred to as the Training Needs Analysis Steering Group (TNASG) but this is misleading as it’s Terms of Reference (ToRs) cover more broader training considerations and so will be referred to as the TSG throughout this document. of the Support Solution Envelope (SSE),  ) and   but is not intended to form the basis of any contractual arrangement. Note that as part of ensuring appropriate supportability arrangements are put in place for the new/changed capability in a timely manner, the PT should inform the shore side enterprise early in the planning for the introduction of new/changed equipment. This broader audience can then consider any changes it may need to make to its organisation’s (e.g. dockside maintainers) training to support the new/changed capability."
  },
  {
    "id": "45e70c6a-4fca-4821-ad82-a5e74b88b084",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 2: Training Points of Contact",
    "content": "The following positions within the RN have the lead for the assurance of Training at various stages of the CADMID cycle."
  },
  {
    "id": "4d79b484-0468-473a-8e9f-b986cdbeb4f9",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Develop Directorate (Pre-Concept - Concept)",
    "content": "and Organisation)"
  },
  {
    "id": "f6795e04-f28e-41a0-a2eb-8240c604a975",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Navy Acquisition Directorate and People & Training Directorate (Concept – Manufacture)",
    "content": "(POCs) (POCs and Links)  (POCs and more detail)"
  },
  {
    "id": "3261586b-a586-4d19-80cf-ba6ff6a4e413",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Training Management Group (In-Service – Disposal)",
    "content": "(inc. Training Capability Managers)  (Document dated May 21)"
  },
  {
    "id": "351920ef-7a17-4357-b87e-fb7d9d3aa960",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Commodore Fleet Operational Standards and Training (TLOD TDA)",
    "content": "(POCs)"
  },
  {
    "id": "0f27e79b-6e25-446e-8d00-5d4297433672",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 3: Defence & Maritime Acquisition Context",
    "content": "Defence Operating Model. The  (DOM) (Fig. 1) shows how capability is about achieving effect in relation to identified requirements and parameters or constraints. The DOM is based on the 5 core functions:     and . The capability model can be applied to all levels of requirement setting, by seeing it as a performance gap model and therefore should be the foundation of all analysis. Unless training can be related to delivering an endorsed capability effect, i.e. closing an identified performance gap, it should not be undertaken. 7 Submarine Individual Training Coherence Organisation (OF5 Area) is due to be established in April 2023 and Future Training/FT/MTAO SM team will form part of this team. Contact details can be obtained via the FPCAP/FT Team as required. 8 In some instances DNO, in it’s role as a Customer and a Delivery Agent, Figure 2: Defence Operating Model Navy Command Operating Model. The Navy delivers its outputs through the six core functions of Direct, Develop, Acquire, Generate, Operate and Enable. Within Enable are a series of cross-cutting functions that map directly to wider the Defence Functions set out in the DOM and their corresponding structures. This shortens decision chains and drives much clearer lines of accountability. Within this framework, the Directorates, which broadly correspond to the core functions, have significant delegated authority – including full budgetary levers and unambiguous ownership of specific intra-TLB outputs Figure 3: Navy Command Operating Model The Navy Acquisition Directorate is responsible for providing professional internal programme management and intelligent customer capability to hold the Royal Navy’s delivery partners to account for the delivery of major programmes. The Force Generation Directorate is responsible for integrating the Defence Lines of Development (DLoDs) for in- service capabilities so that the Royal Navy has the forces required to meet planned Defence outputs. They both work with the Navy People & Training Directorate which attracts, recruits, trains and allocates Royal Navy people across the Whole Force to support the Navy’s priorities and deployable activities sustainably, providing career support for their time in service and beyond."
  },
  {
    "id": "cd45721e-f327-4166-bef6-b4f9faa18d65",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "9",
    "content": "10 5 Directorate HQs: Develop, Acquisition, Force Generation, Operations and People & Training. Finance and Military Capability (FMC) Operating Model. The Financial Operating Model (FOM) is designed to strengthen the link between managing Defence’s finances and delivering military capability. It operates within the restrictions of Defence and follows the direction set out in the DOM. The aim is for military capability to be planned, resourced and delivered across all the DLODs and for balance of investment decisions to be taken which create the best Defence outputs from the resources available. Capability comprises eight DLODs as well as the overarching theme of ‘Interoperability’, any of which may give rise to a new training requirement, as could the operating environment, the nature of the threat it will face, and how it will contribute to any larger coalition. Under the   (TLCM) philosophy, all elements that comprise capability must be adequately planned, delivered and generated through-life. Figure 3: Relationship between Capability and DLODs FINMILCAP and  FINMILCAP and TLCM should ensure that the requirements of Defence policy be translated into an approved programme that delivers the required capabilities, through-life, across all DLODs. It is therefore critical that Training is planned, delivered and generated in a manner that is consistent with all other DLODs to ensure provision of a coherent capability through-life. As Training can prove to be one of the most expensive through-life elements, potentially accounting for more than 30% of the whole life costs (WLC) of a project; the organisation introducing a new capability must have a firm appreciation of all known training factors which could threaten project affordability. The ‘CADMID/T’ is adopted to support the acquisition of maritime capability. Other more agile models are available with appropriate justification. However, the success of these and the CADMID/T cycle depends on the best possible cost and time estimation, both at first and then at important decision/approval points. Acquisition is carried out wherever possible on a modular basis so that equipment can be updated through-life. 11 Finance and Military Capability Operating Model - Version 1 12 Concept, Assessment, Demonstrate, Manufacture, In-Service Disposal/Termination (CADMID/T). E-Learning packages:   and  available on the Defence Learning Environment (DLE) provide further information on CADMID/T. This document refers to CADMID as the most frequently used, however it equally applies to the CADMIT cycle."
  },
  {
    "id": "d727863e-3198-433d-bab2-818a33231ffc",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 4: Training Policy",
    "content": "Support Solution Envelope. The support solution that the PT develops during the acquisition of a capability or equipment solution details how that solution will be supported and maintained through-life up until disposal. The Support Solutions Envelope (SSE) consists of signposts to policy and advice and guidance of how to develop a comprehensive support solution. SSE consists of 19 Core Development Areas (CDAs) and six Cross-Cutting Themes (CCTs). For Training, the relevant CDA is  . Older projects may still be using the legacy SSE which uses Key Support Areas and subordinate Governing Policies. These projects should refer to . It is expected that all projects using the legacy SSE will be complete by May 23, after which it will be retired. Defence Systems Approach to Training (DSAT). Key to success of delivering Training in maritime acquisition is the intelligent application DSAT, explained in detail in Joint Service Publication (JSP) 822. When applied correctly, DSAT should deliver training that is safe, risk-focussed, appropriate, effective, efficient and accountable training to trainees. There are several key roles which are relevant for Training, in particular the TRA and the TDA. The DSAT process comprises four elements, plus management and governance activities that govern all Defence training, both IT and CT, across the Whole Force (Figure 3). Further direction for DSAT in maritime IT, is provided in   but may differ for CT. The training continuum detailing IT and CT can be seen at Annex A. Figure 4: The Four Elements of DSAT"
  },
  {
    "id": "077ff15e-1163-4101-b289-1493f8248c0f",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "14",
    "content": "15 See  for the full list and more detail. 16 Complete inventory of DSAT activities found in 17 DSAT Training Continuum (including Individual, Team and Collective) found at  More detail can be found in Vol 2 (IT) and Vol. 3 (CT). 18 The Whole Force encompasses Regular and Reserve personnel, MOD Civil Servants and civilians, including the Ministry of Defence Police and contractors. It is noted that training sourced through the pan-Governmental ‘Civil Service Learning’ is not subject to DSAT. Any other Civil Service training must be compliant with DSAT."
  },
  {
    "id": "32896221-3db3-4d18-aca6-cc2bb7b38163",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "DSAT and CADMID Relationship",
    "content": "The relationship between DSAT and the CADMID acquisition model is captured at Figure 4. Normally the Scoping Exercise is carried out during the Concept stage and subsequent Outline Business Case (OBC) cost estimates. As the maturity of the design information increases during the Assessment phase this analytical work is reviewed and developed (if required) to inform Full Business Case (FBC). The more detailed analysis conducted during Role Analysis (RA), Training Gap Analysis (TGA), and Training Options Analysis (TOA) is usually carried out post-FBC. The analysis should be conducted to meet the PT milestones such as to inform the business / operational case for wider resource and risk commitments, such as: awarding an equipment commercial contract, implementing significant doctrinal change, relocating a training establishment (TE), or changing an organisation’s structure. The analysis should start at the earliest point in the development of new capability (FT/MTAO can provide further advice). Figure 5: Relationship between the Defence Capability Model and Training (for new capability)"
  },
  {
    "id": "95e99978-579b-4a3c-af3a-bb28e17d0d51",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 5: Training Responsibilities",
    "content": "In accordance with the NCOM, the Navy Acquisition Directorate provides internal programme management and acts as an intelligent customer for Delivery Agents/PTs. The Senior Responsible Owner (SRO) is responsible for articulating the requirements on each of the DLODs, probably through the Programme Manager. The Delivery Agent/PT is responsible for delivering a through-life training capability on behalf of the SRO. However, successfully doing this requires input from a number of key stakeholders from across Navy Command’s other Directorates, particularly Dir P&T. Additionally, in implementing a coherent and effective training solution, there is a dependency and input from a number of the DLODs (see )."
  },
  {
    "id": "6c4cecf9-fa4c-4200-9080-da6e38861732",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Key FLC Stakeholders",
    "content": "19 Amended figure based on existing figure in the JSP that uses legacy acquisition terminology In-Service Capability management. Sitting within one of the six Deputy Directorates of Force Generation Directorate, these managers are responsible for integrating the Defence Lines of Development for in-service capability to generate force elements that can be used to deliver operational capability. Workforce Planners. The RN Workforce Planners are often the TRA for individual steady state training and can validate the analysis of personnel billets affected by the new operational requirement and training conducted in the Scoping Exercise (TNA Stage 1) and RA stage (taking place in TNA Stage 2). However, there may also be a requirement to include for a CT TRA (FGEN for up to Tier 1 training) or other FLC TRAs. In these cases, a lead TRA should be established. Training Management Group and Fisher Consortium. Within P&T, the Training Management Group (TMG) has the overall TDA responsibility for most in-service IT, delivered through the joint RN-industry organisation through the Fisher Consortium from Apr 21. However, other TDAs exist including Fleet Operational Standards & Training (FOST) and the RAF’s 22 Training Group (22 Trg Gp)’s Electro-Mechanical Training Contract. Depending upon the nature of the new capability the effects on training could directly affect infrastructure, training equipment, policy and workforce. Most Training Capability Managers (TCMs) also sit under the TMG and will provide support to the PTs to assist in integrating and implementing the identified training support solution into established training. Future Training & MTAO. The Future Training (FT) team, also part of the P&T Directorate, is responsible for assuring the individual training for new and updated capabilities being introduced over the medium to long term (circa 5-10 years). The FT team also conducts the quality assurance of Training Needs Analysis (TNA), purely from a training management aspect (it is the TCMs who deliver the SME assurance), the majority of which is outsourced. The MTAO is part of the FT team and comprises training specialists embedded at MOD Abbey Wood (as a team and singleton posts within specific project teams) and is charged with delivering specialist training support, advice, guidance and direction to project teams and capability sponsors to ensure that the training and personnel implications of DE&S, Defence Digital and SDA decisions are considered as an integrated component of project team work and at the earliest opportunity. From 1 Apr 23 further Directorate P&T Org design will split these teams, with a new OF5 SM Coherence being created and taking on the SM related elements of Future Training and MTAO."
  },
  {
    "id": "f33894d3-75ee-4adc-859d-c99802244b76",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Project Team Responsibilities.",
    "content": "The PT is responsible for introducing a new or updated capability are responsible for all new training associated with that capability. Although the specifics of this will be unique to each project, they normally include the following aspects: Provision of through-life Individual and Collective training solutions as required for the target audience iaw Authority Input. Training for the whole target audience iaw Authority input. This can include but not limited to both operators and maintainers under the Operate, Maintain, Diagnose and Repair (OMDR) concept. 20 Aviation, Littoral Strike, Ships, Submarines, Support and Royal Fleet Auxiliary."
  },
  {
    "id": "3f85b174-9057-4830-beee-f3cf9049bc76",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "21",
    "content": "22 See 23 Consortium of Capita, Raytheon, Fujitsu, Elbit Systems UK, University of Lincoln. 24 c – Training Delivery Authority More information about the TMG can be found in the TMG  Operating Model (dated Sep 21) 25 h & 9502i"
  },
  {
    "id": "77de8d9b-54b6-4853-bbde-c7efd8d6ed67",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "26",
    "content": "27 Depending on the project this may require an Interim and Steady state solution. See JSP 822 for definitions and more information. Cross-over training for personnel already qualified on legacy equipment. Training for other groups as identified by the TNA process, such as instructors, FOST sea riders, etc. The PT will be responsible for: The production of a Training Strategy/Training Plan that identifies key training milestones supporting the wider capability programme. The production of the Scoping Exercise Report (SER) to identify the target audiences to be trained for the capability, indicative numbers of personnel requiring training, high level tasks that personnel will require training in, timings of when training is required to be in place, potential locations of where training could be delivered, and possible options for solutions of how training could be delivered. Developing a Training Solution Procurement Strategy. For the vast majority of cases, this should indicate the required level of integration into legacy RN training delivered via the Selborne programme by the Fisher consortium. The commissioning and management of the TNA programme, including whether this will be via the Engineering Decision Support (EDS) scheme, the Fisher consortium, the Original Equipment Manufacturer (OEM), or via alternative means. Integrated Logistic Support (ILS) and equipment data, as well as updated doctrine, concepts and tactics to inform TNA and Training Solution procurement. All such data must be free of Intellectual Property, Export Control, and ITAR restrictions suitable for sharing with both TNA and training solution contractors, including the Fisher consortium. The initial procurement, installation, and integration of all specific training media, including hardware, software, and training documentation with a through-life support solution, including integration in the Selborne programme via the Fisher consortium. The funding of updates to the capability specific training media and equipment. The provision of capability specific training infrastructure or required changes to legacy training infrastructure. The production of a Training Support & Transition Plan."
  },
  {
    "id": "6814c09f-384c-46f1-99cd-f7538229913d",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Training and Education Principles",
    "content": "The following principles underpin Training in both the P and TLOD: System of Systems Approach (SOSA). To deliver agile and affordable capabilities, Defence must acquire and build systems that work together (interoperate) and achieve the necessary flexibility, commonality and reuse. The SOSA is the enabling mechanism by which Defence will ensure that all delivered systems are procured and built in accordance with the vision ‘Enabling enhanced capability through achieving commonality, reuse and the interoperability of independently procured systems’. Value for Money. All training systems must deliver value for money (VfM). The 28 See  for more details. National Audit Office uses three criteria to assess the VfM of government spending i.e. the optimal use of resources to achieve the intended outcomes, these are: economy, efficiency and effectiveness. VfM is defined as the relationship between these three factors and is illustrated in Figure 6. Figure 6: Value for Money Model Interoperability Requirements. Unless there is an agreed business reason, all relevant training systems will need to adhere to the Defence Direction for Technology Enhanced Learning (DTEL) and the Defence Modelling and Simulation Coherence (DMaSC). This allows them to be interoperable and suitable for expansion in the future if requires. It is particularly important for simulators to abide by DMaSC so that they can be used in conjunction with other MOD and Allied simulators to provide collective training. Through-Life Considerations.  should ensure delivery of the required capabilities, through-life. It is critical that Training is planned, delivered and generated in a manner that is consistent with all other DLODs to ensure provision of a coherent capability through-life. The need for iteration is imperative through the life of a project as information matures and develops. Export Controls & Intellectual Property Rights. When procuring training a PT needs to be aware of any potential export controls that may apply to the equipment the training relates to, particularly International Traffic in Arms Regulations (ITAR). This is especially true if the training will be delivered through a third party such as contractors of the Electro-Mechanical Training Contract (EMTC) or the Team Fisher and the Selborne contract. Advice and guidance for this is provided in the  on the KiD, as well as specifics on  . More policy is also found in , and  and the Defence Intellectual Property Rights ."
  },
  {
    "id": "cbfcee6b-5fc7-4b64-b9d7-f8a77f9ca779",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Training Building Blocks",
    "content": "The approach taken must be tailored to the specific needs of each project/programme. Early Training Activity. Opportunities to minimise the training burden through equipment design should be investigated early in acquisition cycle . The development of the System Requirements Document (SRD) and the Human Factors Integration (HFI) Working"
  },
  {
    "id": "8f54b18e-5ad5-4b7a-9d39-72c8d6eb386b",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "33",
    "content": "Group provide a mechanism for this work to be taken forward. In addition, an embedded training capability provides a tool that could close the training gap and provide a mechanism to combat skill fade. Often these decisions need to be made prior to the TNA being finalised and the appropriate Training stakeholders engaged. Stakeholders. Identify all key project stakeholders and establish project Training through-life management chains and dependencies with other DLODs. This activity should be undertaken by the PT supported by the MTAO. A Training Steering Group (TSG) should be established (further details can be found at ). CONEMP and CONUSE. The requirement for activity in the non-equipment DLODs need to be captured within the Concept of Employment (CONEMP) which is then later developed into a Concept of Use (CONUSE). Within the CONEMP the Training implications of introducing a new military capability should be identified to enable smooth capability integration to be achieved. Initially input will be provided by Navy Command. Requirements and Acceptance Policy. User Requirements. Initially Navy Command should offer potential training URs for inclusion in the URD. Future Training may provide further input on the potential training requirements. It is essential that training requirements are captured within a URD to ensure that funding is approved for training. System Requirements. Navy Command should be consulted when generating System Requirements (SRs) which will be required to address the training of the new capability and/or its training solution. There must be traceability between requirements and test, evaluation and acceptance activities. Training solutions may have their own URD and SRD that will be developed at the appropriate stage. Assumptions Capture.\tA key component of project management is the identification and impact analysis of assumptions that affect the project. Training assumption impact needs to be managed effectively. The commencement of Training assumptions capture needs to happen at the earliest opportunity. The assumptions then need to be endorsed and managed by the Training Steering Group (TSG). The Master Data Assumptions List (MDAL) and the Cost Data Assumptions List (CDAL) of wider project’s Through Life Management Plan should be used to maintain Training as integral to the wider project it supports. The following areas should be considered: Assumptions made about the training target population or audience (e.g. what experience level and therefore rank of maintainer and operator will be required, etc.). Assumptions made regarding training throughput (e.g. average appointment lengths, any need for spare throughput capacity, etc.). Assumptions made on when training is required to start, finish and how often it may be required, including whether an interim solution is required (e.g. will a contractor be needed to provide interim training whilst the steady state solution is developed?). Assumptions made on training location, particularly resulting from"
  },
  {
    "id": "183b91c0-ffeb-4f3e-ab7e-4e538be33ab7",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "34",
    "content": "35  & policy guidance. Assumptions on how to deliver training, including any policy / concepts and doctrine guidance. Assumptions on whether training will need to be integrated into existing training solutions (e.g. existing simulators / trainers, etc. – this could be a significant cost.). Assumptions on what will need to be trained; drawing upon the CONEMP (can also be very high level, e.g. maintainer training / maintenance managers / operators / command appreciation, etc.). Training Risks. In terms of risk and opportunity identification, the most obvious source of information is the assumptions and constraints data. As with assumptions and constraints, the training risks should be integrated with the wider project risks to avoid duplication of effort and to maintain Training as integral to the wider project it supports. At a minimum the following training risks should be considered, documented, addressed, and updated/maintained: Risk to military capability and effects of not having a training solution ready in time to meet the In-Service Date (ISD), Impact of not having a training solution adequately resourced through-life of the capability, Being unable to articulate training requirements in time to inform training solution design, including identifying and addressing Intellectual Property, Export Controls / ITAR and any licensing needs / constraints to inform the design process, Training requirements articulation, design, and development through unavailability and/or immaturity of key information, Risks to personnel structures through inappropriate training and/or lack of throughput capacity, Doctrinal development and validation through training not capturing doctrinal requirements, Risks to organisations (especially FLC) if training is inadequate or not appropriately resourced, Training infrastructure (including existing training solutions, associated hardware and software) of ability to deliver the new training solution, e.g. new software being DMaSC-compliant and compatible with other requirements of existing Training-LANs (notably with respect to architecture, processing power and cooling), additional classroom requirement should additional through-put be in excess of the existing training estate accommodation, Risks to logistics support activity through inadequate training. Training Strategy/Training Plan. This should provide a roadmap of how the PT intends to deliver the human capability element. The document should include route to"
  },
  {
    "id": "1c6d5bf3-eeb0-46a9-b91b-7c691adf0990",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "36",
    "content": "market for TNA, potential training solutions including procurement strategy, scope of delivery options, and methods and media options and implementation. The Training Support Plan (TSP) should form an element of the strategy (it may also be an annex to the ILSP, maintained by the ILSM. By this means, training is addressed in the TLMP). The Training Strategy is a live document and should be subject to regular review. The TSG will need to endorse the Training Strategy. It is imperative that the Training Strategy reflects the programme and therefore, there are no set times when activity must be undertaken. However, the Training acquisition activity should not be undertaken in isolation and needs to support project milestones and outputs. Further detail of Training activities undertaken at each block mapped to the optimum phase of the CADMID cycle is presented at Route to Market for TNA. The PT is responsible for the commissioning and management of the TNA programme. Not all parts of the TNA may be required and, if they are, they do not need to be contracted with the same provider. For very large or complex programmes, it may be more appropriate to fully compete the TNA requirement. This route is used where a prime contractor has insufficient training expertise or if the procurement is commercial-off-the-shelf and/or the prime contractor offers only a standard training programme. The PT should initially consult with FT/MTAO to identify and agree the most appropriate TNA procurement approach, timings and route to market for their project. Options typically include: The prime contractor undertakes the TNA(s) as part of the overarching contract. This is the most common choice for major or medium-sized projects because the prime contractor usually has a sizeable and experienced training department. Where a prime contractor has insufficient training expertise (or if the procurement is commercial-off-the-shelf and the prime contractor offers only a standard training programme) it may be sub-contracted to a commercial provider. In order for the TNA to be undertaken by the prime or its sub-contractor, the overarching contract must have sufficient detail in the URD, SRD and contract to specify the TNA requirement. The PT contracts a commercial provider to undertake the TNA(s) via a suitable commercial framework such as the Managed Learning Service (MLS). For DE&S the EDP is the default route to market but other preferred contractors exist depending on type of activity. Once the PT has consulted with MTAO to decide the most appropriate procurement strategy for the TNA, the TNA outputs should become contracted deliverables, with defined delivery and quality timetables. MTAO should be consulted to formulate the Statement of Requirement (SOR) for the outsourced TNA in accordance with the Future Training TNA QA endorsed TNA approach (initially outlined in the Training Strategy). Part 2 (Training Analysis Standards) of this document outlines the quality criteria that should be used to develop the TNA SOR including contract deliverables and contract management processes. Provision must be included for review of the deliverables by the TSG and PT and for subsequent amendment and endorsement. Training Requirement Definition. In March 1990 the House of Commons Defence Committee recommended that the Ministry of Defence (MOD) substantially increase their research and development in simulation technology. At that time the MOD estimated that the 37 Maritime Training Strategy v4  and . Update expected in 2023. 38 Whilst FT/MTAO can advise on options for TNA provision, the PT must ensure that the DE&S or NCHQ Commercial function approve the TNA procurement approach and are consulted accordingly. 39 For example Knowledge Pool. Policy contained in 2022DIN07-124 – MOD Managed Learning Service – Procurement of External  Training for MOD Personnel."
  },
  {
    "id": "4ae72e92-88ae-4d7e-abdf-c936bc778e66",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "40",
    "content": "41 For example the"
  },
  {
    "id": "fc5e3b6a-462c-4a2b-97cb-a3c328e9c8a5",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "3000 or so simulators in use across the three Services had cost in excess of £450M with a further spend of £700M planned for the following 10 years. Then, as now, it was recognised that members of the Armed Forces must train effectively to achieve and maintain individual and collective operational capability. Simulators, in combination with the more traditional forms of training, have a key role in the achievement of this objective.",
    "content": "In 1992 the National Audit Office (NAO) examined the acquisition, utilisation and effectiveness of these simulators used in training. The examination covered all three Services but concentrated on the RAF due to the high number and cost of flight simulators alongside their special relevance to RAF training and flight safety. In summary the NAO report concluded that the MOD should: Ensure acquisition choices are based on improved and more timely definition of training needs through the introduction of TNA and, Formulate a clear plan, with well-defined priorities, for future acquisitions. JSP 822 advocates the use of a TNA process for the identification of the training needs and solution. It is a systematic, iterative, output based approach that provides an audit trail of analysis to determine the requirement for training and, if required, enable design of specialist training and acquisition of training equipment/services. The process takes a three-phase approach with a number of stages and deliverables. It is essential that the training solution recommendations include implementation and acceptance requirements and plans sufficient to move the next phase of the project forward cost effectively, in line with timescales and resources available. The MATG provides firm guidance for the conduct of a rigorous, DSAT-compliant TNA. Nonetheless, its contents should not preclude deviation from the procedures it describes, in instances where intelligent analysis are better served by alternative means. Any such deviations must be unambiguously proposed and endorsed by the TSG prior to work being commenced. Figure 7: TNA Deliverables TNA Overview (further detail on Individual TNA is outlined in Part 2 and JSP 822, Part 2 for Collective TNA):"
  },
  {
    "id": "98601e56-2310-492e-b3a3-beedf1fcd84f",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Stage 1 - Scoping Exercise Report",
    "content": "The Scoping Exercise Report (SER) is the initial analysis of the training requirement and options for meeting the training requirement and making a broad order estimate of the risk and resource implications associated with each option. The process first needs to confirm if new or modified training is the solution (or part of the solution) to the problem (normally indicated as a performance deficiency in a job or role). This will include initial estimates of the requirements that will be further refined (as required) during the TNA and will also include identification of the method of and 42 Ministry of Defence: Use of Simulators in Training - National Audit Office Report, dated 7 September 1992 resources needed for the subsequent steps of this process. Dependencies with other DLODs will also need to be clearly established and considered. It is recommended that SER is undertaken to complement other Concept phase activity and inform the Outline Business Case. Estimates of initial and through-life costs that fall upon the PT should be identified at this stage (see  C for potential areas of cost). It should be noted that this process does not identify the training solution prior to the TNA but based on the analysis of likely costs that are supported by good judgement assumptions, it presents an indicator of required resource for training and therefore a suitable resource constraint on the future Analysis work. Figure 8: Potential Sources of Training Whole Life Costs In the Assessment phase a review of the SE should be undertaken, this may require the SER to be ‘up-issued’ and/or re-written. This work should be a re- validation and refinement of the underpinning analysis conducted during the SE. The analysis process is iterative and so the growing quantity, maturity and granularity of available data will enable the SE to provide: Assumptions validated against maturing information. Greater visibility and understanding of Risk exposure. Greater accuracy applied to through-life cost estimates to inform the Main Gate Business Case. Performance Criteria for any potential training solutions to be articulated in greater detail."
  },
  {
    "id": "22867d6e-423f-4167-9dcb-f16043160aec",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Stage 2 – TNA Development",
    "content": "The TNA Development is broken down into 4 deliverables (individual/collective): Deliverable 1 – Role Analysis/Task Analysis. This establishes the 43 Ultimately, the SER bounds the analysis to be undertaken during the TNA Development Phase and recommends the approach to be taken during Stage 2 TNA. 44 Against those stated in the Master Data Assumption List (MDAL). 45 As detailed in the Risk Register. 46 This represents the standard approach to TNA. The adopted approach and required deliverables needs to be project specific. operational/workplace performance, conditions and standards required of individual and collective tasks (i.e. team, sub-unit, unit and formation) for the new or changed operational requirement. It will also identify likely annual trainee throughput that will in turn inform the Statement of Trained Requirement (SOTR). Deliverable 2 – Training Gap Analysis/Teamwork Error Analysis. This identifies the training gap between the new operational/business need and current training provision in terms of knowledge, skills and attitudes. Deliverable 3 – Training Options Analysis. This looks at different combinations of methods and/or media, which will bridge or partially bridge the training gap(s). It will make a recommendation as to a cost-effective training solution. Deliverable 4 – Training Needs Report. The Training Needs Report provides the requirement and the TSG endorsed training solution with a draft RPS/Competency Framework (CF) and draft Formal Training Statement (FTS) with a draft implementation plan. Quality Assurance (QA). The Quality Assurance (QA) of the TNA, in assuring validity, is very important. The QA of the TNA is not just a checklist of the content by using quality criteria, as this only involves assessment of the reliability: it must also consider the validity aspects of the relevant subject matter expert input to the final recommendation. Only the combination of quality criteria, validity of source data and objective management will assure that the overall process is “fit for purpose”. It is important to note that everyone involved in the TNA is responsible for quality and all TSG members will have specific roles with respect to assuring that the final recommendation is cost-effective. It is important that the QA function is separate from the conduct of TNA to allow independent review. TNA Contract Management. The TNA contract, whether provided through a prime contractor, sourced via commercial framework or open competition, requires proactive contract management to ensure its outputs are delivered to time, cost and quality. MTAO, as the Training advisors based at MOD Abbeywood, provide contract management support to PTs to ensure the conduct of the TNA is satisfactory. Early engagement by PTs with MTAO is strongly recommended to ensure that TNA contracts are sufficiently detailed to deliver the TNA outputs to time, quality and cost, iaw the overarching Training Strategy and TNAQA assurance. MTAO also advise PTs on suitable TSG membership, Training activities and coherence with other related projects, concepts and doctrine. Training System and Media Procurement Strategy. The TNA process will identify the most cost-effective training solution through-life. The procurement of training media and services should follow current commercial guidance and adopt a cross DLOD approach. Any training solution that has a modelling and simulation element will need to comply with DTEC rules that are outlined in JSP 822, Part 2. The PT should initially consult with MTAO to identify the most appropriate procurement and through-life support approach, route to market for the Training System Procurement in support of their project. MTAO also liaises with organisations that manage the support contract(s) for a number of maritime training systems, including Maritime Composite Training System (MCTS) and will need to be engaged when updates to the training system is required. Integration. Course scheduling is a complex operation and specific training will need to be integrated into an existing course schedule and branch pipelines. There is the 47 The number of support contracts are currently being rationalised under Maritime Training Systems Through Life Availability and Support Services (MARTASS) project. need to interface early with the Statement of Trained Requirement (SOTR) process that documents the quantitative requirement i.e. the number of trained personnel required by the Naval Service. The RN SOTR process is owned by Director People and Training as the Naval Service TRA, who is responsible for ensuring overall Profession structure and sustainability. It looks- out to 5-yr point, but typically deals with the next 18 - 36 months (however, the SOTR isn’t finalised until 12 months in advance of the Training Year). This then forms the demand for the Training Delivery Authority (TDA), which is responsible for generating the Statement of Training Task (SOTT) i.e. training supply. Training Delivery. Training will be delivered by a Training Delivery Authority on behalf of Director People & Training (IT) or Director Force Generation (CT) unless it can be demonstrated that it is better value for money to use another route (as part of the TNA process). Interim Training Solution. The approach to training provision is that interim training will be based on the submission from contractors in response to successive system iterations through-life. The trigger for the transition to steady state will need to be identified based on system maturity/stability, the transition to ISD & IOC/FOC timelines. Training the Trainers. Consideration will be given to the most appropriate way of building an initial level of knowledge in the new equipment and systems. Provision should be made for attendance on the Interim Training courses. This should also include FOST(Ships) and FOST(Submarines) personnel who will be involved in the delivery of collective training. Steady State Training. The default option is that Team Fisher will be the predominant Training Provider of Steady State IT, although exceptions will exist. This will be based on interim training deliverables from each successive roll out of capability uplifts."
  },
  {
    "id": "effd8398-bc77-4267-80fe-b83634c50fe1",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Stage 3 - Training Needs Evaluation",
    "content": "JSP 822 outlines the need for a Training Needs Evaluation (TNE) of the training recommendations given in the TNA: “The purpose of the TNE is to evaluate the effectiveness and efficiency of the TNA process and the training solution that was recommended at the end of Stage 2 (Analysis). Firstly it should evaluate the TNA methodology through the process of CI, secondly it should evaluate the recommendation by reviewing the training solution it proposed. The rationale for this is that it may be some time (years) after the final report is endorsed before we are in a position to evaluate the proposed solution.” It then provides key Lessons Identified (LIs) and increased levels of confidence in resource and risk forecast information that can be applied to future / ongoing projects, thus continuously improving the whole Analysis and DSAT approach."
  },
  {
    "id": "5b83bdc0-ee19-4a28-a8cb-1cb9d17eabb3",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 7: Training contribution to Acceptance",
    "content": "The Integrated Test, Evaluation and Acceptance Plan (ITEAP) provides the granularity of the project acceptance strategy and provides the detail relating to acceptance criteria. The criteria are developed based on the project outputs and SRD. User Acceptance will occur when there is sufficient evidence to demonstrate that all of"
  },
  {
    "id": "434cb16f-da0b-4370-94ad-3effbef32010",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "49",
    "content": "the validation criteria in the URD have been met. IOC/ISD takes into account all of the relevant DLODs as well as the equipment. The Training areas of the PLOD and TLOD will deliver compliance reports confirming DLOD readiness (including safety and suitability). Therefore, it is imperative that early work of Training milestones is aligned to the programme capability milestones. This will need to be linked to the SRD compliance report summarising the verification outcome against each SR in order to provide Training compliance evidence."
  },
  {
    "id": "42e58e0c-b432-44e4-82a0-2431bbd3798b",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 8: Interface with other DLODs",
    "content": "Training must be able to influence decisions made elsewhere across the DLODs (particularly the ELOD), which could result in excessive training costs and threaten project affordability, as well as highlight potential risks associated with insufficient training provision (See ). It is essential that neither equipment nor support contracts are awarded without a sound understanding of the through-life impacts of their training requirement. The need for this coherent approach is driven by the Defence Operating and Acquisition models. The training component of the capability is reliant on output from a number of the DLODs. The main dependencies are outlined below: Training. The Training activities are detailed at ."
  },
  {
    "id": "e2ef6b30-2bb4-4db4-b133-9493f8b95ba9",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Equipment.",
    "content": "The initial procurement and installation of all specific equipment, including; hardware, software and documentation required for training. The funding of updates to the aforementioned media as required for training. The provision of any required training infrastructure. The initial procurement and installation of all specific training media, including; hardware, software and training documentation. The provision of test facilities that should have utility in the training environment. They are responsible for ensuring maximum utility in training and an explanation of the cost associated with this provision."
  },
  {
    "id": "53ad7744-a224-49c4-9323-88f6d32beff8",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Personnel.",
    "content": "Recent organisational design within the Navy has allocated the governance of IT through the PLOD and CT through the TLOD. The PLOD will provide sufficient instructors and trainees to deliver the required training output, as articulated in the Statement of Trained Requirement (SOTR)."
  },
  {
    "id": "bf74f06c-8ae2-418d-92f4-389dc626499d",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Infrastructure.",
    "content": "The DIO (expand) should consulted as they may be responsible for 50 Training will often form elements of the mitigation in the safety case and so there is the need for the PT Training lead to confirm these activities are being met. 51 For example the ELOD may seek to keep costs down rather than fund development of an intuitive user interface, which results in a more complex role for the operator, longer training and ultimately higher through life costs. 52 e.g. poor maintainer training may adversely impact equipment availability and lead to higher through life spares and replacement costs."
  },
  {
    "id": "26fb8722-6a50-4d33-921c-51b48437404f",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "53",
    "content": "providing sufficient and suitable training facilities to host the training requirement, as articulated by the ELOD. This may not be the case if the preferred steady state training solution is a K course. Doctrine. The CONEMP/CONUSE, the URD and any other pertinent extant documentation (for example MWC or DCDC) that will be utilised by Training to inform and shape the training requirement. Organisation. Force structures required for the new capability or the training for the new training solution (Mil/CS/Contractor). Training may need to be more than military personnel and include MOD Civil Servants or Industry Partners. Information. The training documentation hosted/managed on a learning management system (e.g. Defence Learning Management Capability) will be provided by the lead equipment PT."
  },
  {
    "id": "156b446c-6647-4593-aaf7-b7b408e84dd6",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Logistics",
    "content": "The proposed maintenance arrangements for the new equipment. The timely availability of technical manuals to support analytical work. D provides further details on the cross-DLOD dependencies and potential associated cost drivers."
  },
  {
    "id": "4238ab16-f051-4094-ae5e-4aa797e408cb",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Section 9: Training Governance",
    "content": "The governance heirachy for Training can be seen in Figure 11. The single key factor that drives a successful project is the formation of a Training Steering Group (TSG) at the earliest opportunity within the Concept phase of the CADMID cycle. The TSG’s primary purpose is the management of the integration of Training within the project and is overseen by the Chairman from the PT who is to ensure that all the appropriate stakeholders are identified and actively engaged in the process (see Annex E). This is done through regular TSG meetings where deliverable timelines are agreed, stakeholder feedback coordinated and regular communication with the PT maintained to ensure they remain aware of projects progress. Cross-DLOD issues identified at the TSG will be raised up to the Capability Integration WG and potentially the Programme Board (PgB)."
  },
  {
    "id": "79624b26-9739-4f8f-89e0-f20c39afea3d",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "56",
    "content": "57 This body is often given different titles to reflect the different needs and stakeholders throughout the acquisition process. Referred to as a TNA Steering Group (TNASG) with a list of responsibilities wider than the TNA in  Name likely to change in v6 in Sep 23. Figure 9: Training Governance Structure Collectively the TSG members should identify the activities required to be undertaken, the milestones to be achieved and the training-related risks and issues associated with the project, the lead stakeholder for each action, and the dependencies with the overall project plan and with other DLOD activities. In addition, some of the stakeholders will act as endorsing members for all Training related documentation or content required for approval points and acceptance purposes. It is therefore imperative that the roles and responsibilities of each member of the TSG are clearly defined and the individuals fulfilling those roles fully understand what is required of them. Training Steering Group Membership. The composition of the TSG is fundamental to the effective management of the Training aspects of a project throughout its life. It is the lead forum for Training issues and has the following core membership who are required for endorsement decisions: Delivery Agent. The Chair of the TSG will be decided by the Project Manager. It is recommended that the responsibility to chair the TSG be delegated to the ILSM or PT Training Lead. The PT will also provide the secretariat to the steering group. Training Requirement Authorities. The FLC owner of the training requirement. As the end-user of the trained output the TRA is the ultimate authority for training related decisions. However, there may also be a requirement for multiple TRAs (to represent CT or other FLC TRA). In these cases, a lead TRA should be established. FLC Capability area. Sitting within one of the six Deputy Directorates of Force Generation Directorate, these managers are responsible for integrating the Defence Lines of Development for in-service capability to generate force elements that can be used to deliver operational capability. They also run the CIWGs, which sit above the TSG in the governance structure shown in Figure 11. More than one Capability Desk may be required depending on the specifics of the training solution, for example one for both the operator and the maintainer. 58 Examples include the User Requirement Document (URD), System Requirement Document (SRD) or Training Needs Analysis (TNA) deliverables). 59  3 60 See 61 Aviation, Littoral Strike, Ships, Submarines, Support and Royal Fleet Auxiliary."
  },
  {
    "id": "8cca1646-b1b4-43e5-baa4-4710b9283be3",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Training Assurance (FT/MTAO).",
    "content": "TNA Quality Assurance. A training support specialist from Future Training who can: Advise that the steering group is representative of all the stakeholders affected by the new capability, Ensure the compliance of each deliverable with the methodology agreed at the Scoping Stage, Ensure that a clear audit trail exists for each decision made via appropriate Deliverables and that any references to data sources are valid. Advise that the steering group is representative of all the stakeholders affected by the new capability, Ensure the compliance of each deliverable with the methodology agreed at the Scoping Stage, Ensure that a clear audit trail exists for each decision made via appropriate Deliverables and that any references to data sources are valid. Other representatives should be added to the membership of the TSG where they can add value including any relevant TDAs, the TNA contractor, the FLC TCM and relevant Industry Partners. The detailed tasks the TSG is required to perform (Terms of Reference) can be found at  E)."
  },
  {
    "id": "8f838226-e67e-40f0-82ba-310a0147c90b",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Defence Training Continuum",
    "content": "One of the key drivers in maintaining Force Elements at Readiness (FE@R) is the provision of sufficient capable and motivated personnel. Training and education makes a contribution to both the capable and motivated aspects of this requirement. The outputs of both individual and collective training combine to enhance performance and produce Force Elements at the appropriate level of Operational Capability to meet mandated Readiness Profiles. In Defence there is a training continuum that runs from individual through team to collective, definitions of each element are set out in Figure 5 below:"
  },
  {
    "id": "09a90432-7c83-452b-a993-bc6180a802c5",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Individual/Team/Collective",
    "content": "Individual. Training designed to develop the competencies (a mix of knowledge, skills and attitudes) of individual personnel. Team. Training which is aimed at generating the ability of teams and sub- teams to function as a cohesive entity and so deliver operational capability. A team is a sub-division of an individual unit’s personnel, for example a submarine would comprise teams operating as the Command Team, Ship Control Team, Propulsion Team, etc. A sub-team is where the above teams can be sub-divided further into sub- teams; for example the Command Team can be split into Command Information System, Sensor, Fire Control, Tactical Picture Compilation and Navigation sub- teams. Collective. Training which is aimed at improving the ability of units, or formations of units, to function as a cohesive entity and so enhance operational capability. Tier 1 training prepares units and sub-units to take their place within a tactical formation or Combined/Joint Force Component. Tier 2 training prepares tactical formations operating below the Combined/Joint Force Component level for operational employment. Tier 2+ Collective Training prepares one or more Combined/Joint Components for operational employment. It may be conducted in combined or joint contexts on a UK, NATO or Coalition Partner framework basis."
  },
  {
    "id": "da19d7e5-2093-4aa5-918c-f5a71736be04",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Dated 14 Feb 23",
    "content": "62 This list will need to be applied pragmatically based on the nature and scale of the acquisition project."
  },
  {
    "id": "70c0095c-0e44-4c10-b478-464f13dc6a95",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "INITIAL AND THROUGH-LIFE TRAINING COSTS",
    "content": "Potential Sources of Cost. Potential sources of cost arising from all Training activities are identified below. Capital Costs. Capital Costs (usually EPP funded) could potentially include: Training Media. Estimate ROM costs of potential training solution options that may meet the training requirement. These could include solutions such as CAI, CBT, Part Task Trainers (PTT), GFE, simulation, serious games, e-Learning, contractor courses, Private Finance Initiative (PFI), managed service, etc. Costs may be estimated by identifying costs for similar in-service solutions and by approaching industry for ROM estimates on a ‘without commitment or prejudice’ basis, however it should be noted that industry may charge to produce a ROM quote and it may take several months to produce. Integration into Existing Training Solutions. The cost of integration into existing training solutions must be established through the appropriate DE&S PT or FLC that manages the training solution. Solutions include MCTS, Bridge Simulators, SM Command Team Trainers, MTDS, CATT, CAST, DCCT, etc. It should be noted that integration into such systems may include costs for support functions, e.g. Training Support Systems, Support Staff, Training Design & Delivery, Facilities Management, Infrastructure, etc. – confirm with appropriate PT. Interim Training Solution (ITS). An interim training solution, or First of Class training, may be required if steady state training is unavailable to support the first tranche(s) of trainees required to meet ISD. First of Class training may also be required for instructors to gain system familiarisation. It may be desirable to achieve the steady state solution in time for ISD, thereby removing the need for a First of Class or interim training solution. Training Support Systems. The training solution may require a LMS, LCMS, and TAFMIS to aid design and management of training. Training Support Systems must be compatible with existing MOD systems such as DLP, DITM, JPA. Reference Documentation. Access to technical reference documentation will be required to support training analysis and design. Access to such documentation may require funds to be provisioned to cover any IPR and International Trade in Arms Regulations (ITAR) restrictions. Training Design. Training Design, including instructional design, will be required to be conducted in support of the training solution. It should not be assumed that training design for new capabilities is covered within existing partnering agreements with a single Service (sS). Use of LCMS systems may facilitate the training design process through-life. New or Refurbished Training Infrastructure.\tClassrooms, buildings, ranges, berths, etc. may all need to be built or refurbished as part of the new training solution. Opportunities for sharing and re-using such facilities with other training should be exploited. There may also be a need to upgrade support facilities such as messes, catering, car parking, etc. 63 Identify costs with the PT or FLC supporting the training system. 64 Contact with industry should only be made after successful completion of Commercial Awareness training (DACMT’s Introduction to Commercial Practice On-line training is suggested). 65 May not be required if steady state solution ready in time. 66 United States’ ITAR regulations may apply to US systems or companies; clearance must be sought through sponsoring PT."
  },
  {
    "id": "9b8343e2-60b6-4af5-b9e6-2e43b6898549",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Dated 14 Feb 23",
    "content": "IT Infrastructure.\tIf new IT infrastructure is required, it should be compatible with MOD systems. IT infrastructure could include items such as servers, LANs, workstations, software licences, projectors, SMART boards, etc. SCIDA & IT Security Accreditation requirements of any proposed Training Solutions should also be considered. Risk Mitigation.\tCosts to mitigate any identified training risks must be provisioned. Annual Through-Life Support Costs.\tAnnual through-life support costs could potentially include: Instructors.\tA range of instructor options should be investigated, including military (various ranks), MOD Civil Servant and industry. For military instructors, clearance with the respective Personnel desk should be sought. Costs for military and Civil Servant instructors should be based on the respective workforce capitation rate. Training Support Staff.\tAdditional staff may be required to support some training events, e.g. to be role players, to assess training, to manage exercises, etc. These could be military or civilian, either full time or only required for specific training events. Travel and Subsistence.\tIf trainees are required to travel to undergo training it should be costed for, including any additional allowances payable for foreign travel, etc. Consumables and Utilities.\tTraining consumables may comprise stationery, materials, ammunition, tools, etc., whereas utilities would include items such as electricity, heating, water and sewerage, air conditioning, telephone line rental, IT line rental and network line rental. Specialist clothing and Personal Protective Equipment (PPE) may be required for some training events. Training Design. Continuous training design (and instructional design) support will be required to maintain changes to training documentation arising from changes to policy, doctrine, equipment, etc. This could be simplified through use of modern LCMS systems. It should not be assumed that this would fall under any existing partnering arrangements. Training Publications. Publications which may support training include handouts, charts, maps, booklets, web sites, blogs, wikis, etc., all of which would have to be produced and maintained through-life. Train the Trainer Courses.\tTrain the Trainer courses will be required if instructional staff are likely to have to operate complex training solutions. These will be required in time for ISD as well as through-life to account for staff turnover, and may require additional classroom facilities and facilitative delivery. This should not be confused with the Defence Train the Trainer courses delivered by DCTS. 67 For instance MODNET Official/Secret, TRIBUNE. 68 Training Design and Instructional Design likely to require through life support to cater for updates to training – do not assume current service provider, if any, will conduct Training Design and Instructional Design. 69 Likely to be required through life to cater for staff turnover; to be annotated in relevant SOTR."
  },
  {
    "id": "392a9613-6c02-4313-b346-0845f148a4b0",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Introduction",
    "content": "The [project name] Training Steering Group (TSG) has been established to manage the Training and Training Equipment of the XXXXXX project in accordance with the principles of JSP 822 and the SSE."
  },
  {
    "id": "033ffb48-bd25-42c9-a7fa-064f5e151863",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Membership",
    "content": "The composition of the TSG will change depending on the focus of the group throughout the acquisition cycle. The core endorsing members of the TSG are: Delivery Agent (Chair) Training Requirement Authorities FLC Capability area representatives Training Assurance (FT/MTAO) Future Training TNA QA Other key stakeholders can be added as required to the membership of the TSG including: TNA Contractor FLC TCM Training Delivery Authorities Industry Partners Other DLOD or Customer Representatives as required"
  },
  {
    "id": "ac94c925-2a44-4ffb-b7c5-28366462f77c",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Primary Purpose",
    "content": "To manage the integration of the individual and collective training requirements and provide a clear view of progress to the XXXXXX Project Board."
  },
  {
    "id": "2b1d987b-703a-42eb-9536-32c68c7fa250",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Secondary Purposes",
    "content": "Develop and maintain a Training Support Plan (TSP). Scope the training aspects of the project including potential hurdles and key milestones. To ensure that any training related issues are adequately captured and endorsed in all Project documentation (e.g. ITEAP, TLMP, URD/SRD etc) Ensure the Defence Acquisition processes for Training is followed. 70 DE&S, DD, SDA. Although the Chair, as per  it will be the TRA that has the final say on non-quorum decision- making. 71 TMG for most, but not all, RN IT. CT TDA is FOST."
  },
  {
    "id": "de0011a8-e53a-4aa5-a0aa-81ded4cd3f18",
    "document": "Maritime Acquisition Training Guide  (MATG) Part 1 Project Team Guidance V2.0.docx",
    "section": "Dated 14 Feb 23",
    "content": "Endorse the most cost-effective training solution recommendation. To commission and endorse any training analysis work that needs to be conducted. Including: Co-ordinate the activities of all contributors to the TNA. Brief potential Contractors and act as a point of contact for any requests for information or subject matter expertise. Endorse proposals affecting the TNA process or that amend outputs. Review and co-ordinate amendments to TNA outputs. To recommend or quality assure recommendation of the most cost-effective training solution. To assist the design and implementation of the chosen training strategy. To provide a forum whereby training issues can be discussed by all key stakeholders. To identify and manage training related risks. To support XXXXXX Project board to facilitate the introduction of the training by the Ready for Training Date (RFTD). To agree the Training Maturity Assessment to be passed to the XXXXXX Project Board."
  },
  {
    "id": "9d72373d-fd2f-41ff-8410-c3f6df6db5e6",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Uncategorised",
    "content": "Maritime Acquisition Training Guide Part 2: Training Analysis Standards"
  },
  {
    "id": "643b5251-0637-4014-9327-1612a0b32004",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Dated: 14 Feb 23",
    "content": "© Crown Copyright 2023"
  },
  {
    "id": "1df47b6f-21f3-4bbd-a2af-c8a187788c25",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Annexes:",
    "content": "Scoping Exercise Report (SER)………………………………………………………A-1 \tTNA Scoping Exercise Report Quality Criteria……………………………………...B-1 \tRole Scalar Hierarchy………………………………………………………………….C-1 \tDifficulty, Importance, Frequency (DIF) Analysis…………………………………...D-1 \tKnowledge Skills Attitude (KSA) Analysis…………………..……………………….E-1 \tRole Performance Statement (RPS) ...………………………………………………F-1 \t Role Analysis (RA) Quality Criteria...……………………………………………......G-1 \tTraining Gap Analysis ………………………………………….……………………..H-1 \tDesigning New Training Objectives ...……………………………………………….I-1 \t Training Gap Analysis (TGA) Quality Criteria ...…………………………………….J-1 \tFidelity Analysis………………………………………………………………………...K-1 \tMeasure Of Training Effectiveness (MOTE) ………………………………………..L-1 \tTraining Options Analysis (TOA) Quality Criteria...…………………………………M-1 \tTraining Needs Report (TNR) Quality Criteria………………………………………N-1 \t Training Needs Evaluation (TNE) ...………………………………………………….O-1 \tTraining Needs Evaluation (TNE) Quality Criteria……………………………….…P-1"
  },
  {
    "id": "34fd6e48-111d-4f94-86ce-3a7415c3b17c",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Purpose",
    "content": "The Defence Systems Approach to Training (DSAT) is “is cyclical and flexible and should  be applied intelligently rather than followed dogmatically. Users should select both the activities  specific to their need and the order in which they are applied, to achieve the most appropriate  Training System.” A variety of providers, both internal and external to Defence, supply Training Needs Analysis (TNA) to support Maritime Acquisition projects and programmes. The contexts and structures of pre-existing Training Systems across each capability domain (Air/Land/Maritime) can differ significantly. To ensure intelligent application of the DSAT in Maritime Acquisition and to maximise the chances of successfully introducing a workable Training Solution into the existing Training System, it is important to ensure alignment of expectations between the analyst(s) and the key project/programme stakeholders. This document therefore provides standards which are intended to normalise TNA practice for analysts working in the Maritime domain and are applicable to both internal and external analysts conducting this work. The DSAT is applicable to all training and development activities within the Defence Training System and is therefore necessarily generic and gives options and freedoms in places; this document is deliberately more specific."
  },
  {
    "id": "9cade7aa-8a19-4a31-9dc3-4fd87c8ebe78",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Scope",
    "content": "The standards within this document apply to analysts conducting, or supporting, the activities outlined below in support of Maritime domain Acquisition projects and programmes. Whilst every effort has been made to ensure congruence of this document with the extant DSAT, nothing contained in this document relieves analysts of the obligation to comply with Direction contained within JSP 822."
  },
  {
    "id": "4b817c5a-9098-4637-a853-e4e5abbf0807",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Contracted Analysis",
    "content": "JSP 822 v5, Vol 1 - Introduction states “Where discrete elements of the DSAT process are outsourced to contractors, the  exact requirement should be captured in the contract in order to ensure that DSAT  activities that are undertaken by DSAT SQEP staff, are compliant with JSP 822 DSAT  direction. Outsourcing the provision of DSAT activity to commercial organisations can  be an effective use of resources especially where capability or capacity shortfalls exist  and where time imperatives or the need for concurrency demand it. (p.8) This document is designed to be consistent with the DSAT and to complement Maritime domain contracts for outsourced TNA: the contract will detail what is required to be delivered, whilst this document provides product standards and process standards against which the contracted analysis outputs will be assessed. Contracts may make reference to this document accordingly. All standards contained within this document are applicable to contracted analysis unless they have been explicitly waived or relaxed by the customer and ratified by the appropriate Steering Group. Any such agreed waiver or relaxation should be formally documented, ideally within the contract or associated Statement of Work, verified by both parties (i.e. the Delivery Team and the customer in the appropriate steering group) and copies of the agreement provided to both parties. Many contractual agreements make the payment of the supplier dependent on the 1 JSP 822 v5, Vol. 1, p. 7. customer’s endorsement of analysis outputs. Adherence to the standards within this section is a key criterion for stakeholders in deciding whether to endorse a given piece of analysis work."
  },
  {
    "id": "50587a55-0d54-40f4-96fc-0f5bf71c1c81",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "DSAT Overview",
    "content": "The DSAT is explained in detail in   All analysts working on, or in support of, Maritime domain Acquisition projects and programmes are expected to be fully conversant with the content and application of the DSAT detailed within the extant version of JSP 822."
  },
  {
    "id": "951a84fb-e3d4-45f2-9ac0-5d032f3ffbca",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "TNA Overview",
    "content": "When procuring new or replacement training capabilities, a TNA is undertaken to identify the most cost-effective training solution and fund/deliver the design, development, through life delivery and ultimate disposal of the training solution. The Analysis process is iterative and so with increasing quantity, maturity and granularity of available data deliverables should be reviewed and updated. The process can be broken down into 3 phases (see Figure 1):"
  },
  {
    "id": "7e22fac3-869b-4448-834c-f62b173f0ccf",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "TNA Stage 1.",
    "content": "Scoping Exercise. Initial analysis of the training gap is undertaken and possible training solutions identified. It also defines the management of the TNA, programming and resourcing issues, policies, constraints, risks and assumptions. The key output is the Scoping Exercise Report (SER) which recommends whether further analysis is required or that training is not the solution and the process is not taken forward. TNA Stage 2. Alongside the specifics detailed below, each deliverable should supply a robust audit trail to substantiate its contents and recommendations. This inclusion is key in enabling progressive assurance throughout the TNA process. Deliverable 1 - Role Analysis (RA). This identifies the Role(s) that need to be trained for, the supporting duties, tasks, sub-tasks and task-elements, then analyses these to generate Performances, Conditions and Standards. This is summarised in the Role PS. Deliverable 2 - Training Gap Analysis (TGA). This analyses the composition of the training gap (in terms of KSA). The outputs are the Statements of Training Gaps (an initial draft of the TOs, based upon the Role PS, which are the key outputs. TSGs should be mindful that the TOs are not final. They are representative of the analyst’s understanding and recommendations for training at that point in the project; endorsement of the TGA does not, therefore, render the TOs unchangeable at a later date. Deliverable 3 - Training Options Analysis (TOA). The third deliverable looks at different combinations of methods and/or media which will bridge or partially bridge the training gap. Each method and/or medium is analysed in combination, or independently, for its training effectiveness, cost effectiveness, risk and On-Job-Training (OJT) requirement. The product from this deliverable is a recommendation as to the most cost- effective solution. Deliverable 4 – Training Needs Report (TNR). The Training Needs Report provides the requirement and the endorsed training solution with a draft RPS and FTS, the implementation issues and Training Needs Evaluation (TNE) strategies and the full audit trail to all the previous TNA products. The DSAT process will begin with a State of Requirement (SOR), which states that there is a (real or perceived) need for personnel to have specific KSA due to a new or changed requirement. In the case of new equipment the TNA process is initiated as part of Train activities rather than through a formal SOR."
  },
  {
    "id": "a5c2abfc-50e3-4841-809b-e92ae57a4e19",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "TNA Stage 3.",
    "content": "Training Needs Evaluation (TNE). This assesses and reports on the effectiveness of the TNA process as well as the ability of the implemented training solution to meet the Defence requirement. The TNE is conducted in 2 parts: evaluation of the process, and evaluation of the training solution. The key output is an assessment of how well the TNA outputs contributed to the provision of a training solution that meets the Defence requirement. This completes the TNA process. Figure 1: The TNA Process 3 JSP 822 v5, Vol 2, para 13, p. 53 Adaptability of the Approach. Every TNA project will be different. The TNA approach should be tailored to suit the specific requirements of individual projects but must always provide a full audit trail. The complexity of the TNA should be balanced against the scale of the operational/business requirement. Evaluation of Training Requirement. The most common adaptation of approach is when the change to the operational requirement is small or where there is perhaps no/minimal change to the RPS. Typical examples are equipment updates which result in changes to maintenance routines and, for efficiency purposes, the proposal of alternative learning strategies involving new training methods and media. For these types of capture, an evaluation of training requirement is recommended which replaces deliverables 1 and 2. The training options analysis will then follow. The detailed strategy shall be determined as part of the scoping exercise for each individual project Process Governance. The Training Steering Group (TSG) ensures the validity of the TNA process and outputs. It is a dedicated steering group representing all stakeholders, which manages the TNA via the production and maintenance of a Training Support Plan (TSP). It also provides the governance for advising and endorsing the tailoring of the TNA approach as appropriate."
  },
  {
    "id": "ab9a2829-591c-4f92-9f7f-6ed26fa6e867",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 2: Standards for Scoping Exercise Report (SER)",
    "content": "Purpose. The Scoping Exercise Report (SER) involves initial analyses of the training requirement, identifying possible options for meeting the training requirement and a broad order estimate of the risk and resource implications associated with each option. In addition, SERs will define the objectives of the Analysis, set out its management structure, the timeline for completion and associated milestones. The SER (and substantive stages of the TNA) provide the analysed evidence to inform the timelines and milestones agreed in the TSP. Output. The main outputs of the deliverable are outlined below. Establish/confirm training is necessary and recommend scope of further analysis if required. The articulation of the high-level training requirement. Potential Solutions (training and non-training along with any estimates of initial and through life costs). Project Plan/TORs covering the next phase of the TNA. Note that this requirement is dependent upon the SER’s ultimate recommendations: if sub-paras a-c are addressed without the need, ultimately, for a full Stage 2 TNA, the provision of Stage 2 TORs and parameters is not necessary. Such a finding may not, though, preclude the requirement for a broader project plan. These considerations are important for the DT at the point of contracting – contracting for the Scoping Exercise and the Stage 2 TNA at the same time might potentially bias the SER’s findings to justify the contracted Stage 2. Data Sources. The initial information source will be the Training Strategy document produced by the PT. However, this is a high-level document and more detailed information will be required from Technical Documentation, the programme’s Master Data Assumptions List (MDAL), Risk Register, URD, SRD, CONEMP and Information from other DLODs (Integrated Logistic Support (ILS) studies, Human Factor (HF) or Human-Machine (HM) Interface studies). Methods/Tools. It is important that the SER is not just a data depository and contains analysis and addresses the ‘so what?’. The Analyst should use those tools detailed at the annexes in support of the TNA Development. Format. The common elements of all SERs are detail at"
  },
  {
    "id": "56aa9c15-862d-407e-a483-c666a430190c",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 3: Standards for Role Analysis (RA)",
    "content": "Purpose. Role Analysis (RA) is the process of examining the specific Roles of the Target Audience indicated by TNA Scoping in detail, in order to identify all the component duties and tasks, the Conditions under which the Role is performed, and the Standards to be achieved when performing the Role. Outputs. The main outputs of the deliverable are outlined below."
  },
  {
    "id": "2a9df600-f6d5-4fda-8cfe-81efe07145ca",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Summary of recommendations based on the findings at this stage.",
    "content": "Updated SE. The analyst should review the SE and identify any important information that has changed since any previous analytical work was completed. Target Audience Group Descriptions. The introduction of new capabilities, and replacement or upgraded equipment often affects a cross-section of personnel fulfilling different roles; usually the contexts, and hence implications, for the different role holders vary considerably. The identification of primary and secondary impacts on each role in the target audience is an important factor in decisions concerning where RA activity is focused. Where the target audience identified by TNA scoping includes more than one distinct group, a description of each group and their context should be produced at the outset of RA (unless already produced during scoping, in which case the descriptions should be reviewed and validated), considering: Higher level context, including strategic context, operational doctrine and team/collective scenarios. What is the overall purpose of the role? External context, including wider environment and conditions, for both individual and team/collective, and number of people fulfilling the role. What external factors affect performance of the role? Internal context, such as organisational structures, role dependencies, relationships and responsibilities, and the training audience, throughput and selection processes. What internal factors affect performance of the role? Role Scalars and Role Performance Statements. A role scalar is produced by analysing a role, forming performance statements for the duties, tasks, sub-tasks and task- elements that have to be performed within the Role and recording them diagrammatically. The Role Scalar forms the basis of the Role Performance Statement (RPS) which expands and completes the descriptions of the Tasks and Sub-tasks by including the Conditions the Tasks are performed under and the Standards which they must be performed to. Data Sources. From the outset, Data Maturity must be evaluated and communicated within the TNA. Any associated risks must be formally captured. The following sources of information should be used in RA: Documentation. In order to begin identifying duties and tasks any applicable documentation should be consulted These should include if available (and relevant): CONUSE / CONOPS / Employment, Books of Reference (BRs), Joint Service 4 Extant scalars should be reviewed and updated where possible to reflect any changes and avoid nugatory work (audit trail of any changes is to be captured) Publications (JSPs), MOD / manufacturers’ manuals, Subject Matter Experts (SMEs). Normally the most valuable source of RA data, the most appropriate SMEs are likely to be drawn from role holders (), line managers, trade managers, technical specialists (internal and external) and manufacturers. In some equipment acquisition scenarios, the manufacturer or users outside of Defence may be the only sources of data. Analysts should not be wholly reliant on others to provide them with SME contacts; they should be proactive in seeking, identifying and engaging with as many SMEs as necessary to provide a balanced opinion of issues and potential training options. Although, ultimately the responsibility for providing access to SMEs does reside with the TSG. At every point of the TNA, the Analysts are required to advise the TSG of data maturity concerns. It is not acceptable to knowingly submit deliverables that lack substantiating evidence, without its having been cleared with the TSG beforehand. Methods/Tools. These tools must be used in the development of Deliverable 1: Role Scalar Hierarchy at Difficulty, Importance, Frequency Analysis at Initial KSA Analysis at  E. Quality Criteria. The RA quality criteria are at"
  },
  {
    "id": "aadd0810-1a17-40a3-ba1e-ca639f713d3b",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 4: Standards for Training Gap Analysis (TGA)",
    "content": "Purpose. The TGA identifies the additional training requirement of the affected Role holders by determining the training gap between the Role Performance as stated in the Role PS and the performance achieved by trainees by the end of any existing training solution(s). This analysis also enables obsolete training content to be removed or updated; additionally, the impact upon Defence capability can be assessed if a new or changed Defence capability is implemented without additional training. Outputs. The main outputs of the deliverable are outlined below. Summary of recommendations based on the findings at this stage. Knowledge, Skill and Attitude (KSA) Analysis. Define the additional learning requirements, if any, of the Role holders in terms of KSA at the sub-task and task- element levels. Statement of Training Gap. The new or amended TO’s that define the training gap are documented in a draft TPS (at this stage the training solution is unknown). Data Sources. Accurate identification of Training Gaps is dependent on having both valid RPS and valid TOs for the extant training solution(s). Before starting to derive any Training Gaps, analysts must consult the Training Delivery Authority and/or Training Provider who has custody of the TOs in scope and consequently must determine the validity of those TOs for serving as the basis of further TGA and inform the customer of their findings. If any extant TOs are deemed to be invalid or deficient in conforming to standards required of TOs, further consultation with the analysis sponsor/customer is essential to determine the way ahead. Methods/Tools. The following tools support the development of a TGA: KSA Analysis at Gap Analysis at An exemplar for documenting Training Objectives is at  I. Quality criteria for the TGA are at Annex J."
  },
  {
    "id": "f7c3a22f-888f-40ce-b243-285a270718fa",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 5: Standards for Training Options Analysis (TOA)",
    "content": "Purpose. The TOA analyses the cost-effective delivery, through-life, of the different combinations of methods and/or media which will fully or partially bridge the training gap. Each method and/or medium is analysed in combination, or independently, for its training effectiveness, cost effectiveness, risk and any On the Job-Training (OJT) requirement. The product from this deliverable is a recommendation as to the most cost-effective solution. Outputs. The main outputs of the deliverable are outlined below. Summary of recommendations based on the findings at this stage. Updated SE/Deliverable 1 & 2. The analyst should review previous deliverables and identify any important information that has changed since any previous analytical work was completed. Fidelity Analysis. An assessment of the requirement for the training environment to replicate the workplace (real) environment to enable training to be effective. The product from this deliverable is a recommendation for a cost effective training solution for meeting the identified operational tasks or competences that require training. RPS for the duties and tasks (or competencies) affected by the recommended training option with an estimated Training Category reflecting the shore to sea training split. Formal Training Statement (FTS). A provisional set of Training Objectives in the form of an FTS with supportive notes to amplify OJT requirement to be included as appropriate to assist Training Designers with OJT specifications. This enables changes required to affected DSAT course documentation to be identified. Data Sources. Accurate identification of suitable training options requires an up-to-date knowledge of current methods and media, GFE, synthetic (CBT/CAI) along with their advantages and disadvantages; emerging innovative training technology should also be considered. If synthetic training is considered as an option, it must be compliant with current training, education and simulation policy. Future Training can advise on this. Methods/Tools. The following section is intended to provide the analyst with a range of tools that can be used in support of the development of Deliverable 3. To mitigate the subjectivity of the analysis, the TOA is comprised of 2 fundamental mandatory processes: A Measure of Training Effectiveness (MOTE). A Cost Benefit Appraisal (CBA). This methodology may be substituted with an alternative proposal by the analyst; irrespective of the processes employed, the TOA should never rest wholly on algorithmic findings. The input of the analyst’s reasoned judgement and expertise is paramount. The tools are found out the following Annexes: Fidelity Analysis at The format for conducting MOTE is at TOA quality criteria are at"
  },
  {
    "id": "1fd71e06-0e87-4006-b6d2-d715d15368e7",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 6: Standards for the Training Needs Report (TNR)",
    "content": "Purpose. The TNA process, starting from the Scoping Study, will develop data into a Training Needs Report that specifies the training requirement, the recommended training strategy and the resources required to design and support the training. Output. The main outputs of the deliverable are outlined below. Summary of recommendations based on the findings at this stage. The Methodology used throughout the study. Identification of the Operational/Business Performance Requirement – the RPS/CF for each job holder. Identification of the Training Requirement – the results of the Training Gap Analysis to include Training Objectives with clear Performance statements, Conditions and Standards. Identification of the Training Requirement – the results of the TGA to include Training Objectives with clear Performance statements, Conditions and Standards. The steering group endorsed training solution stated and clearly summarised to enable implementation, to include: The TSG endorsed training solution, resulting from the Cost Benefit Analysis and final selection using the Options evaluation, a statement of the fidelity requirements (based upon the HMI/HCI analysis), associated risks, assumptions and constraints. Implementation plan, including where responsibilities lie e.g. conversion training for new equipment (if applicable) or date of implementation (of legislation and/or policy change), acquisition and setting to work the steady state training solution and course design. At this stage all the new or changed training objectives endorsed by the steering group should be available and expressed as training performance, conditions and standards to enable implementation by the responsible training design team(s). Any recommendation regarding estimation of course resource, timings and assessment should be clearly referenced to aid the training design team. Input to inform or refine the SOTR (for formal endorsement) to focus and direct the design stages. 5 RPS/ICF should be passed formally to P&T, TMG, Training Governance and Assurance (or the relevant organisation) for inclusion into the appropriate document management system such as TAFMIS etc. 6 JSP 822 v5, Pt 2, Para 56 7 Ibid, Para 57. 8 This should be passed formally to the contractor (or the relevant organisation) responsible for delivering the Training Design work under any extant contract such as SELBORNE. An updated Training Support Plan to inform the ILS project plan and support the implementation Plan. Data Sources. No new analysis activities should be introduced at this stage and the Training Needs Report should collate all the information from the Scoping Study and TNA Deliverables adding an implementation plan and TNE strategy. Methods/Tools. There are no tools defined in support of the development of Deliverable 4. Quality Criteria. The TNR quality criteria are at"
  },
  {
    "id": "023fbbdc-945f-4c25-9223-a7d30b0dc427",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 7: Standards for the Training Needs Evaluation (TNE)",
    "content": "Purpose. The TNE evaluates the effectiveness and efficiency of the TNA training recommendation for future reference, regarding lessons learnt and to tailor the methodology accordingly for continuing development. It is intended that the TNE will look separately at the management of the TNA and the solution it proposed. The rationale for this is that it may be many years after the final report is endorsed before we are in a position to evaluate the proposed solution. Implementation and management of the TNE will depend upon the nature of the project, which will have been recommended by the TNA final report. Output. The main outputs of the deliverable are outlined at . Quality Criteria. The TNE quality criteria are at ."
  },
  {
    "id": "fd84a0eb-f671-4e5e-9715-7ff0aa76768f",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 8: Practitioners Issues",
    "content": "Selecting the correct approach. The TNA must be tailored to meet the requirements of a project. The outputs to be delivered from the TNA process should be agreed at the scoping phase and the analysts can then select the correct approach and tools based on the constraints and information available at the time. Analysis should not be conducted as a check list exercise: it uses thought processes and deduction to reach sensible recommendations. Analysis should only be undertaken if it adds value to the TNA. Early setup and consultation with the TGS and its key stakeholder members including TNA QA and TRA will allow the optimum approach to be identified and endorsed. SME/Stakeholder. An SME is an individual who has thorough knowledge of a job, function/tasks, or a particular topic, which qualifies them to assist in the TNA process. Identification and availability. It is important to identify key personnel who can provide SME support to the TNA process. The sponsor must be made clearly aware and agree to provide the necessary SMEs. Those nominated should be made aware of the expectations of that dedicated support. SME support can be drawn from a variety of sources including: Operational Command (end user); policy; organisational headquarters; equipment manufacturer; users of the equipment/system; training staff; training equipment companies; CBT designers. In most cases SMEs are not exclusively tasked to provide advice and support. When collecting data and validating analysis the analyst should consider time, location, and the accessibility of SMEs to make the most efficient use of these valuable resources. Workshops, meetings, e-mails and telephone conversations form the normal correspondence. The selection of SMEs may vary during the different phases of the TNA. Briefing. Sponsors and stakeholders often have a limited knowledge of the management of training and are unfamiliar with the TNA process. At the start of a project, time is often well spent in educating those who are to be involved in the TNA about the process. This is particularly important for those involved directly with the TNA work and the steering group. They must be aware of their roles and responsibilities, including the provision of information and staffing routines. Subjectivity. The analyst should evaluate SMEs’ input, taking unconscious biases into account regarding existing capabilities, SOPs and ways of working. Cost Benefit Analysis. Costing and investment appraisal are superficially easy but have many pitfalls for the uninitiated. Their techniques are beyond the scope of this manual. It is important that costing and investment appraisal are undertaken strictly in accordance with the current policies. Presentation of TNA findings. It is important that the work and analysis that has been conducted is presented effectively. Analysts need to be able to articulate their findings on paper and orally at the TNA steering group. The written report(s) should be concise, follow a logical sequence and present a robust argument with supporting evidence. The ability to be able to articulate the options to the steering group and explain the implications of selecting different options is key , so that a clear understanding of the various training solutions is established. Iterative Nature of TNAs. Whilst a TNA is carried out by completing a number of stages in a linear sequence, it is important to remember that the process is essentially iterative and aims to include all supporting data, completed stage reviews and all assumptions that have been justified. It is vital at every stage of a TNA for the outputs to be reviewed to ensure their continuing validity, and appropriate stages of the process repeated if necessary."
  },
  {
    "id": "60aad435-f068-4013-8277-379417b90830",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Section 9: Training Points of Contact",
    "content": "For specialist training advice on DSAT and Royal Navy Training, the following can provide further information:"
  },
  {
    "id": "e57ea520-226d-41f3-a5c0-a8b22ead9c16",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "People and Training Directorate (P&T) (2* Area), Deputy Director People Strategy (DDPS) (1* Area), Future People Capability (FPCAP)/Future Training (FT) (OF5 Area).",
    "content": "Sharepoint page (with PoCs and Organisational Diagram) Future Training within P&T can provide advice and consultancy to project teams within the delivery agents via the MTAO team. Future Training also own the TNA QA (AW and SM team) who will conduct the quality assurance of the TNA work. It should be emphasised that the focus of the output of P&T is individual training (as described in Pt 1 of the MATG) but MTAO are able to offer advice and consultancy on DSAT broadly (individual and collective) as RN Training Managers."
  },
  {
    "id": "f9304aba-5403-44be-ac51-8332d6dd599a",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Director Force Generation (Dir FGEN) (2* Area), Commander Fleet Operational Standards and Training (COM FOST) (1* Area)",
    "content": "Information and discussion related to Collective Training should be addressed to COM FOST Chief of Staff (COS) who can then direct to key PoCs in FOST Ships or FOST Submarines. As stated above support and advice/consultancy can still be sought from Future Training. The majority of TRAs for the Royal Navy can be found within the following organisation:"
  },
  {
    "id": "121d38e5-a0e6-46c4-9db0-ac76cada8a72",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "P&T, DDPS, Workforce Planning and Talent (OF5 Area)",
    "content": "9 In particular JSP 822 v5, Vol 2, Pt 3, Para 56, p.32. 10 Submarine Individual Training Coherence Organisation (OF5 Area) is due to be established in April 2023 and Future Training/MTAO SM team will form part of this team. Contact details can be obtained via the FPCAP/FT Team as required. Workforce Planning Teams/Branch Managers act as the TRAs for most RN individual training. The TRAs for Collective Training can be contacted via COM FOST with details at the ."
  },
  {
    "id": "443ac626-d8d3-4d1a-abf4-df75e833b1fd",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "SCOPING EXERCISE REPORT (SER)",
    "content": "There are some common elements of all :SERs: Summary of Requirement. Analysts should have a sound understanding of the new/changed capability that is underlying the SER and its key elements, particularly those that will impact on training; refer to the CONEMP where available. Aim of SER. Analysts should ensure that there is a clear understanding of the aim of the SER, i.e. first, to confirm training as a necessary component to the successful integration/maintenance of the capability in question. Second, to conduct one or more initial analyses of the training requirement and, where applicable, suggest possible options for meeting the training requirement and make a broad order estimate of the risk and resource implications associated with each option. Normally, confirmation of training as a necessary component of the capability is dependent on analysis of the training requirement and analysts should be aware that there may be an initial indication that training or changes to existing training is required that could be found to be in error based on more detailed analysis. Guidance on the Conduct of SERs. It is imperative that clear guidance has been provided for the conduct of the SER. A considerable amount of resources may be required to carry out the SER and these should be detailed clearly within this guidance, which should include: The scope and size of the SER task. Methodology of the SER. If it does not follow the guidance provided in this manual, it should be stated where any differences apply and identify any additional source reference documents that are to be used to inform the way the SER will be conducted. Deliverables and reporting procedures. Timescales and milestones associated with delivery of the capability. Resource Requirements. The SER should highlight what resources it requires in order to proceed. These would normally include (but not limited to) access to Subject Matter Experts (SMEs) from MOD and industry, access to MOD and industry facilities, access to technical documentation, access to concepts and doctrine, access to legacy training solutions and facilities. Analysts should not be wholly reliant on others to provide them with SME contacts; they should be proactive in engaging with as many SMEs as necessary to provide a balanced opinion of issues and potential training options. SER Planning. Analysts should plan SER and further analysis activity at the outset. It may be useful to include a draft plan with timelines for when deliverables will be complete, what deadlines they are working towards, and what they will contain. It should also include any known constraints on the plan in terms of resources and availability of key personnel, release of documents, witnessing key events / trials, etc. SER Management Structures.\tIdentification of the management structure, including key stakeholders and approval authorities is essential for SER success. This will normally be defined by ILS methodology (for acquisition related projects coordinated 11 Subject Matter Expert (SME) – an individual who has thorough knowledge of a job, functions/tasks, equipment or a particular topic (e.g. training), which qualifies him/her to assist in the training development process (for example, to consult, review etc.) through DE&S, normally under a Project Team umbrella) or by the applicable CEB. In either case, the SER will most likely be managed and overseen by a TSG that will be responsible for ensuring that it is completed on time and that content is endorsed by all members. It is not essential that the TSG formally sits, and it is possible for decisions to be made ‘virtually’ out of committee. The TSG should consist of applicable DLoD representatives, all of whom should be consulted when producing SER outputs and prior to its distribution for endorsement. The analyst is accountable to the TSG and responsible for delivery of the SER products as agreed by the TSG. TSG members are responsible for representing the views of their organisations and are to ensure that any issues have been staffed to an appropriate level prior to being addressed in committee. Stakeholders.\tPossible stakeholders that will probably form the TSG are detailed below:"
  },
  {
    "id": "2a55e0d9-456c-4805-a338-3b4fe00d1825",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Endorsing Members:",
    "content": "Chair. This should be the person sponsoring / commissioning the high level SER. Could be from either Mil (Cap), but normally delegated to the PT. Also represents the training Equipment DLoD. Training Requirements Authority (TRA). Often the Branch Manager or Workforce Planning Team lead. If multiple TRAs then a lead should be nominated. Front Line Command (FLC) Capability Area Representative. Representing the User of the capability. Training Capability Manager. Representing the in-service space. Future Training TNA QA. SM or AW SO3 TNA QA as appropriate."
  },
  {
    "id": "20b9a6c9-980f-43e7-bf21-1c6868a9d58f",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Other key stakeholders can be added as required to the membership of the TSG including, these aren’t necessarily going to be endorsing members:",
    "content": "Delivery Agent Training DLoD Integration Authority. Ensures coherence with training acquisition guidance and assesses impacts on existing training solutions and infrastructure. Industry. At the Chair’s discretion if contracts have been let. Could be prime contractor and / or training solution / Analysis contractor. Training Deliverer. From training stream / lead school to represent the training Information and Training DLoDs for instructor and training design issues. Collective Training Representative. As required."
  },
  {
    "id": "bce447ed-1db4-42f5-b68f-6e4e3d248a8b",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Other DLOD Representatives as Required.",
    "content": "SMEs. As required. It should be noted that many SMEs may not have experience of the new capability, but will have experience of similar legacy capabilities. Assumptions, Constraints, Risks Issues and Dependencies (ACRID) Capture. A key component of project management is the identification and impact analysis of 12 JSP 822 v5, Vol. 1, Para 12, p. 14 Assumptions, Constraints, Risks, Issues and Dependencies (often abbreviated to ACRIDs) that affect the project. Assumptions are those factors which are assumed to be true, but which have not yet materialised or which are not yet confirmed in detail. Constraints are those factors which are known and which have a limiting effect on the project. Risks are defined as uncertain future events that could negatively or positively affect the organisation’s achievement of its objectives, partly or completely. Issues are a certainty. It is an event that has already occurred, something that is known and certain to occur, and will affect the organisations ability to achieve its objectives. If the effect is uncertain, it is not an Issue and should be managed as a risk. A Dependency is a logical relation between two things where the second thing depends on the first. So, for example task where one task cannot be done until a preceding task has been. Dependencies can always be identified and often can and should be tracked. Project dependencies are task dependencies in the context of a project. The need to set up, maintain and circulate a register of ACRIDs during the TNA process is essential and these must be reviewed and updated regularly by the TSG as as the TNA progresses. These need to be considered at different levels of applicability, i.e. to the TNA, or to the Project, or to the Programme, or even to the Enterprise and escalated if necessary. Assumptions and Constraints.\tAssumptions and constraints could arise from a variety of factors, including policy, legal requirements, career structures, infrastructure, existing training capability, acquisition decisions, MDAL assumptions, URD and SRD requirements, CONEMP/CONUSE /CONOPS guidance, etc. Analysts should also identify potential constraints to what cannot be achieved in certain methods of training, which may eventually inform a RTGS, e.g. firing of live weapons against enemy targets, excessive violence by/against trainees, environmental legislation, duty of care regulations, full sensory immersion, health and safety legislation, availability of assets, financial cost, political sensitivities, host nation support for training exercises, etc. Both assumptions and constraints may apply to the actual conduct of the Analysis and the training solution recommendation.. It is important that the SE analyst identifies these two types, and ensures that the formers’ impact on the latter is managed effectively. Project assumptions and constraints must be captured and provided for endorsement in the SE report(s). This is best achieved through the use of an assumptions register, which should be integrated with any wider project MDAL, or similar, to avoid duplication of effort and to maintain the Training DLoD as integral to the wider project it supports. SER assumptions and constraints should also be identified on project TORs, highlighting possible impacts on the SER’s accuracy. Analysts should summarise key assumptions and constraints: Assumptions made about the training Target Population (e.g. what experience level and therefore rank of maintainer and operator will be required, 13 This may also be referred to as RAIDO – (Risks, Assumptions, Issues, Dependencies and Opportunities). 14 A statement of any assumptions being made in support of the Training DLoD for inclusion in a Master Data Assumptions List (MDAL). This will enable de-confliction of assumptions made across DLoDs and help justify commitment of resources in support of training. etc.). Assumptions made regarding training throughput (e.g. average appointment lengths, any need for spare throughput capacity, etc.). Assumptions made on when training is required to start, finish and how often it may be required, including whether an interim solution is required (e.g. will a contractor be needed to provide interim training whilst the steady state solution is developed?). Assumptions made on training location, particularly resulting from policy guidance. Assumptions on how to deliver training, including any policy/concepts and doctrine guidance. Assumptions on whether training will need to be integrated into existing training solutions (e.g. existing simulators/trainers, etc. – this could be a significant cost). Assumptions on what will need to be trained, drawing upon the CONEMP (can also be very high level, e.g. maintainer training/maintenance managers / operators / command appreciation, etc.). Training Risk Management.\tThe underpinning rationale for UK Defence training is to only provide that which is essential – hence the importance of properly defining the training requirement through the Analysis phase of DSAT. Because SERs will often be conducted with limited resources and to timescales that may preclude full analysis, it is crucial that the process identifies and manages risks inherent in both the project’s approach and the training solution(s) being offered as potential options. In terms of risk and opportunity identification, the most obvious source of information is the assumptions and constraints data. It is imperative that the MDAL, or similar, relates to a risk register. As with assumptions and constraints, the training risks should be integrated with the wider project risks to avoid duplication of effort and to maintain the Training DLoD as integral to the wider project it supports. Additionally, larger projects may have specific risk management staff, rather than relying on Training DLoD or SE personnel with limited risk management experience."
  },
  {
    "id": "fc00384f-cf6e-444d-9572-a0f057d195e8",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Risk identifier / title.",
    "content": "Risk Category. Used as a method of grouping similar type risks (e.g. ‘Resource’ or ‘Finance’). Risk Description (Cause, Event, Consequence). Details of the risk including the cause, risk event and consequence (best practice is to use three separate fields). Risk Owner. The person with the authority and resources to enable effective assessment and management of a risk. Probability. Qualitative or quantitative (percentage) measure indicating the likelihood of a risk occurring; both pre-response and post-response estimates should be recorded. Impact(s) (Typically Time, Cost and Performance). For quantitative assessment, the criteria (e.g. high, medium, low) should be defined in the Risk Management Plan, for qualitative assessment specific estimated values are chosen; both pre-response and post-response estimates should be recorded. Response Action. Description of the response including the Action Owner (person responsible for ensuring the mitigation is implemented), and the planned start and finish dates for the action. Fallback Plan. Responses to be implemented if the risk occurs, and the point when the decision to implement the Fallback Plan needs to be taken (if before the risk might occur). Analysts should summarise key risks (including opportunities). A more detailed list of risks should be presented in a common format with the project’s Risk Register. At a minimum, analysts should consider the following training risks to: Risk to military capability and effects of not having a training solution ready in time to meet In-Service Date (ISD). Impact of not having a training solution adequately resourced through life of the capability. Being unable to articulate training requirements in time to inform training solution design. Training requirements articulation, design and development through unavailability and/or immaturity of key information. Personnel structures through inappropriate training and/or lack of throughput capacity. Doctrinal development and validation through training not capturing doctrinal requirements. Organisations (especially FLC) if training is inadequate or not appropriately resourced. Training infrastructure (including existing training solutions) of ability to adsorb new training solution. Logistics support activity through inadequate training. Findings – Potential Training Gap. It is important that the SE is not just a data depository and contains analysis and addresses the ‘so what?’ Articulation of potential training performance requirements for the capability and its training solution need to be established. Before examining them in detail from a training perspective, it is crucial that the questions are first approached in terms of ‘who’ will be performing the capability and ‘what’ will that capability require in terms of human job/role performance. Analysts should consider the following performance criteria: What is the nature of the performance expectations of individuals and teams involved with the delivery of the capability? Who may need to be trained; individuals, sub-teams, teams and collective? Potential annual training throughput if possible (this should also inform Statement of Trained Requirement (SOTR) analysis). What elements of the performance expectations may need to be trained? When training may be required to begin, is an interim solution required, how long will it be required for, and how frequently will it be required (including continuation training)? Where could training be delivered? e.g. Training Establishment, workplace, contractor’s premises, online, etc. How should training be delivered? What are the potential options? What is the policy direction? What are the impacts on existing training solutions? Depending on the maturity of applicable doctrine and concepts, it may even be possible to provide a very high level overview to show what job/role tasks will need to be trained. Is this likely to change through life – e.g. changes to equipment and doctrine may require changes to training? Analysts should estimate what the gaps are between what training is delivered now and what will be required for the new capability. It could be cheaper and less risky to integrate new training into existing training capability, but this assumes the current training meets the new requirements. In particular, analysts should consider the following points for each individual/team/collective target audience: Is current training (including any underpinning career training/education) fit for purpose and effective? Will current training meet the doctrinal requirements of the new capability? Is current training funded to continue over the life of the new capability? Does current training have throughput capacity for the new capability? What is the TE/workplace training balance, is this appropriate and cost effective? Findings – Potential Training Solutions. Analysts should summarise existing training capability applicable to the project for the following reasons: Where a new capability is replacing an existing capability (e.g. a navigation radar), it is useful to understand how efficient and effective the existing training is so that requirements for its replacement can be set to improve upon it. These may focus on such criteria as reducing course lengths, increasing course capacity and frequency, improving TPS levels and reducing workplace training burden in the front line, reducing instructor numbers, and lowering costs of training to the MOD. Is there an impact on existing training systems? The MOD has invested heavily in large training systems (mostly team training systems) which are likely to require modification to incorporate the new capability being analysed. Modification to these systems will normally be on the ‘who changes pays’ basis for which funding should be provisioned. Any modification must also be carefully planned to ensure minimal disruption to legacy training provided by that system. It may prove less expensive and risky to modify an existing training system to incorporate training for a new capability than procure a new one. Policy may direct you to incorporate training into an existing training capability or deliver in specific locations. Analysts should identify potential training solutions that could meet the potential training and fidelity requirements for all those identified as part of the Target Population (individual, team, collective). It is likely that a combination of training media may be appropriate to address discrete elements of the training gap, e.g. CBT/CAI for knowledge/mental skills, Part-Task Trainers for physical skills, simulation for tactical/doctrinal exploitation and team training, etc. Consideration should also be given to workplace support tools, mobile training tools, and enhanced Interactive Electronic Technical Manuals. Analysts should identify all known existing and planned training systems that will potentially be affected by the new capability. Generally, this will apply to the larger scale team training systems (e.g. Maritime Composite Training System (MCTS), Submarine (SM) Command Team Trainers, Bridge Simulators, SM Manoeuvring Room simulators, Combined Arms Tactical Trainer (CATT), Command And Staff Trainer (CAST), Mission Training through Distributed Simulation (MTDS), Dismounted Close Combat Trainer (DCCT) etc.) in which the MOD has invested significantly. The value of these training systems will be jeopardised if they do not keep pace with new capabilities being introduced into service, and on the ‘who changes pays’ basis, it would be the responsibility of the new capability sponsor to fund any change to existing training solutions to incorporate the new capability. Training Resource and Cost Estimates.\tIt is not possible to generate cost effective and optimised training without an understanding of the resource requirements of a given training solution. There may be many ways to generate a training effect and it is essential that the SE begins the process of rationally justifying why a specific training solution is preferred. Similarly, there is no point Defence committing to a given capability solution unaware of the training impact required to deliver that capability. Analysts should estimate potential WLC to defence of the Training DLoD in order to ensure sufficient funds are allocated. Estimates should include costs which could arise from factors such as the ones below, as well as an indication of whether these are EPP or ESP funded items. Any assumptions made regarding cost sources must be annotated in the MDAL, similarly any cost risks must be identified in the Risk Register. 15 Analysts should always consider the ‘do nothing’ option and highlight any risks to capability and subsequent costs that this will present. Audit Trail.\tIt is essential that an accurate audit trail is kept of all documents referred to, all key e-mail and telephone correspondence, and all relevant meetings attended. These should be annotated as footnotes to the respective piece of text to validate its accuracy and add credibility to the analysis. Iterative Review. Analysts should review any previous analytical work and any additional pertinent documentation. The iterative review will also provide analysts with the opportunity to identify any important information that has changed since any previous analytical work was completed."
  },
  {
    "id": "cc147acb-d2ce-40af-a692-c7a44fe0da79",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "ROLE SCALAR HIERARCHY",
    "content": "Duties. Duties are the major functions, or areas of responsibility, of the Role. They have no specific start or finish and tend to be general in nature. A duty may be common to more than one Role. For complex Roles, or when analysing groups of Roles that share Duties, it may be necessary to apply more than one layer of Duties to build a meaningful Role Scalar; this is permissible where warranted. The Scalar numbering system should be adjusted accordingly to ensure consistency with the RPS. Tasks. Tasks are the fundamental building blocks of a Role. A task is: A specific action Performed by an individual. Recognised by a definite beginning and an end. Performed for a relatively short period of time (could be hours but rarely days). Observable and measurable. Sub-tasks. Subordinate Tasks, usually referred to as ‘Sub-Tasks’, are the component parts of a primary task. Typically, they are carried out as part of a primary task, but not for their own sake. Depending on the nature of the primary task, there may be a variety of sub- tasks at various levels within the hierarchy, with some sub-tasks subordinate to other sub- tasks. Task Elements. Task elements are sequenced step-by-step component of a sub- task. Where there is a need for a Process Standard for a Task but no such standard is laid down in a referenced publication, Sub-tasks and Task Elements may be used to construct a Process Standard within an RPS. The usual convention for levels in a Role Scalar is shown below in Figure 2. Note that use of Task elements should be minimal and only where justified; Sub-Sub-Tasks will carry through to the RPS and should therefore usually be used instead. Figure 2: Role Scalar Role Scalar numbering system. It is important to employ a hierarchical numbering system within a Role Scalar, as often it is cross-referenced to other training documentation. The numbering system should indicate the level and relationship of the particular components of the Role. An example of a numbering system is shown in Figure 3: Figure 3: Role Scalar Numbering System If changes to an extant RPS are being considered, analysts should investigate and take in to account the impact of any changes upon cross-references to the extant Role Scalar(s) from existing training documentation. This should normally include consultation with the custodian(s) of such training documentation."
  },
  {
    "id": "6e163f75-282e-472d-8455-375b83a4512a",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "DIFFICULTY, IMPORTANCE, FREQUENCY (DIF) ANALYSIS",
    "content": "Every Task should be analysed for its respective DIF. It should not be assumed that Sub- Tasks will share the same DIF profile as their parent Task, or other Sub-Tasks of the parent Task. Sound DIF analysis requires analysts to consult a suitable range of SMEs to get as balanced as possible a view of Task and Sub-Task difficulty, importance and frequency, and their respective discriminators. Table below should be used as criteria to discriminate between the levels of difficulty, importance and frequency for each task. When DIF analysis includes multiple participants, disagreement and debate is normal and is usually very constructive. Once consolidated difficulty, importance and frequency conclusions have been reached for each Task and Sub Task should be taken forward to generate preliminary Training Categories for that Task/Sub Task using the algorithm in the table below. Variances between SME views should be resolved before calculating the provisional Training Category; it is not acceptable to calculate a set of provisional Training Category numbers and then use the average number as the provisional training category. Detailed records of DIF analysis, detailing intermediate scores, variances between SME views and how significant disagreements were resolved, should be kept by the analyst(s) and made available to the customer/sponsor. Figure 1 - DIF Analysis Definitions"
  },
  {
    "id": "d7f84b30-f972-42fa-a26b-feb453b2e0b9",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Figure 2 - DIF Analysis Algorithm",
    "content": "18 JSP 822 v5, Vol 2, Pt 3, para 32, p. 25"
  },
  {
    "id": "73115a70-6049-42b6-b809-9ad8e1354b98",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "KNOWLEDGE, SKILL AND ATTITUDE (KSA) ANALYSIS",
    "content": "KSA analysis is systematic analysis of Performance, Conditions and Standards in order to identify the necessary KSA required to perform a Role. A KSA Analysis moves on from what the Role holder does (captured in the Role Scalar), to identifying the KSA that have to be learned to successfully perform the task. The results of a KSA Analysis contribute to the generation of TOs and EOs, judgement of the most cost-effective Training Options and the selection of the most appropriate training Methods & Media. Judgement should be applied to ensure large swathes of trivial KSA are not listed and that KSA are identified with a suitable level of precision to enable the development of performable TOs/EOs. For example: claiming a necessary procedural skill is ‘apply basic Mathematics’ is imprecise; ‘apply Ohms Law’ or ‘resolve speed/distance/time problems’ is more precise and hence far more useful for TO/EO development."
  },
  {
    "id": "bf8c93b3-11fa-40c6-9f15-419f293f1a02",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "KSA Categories",
    "content": "KSA can be divided into the following categories and sub-categories, combinations of which may apply to each Role PS task being analysed. Underpinning Knowledge. The Knowledge required for successful Task completion should be categorised as: Factual Knowledge. The basic elements that performers must know to be acquainted with a discipline or solve problems in it, which could include knowledge of: Terminology. Specific details and elements. Conceptual Knowledge. The interrelationships among the elements within a larger structure that enable them to function together, which could include knowledge of: Classifications and categories. Principles and generalisations. Theories, models and structures Procedural Knowledge. Knowing how to do something; methods of inquiry, and criteria for using skills, algorithms, techniques and methods, which could include knowledge of: Subject-specific skills and algorithms. Subject-specific techniques and methods. Criteria for determining when to use appropriate procedures. Underpinning Skills. The Skills required for successful Task completion should be categorised as : Physical Skills. Organised and co-ordinated patterns of mental and/or physical activity. Physical skills may be built up gradually by repeated training or practice and can include: Accurate, co-ordinated physical movements. Consistent in physical actions. Smooth, fluid and rapid physical actions. Perceptive Skills. Using the senses to obtain cues that guide performance, which could include: Developing a mental image of an environment. Developing an awareness of an environment through physical sensation. Developing visual recognition/proficiency. Procedural Skills. Using physical and practical skills in order to accomplish a specific and well characterised technical task. Complex Response Skills. The skilful performance of motor acts that involve complex movement patterns. Proficiency is indicated by a quick, accurate and highly coordinated performance, requiring a minimum of energy. Adaptation Skills. Skills are well developed and the individual can modify movement patterns to fit special requirements: Responds effectively to unexpected experiences. Modifies instruction to meet needs of learners. Perform a task with a machine that it was not originally intended for that purpose. Origination Skills. Creating new movement patterns to fit a particular situation or specific problem. Learning outcomes emphasise creativity based upon highly developed skills. Constructs a new set or pattern of movements organised around a novel theory or concept. Develops a new and comprehensive training program. Underpinning Attitudes. The attitudes required for successful task completion should be categorised as : Openness to experience and willingness to hear. Willingness to react and participate actively. Ability to attach values and express personal opinions. Ability to reconcile internal conflicts and develop value system."
  },
  {
    "id": "d50d2496-b9d0-41c8-a6d5-4e30f17d2df3",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Figure 1- KSA Analysis Example",
    "content": "19 JSP 822 v5, Vol 2, Pt 3, para 32, p. 27"
  },
  {
    "id": "5d26433c-0e2c-4636-9a65-845957c7b32b",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Task Structure.",
    "content": "Tasks are comprised of 3 components, as shown in the table below: Figure F-1 Task Components Tasks are the fundamental building blocks of a Role and much of the necessary detail used in subsequent stages of TNA, and to then develop training, is contained within them; it is therefore essential that the Performance, Conditions and Standards identified in the RPS reflect the realities of the Role. ‘Reverse engineering’ of Tasks from existing or desired training content is never acceptable."
  },
  {
    "id": "906de806-38ee-4bce-b16b-bed029c8f0ae",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Writing Performance Statements",
    "content": "The Performance statement, the first of the three components of any task, is a clear, concise statement of the performance required. It represents a logical and complete part of a Duty within a Role, and is observable and measurable. A properly constructed Performance statement answers the question ‘what does the Role holder have to do?’ It must be a single statement containing an action verb, the object of the action and any necessary qualifier as illustrated in the table below. The choice of verb for the Performance statement is critical. Verbs such as ‘know’ or ‘understand’ do not adequately define an action on the part of the member and are not observable or measurable. ‘Diagnose’, ‘assess’, ‘select’, ‘identify’, ‘distinguish’ are much more readily witnessed and can be assessed more easily. The table below illustrates examples of good and poor practice in task performance statement writing: Figure F-2 Task Performance Statement Writing Often the Performance statement of a Task (without Conditions or Standards) is necessary and useful in its own right (i.e. when producing a Role Scalar). However, the task is only complete when all components (i.e. Performance, Conditions and Standards) are present. In RA, the content of Tasks may develop or be refined as the RA continues and as the information available matures; this is very likely to happen in Acquisition projects as they progress through the CADMID cycle. Where all or part of any component of a Task is not yet known, the ‘known unknown’ information should be indicated and the Task(s) should be identified clearly as being ‘draft’ or ‘provisional’. In addition, the Task Performance statement should include the following elements: Figure F-3 Task Performance Elements"
  },
  {
    "id": "0fa6ff87-72da-44bc-8a67-c9528858890c",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Specifying Conditions",
    "content": "Conditions statements describe the situation under which the action specified in the performance statement must be completed. Conditions statements are often written in terms of what will be ‘given’ (available to) or ‘denied’ (not available to) the service member while performing the required task and in what environment the task will be performed. Conditions should reflect the work situation as accurately as possible, but include only those factors that influence job performance: An exhaustive list of every trivial condition is not necessary and detracts from the value of the RPS. Conditions that do not impact on Task or Sub-Task performance do not require statements. Since the Conditions may be critical in determining future Training Gaps, informing training design and helping to justify resources, they should be documented as accurately and closely as possible to the actual conditions in the workplace. Each Task and Sub-Task must therefore have a full Conditions statement clearly linked to its Performance statement (not a key to a list of Conditions located elsewhere). It is recognised that Sub-Tasks will usually (although not always) share identical Conditions to their parent Task. In such cases it is not necessary to repeat the full Conditions statement; instead, having checked and confirmed the commonality, a positive statement linking to the Conditions of the parent Task may be made (i.e. for Sub Task 1.3.1: “Conditions as per Task 1.3”). Conditions: Good practice. While customers in other domains may prefer Conditions to be analysed at the Role or Duty levels, in the Maritime domain it is expected and required that Conditions are analysed and recorded specifically at the Task and Sub-Task levels. A set of generic ‘blanket’ Conditions covering all eventualities is not acceptable. The tables below illustrate examples of the use of various types of Conditions."
  },
  {
    "id": "5f20eb02-8ff2-4db6-a0aa-59a02e12bfb5",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Specifying Standards",
    "content": "Standards statements indicate the required level of performance by describing how and how well the performance statement must be completed. Valid standards are based on actual job / workplace requirements that are both specific and clearly written. Standards statements indicate the acceptable level of performance to all concerned: trainees, designers, instructors, units and command authorities and as such, they will provide direction for the scope and limits of the training. Standards statements are used to: Define the desired level of performance from an end user perspective. Identify individuals who can satisfactorily perform the task and those who cannot. Indicate to designers and instructors the level of proficiency which trainees must eventually attain. Accurate Standards are required for the subsequent design of relevant and valid assessments. It is therefore imperative that Standards statements reflect actual Role requirements: they must be neither arbitrarily demanding nor too easy. If Standards are too demanding, they may reflect an unrealistic ideal, and generate unnecessary training costs. If Standards are too easy, trainees may not achieve the required capability to carry out their Role responsibilities. Standards: Good practice. While customers in other domains may prefer Standards to be analysed at the Role or Duty levels, in the Maritime domain it is expected and required that Standards are analysed and recorded specifically at the Task and Sub-Task levels. A set of generic ‘blanket’ Standards covering all eventualities is not acceptable. Three types of Standards can be used, as described in the table below."
  },
  {
    "id": "64f9efaa-2c28-4d5f-87e3-9b60966f6050",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Types of Standards",
    "content": "Referencing Standards within other documents. Where auditable official publications detail relevant Standards it is valuable to refer to these in the RPS; this prevents contradictions and keeps the RPS to a workable size. When referring to other publications, analysts are to consider the purpose of the RPS as the basis of subsequent work to develop training: the guiding principle should be to assist the next user of the document to find the information relevant to the Standard(s) quickly and easily. Therefore: Whilst it may be convenient to the analyst to use a key to refer to a ‘master list’ of reference publications, this can be very inconvenient and difficult for a training designer or other user to follow and use and therefore this is considered poor practice. The analyst is expected to check any reference publication(s) cited in Standards to confirm that a relevant Process, Product or Combination Standard is actually present within the document. Judgement must be applied in the level of detail given in each reference. For example, JSP 440 is a very large document comprising 8 multi-section Parts and Supplements. Stating “in accordance with JSP 440” therefore gives the next user an unacceptable burden to trace the detail of the Standard. As a baseline expectation, the relevant Publication, Volume/Part and Chapter(s) should normally be specified in every Standard. Publications referenced within Standards should be chosen to avoid variability: i.e. ‘in accordance with Unit Standing Orders’ leaves open the possibility of variation between Standing Orders of different units, and therefore should be avoided."
  },
  {
    "id": "f4ee84fb-7357-4b08-9b62-00fea1969b63",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Prioritisation of Training - Training Categories",
    "content": "A thoroughly conducted RA will be wide ranging and will consider levels of supervision, work conditions, difficulties and distastes, frequency of task performance, percentage of personnel performing the job, likely job changes and consequences of inadequate performance. All of this information, in conjunction with information on trainee entry standards, trainee throughput and knowledge of the likely training environment, can lead to conclusions regarding the balance between formal training course and workplace training. These conclusions should be expressed through the use of training categories, summarised in the table below. Training Categories are designed to give an indication as to where the training should take place and to what fidelity it should be delivered. They should provide a basis for any balance of investment decisions affecting training and inform the judgement of risk related to trade-offs within the training solution. Figure F-4 Training Categories The main analytical tool already used to derive training categories is the Difficulty- Importance-Frequency (DIF) Analysis. This technique involves looking in some detail at the nature of the job in terms of the Difficulty, Importance and Frequency of Tasks and Sub-tasks (DIF Analysis) and then considering what would be required to provide in order to adequately prepare an individual to perform the Tasks and Sub-Tasks. At this stage of the process, the DIF is more an indication of a ‘training priority’, this will be transitioned into a firm Training Category during the TOA stage. 20 JSP 822 v5, Vol 2, Pt 3, para 32, p. 28"
  },
  {
    "id": "adacda0d-7e38-4f74-a73a-4ab866991251",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Comparison of Newly Generated and Extant Role PS",
    "content": "It is common for a Role PS to be produced for an existing capability that has had a change in equipment, scope or complexity. It then becomes necessary to conduct a comparison between the newly generated Role PS and any extant documentation (OPS/RPS). This process is conducted to enable the analyst to select new or amended Tasks to take forward to develop into TOs in the TGA, and to delete obsolete Tasks and any material that supports them (which will have an effect on any existing TO’s that are taken forward into the new training documentation). The first step in this process is to identify Tasks which are no longer required from the old documentation and ensure that the training conducted to support them is removed from the dependant training documentation. The second step is to identify any tasks that do not alter. This should be done by comparing the Performance Statements as well as the Conditions and Standards for each one. Only when all three remain unchanged can a Task be pulled straight through to the new documentation along with any extant training that supports it. Finally, all tasks that are either new or amended should be carried through to the TGA to have KSA analysis conducted on them in order to develop TOs (also in the form of Performance, Conditions and Standards)"
  },
  {
    "id": "a52c669d-0870-43a5-8b0b-749fac15825a",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "DESIGNING NEW TRAINING OBJECTIVES (TOS)",
    "content": "Training Objectives ensure that the training activity has a definite purpose such that the Role Performance needs will be met. They help ensure that the associated trainers, support staff and trainees have a clear understanding of what the trainees are required to be able to do by the end of training. TOs form the basis of the detailed design of each of the training events as well as underpinning the identification of appropriate training resources. They may also be used in support of the award of civilian accreditation. TOs are precise statements of what a trainee should be able to do after training. A TO is measurable and has three constituents: the Performance required, the Conditions under which the trainee must perform and the Standard to which the trainee must perform (see table below). These statements must be in the form of observable and measurable behaviour which allow the achievement of the TOs to be confirmed through assessment. Figure I-1 Training Objective Components A TO defines what a successful learner is able to do at the end of a period of training: at the end of a lesson, series of lessons, or a course or training activity. It does not describe the learning process or any learning experience. Assessment of a TO should consist of the trainee performing the TO under the given training conditions and to the required training standards. Therefore, when complete, a TO must make sense as a precise instruction to a trainee."
  },
  {
    "id": "b6e40488-286c-4de7-ab68-a6343e5fd4b8",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Writing TO Performance Statements",
    "content": "The performance statement of a TO states what a trainee should be able to do at the end of training and should be derived from the corresponding task from the Role PS and therefore has an action verb as the first word in the performance element. Good practice in writing Task Performance statements is equally applicable to writing TO Performance statements. It may be feasible and useful to replicate the Performance Statement from the Task when this is what will actually be performed in training; however it may be necessary in some cases to break a Task Performance statement down in to a set of constituent training objective Performance statements. As a result the number of TOs generated would usually be expected to be equal to or greater than the number of Tasks in scope. TO Performance Statements should never be written at a less precise level than the Task they relate to as significant details from the Task will be lost. ‘Reverse engineering’ of TOs from existing or desired training content is never acceptable."
  },
  {
    "id": "229d552f-a900-403c-a661-20905f49b1c7",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Specifying Training Conditions",
    "content": "The conditions statement of a TO, specifies the actual conditions, or circumstances, within the training environment in which the TO will be carried out. In training, the ideal solution would be to provide the same conditions normally experienced in the Role. However, this is not always possible or cost effective so the conditions statement must clearly indicate the precise conditions of the training environment will provide. Good practice in specifying Role Conditions is generally applicable to specifying training Conditions. However, while there may be some variability of Conditions experienced within the Role (multiple Role Conditions where not all always apply i.e. ‘Condition X or Condition Y’), a TO should contain a single, consistent set of Conditions (i.e. ‘or’ should not appear in training Conditions)."
  },
  {
    "id": "bc4a4552-9907-4f99-9a91-80b94d1a89ff",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Specifying Training Standards",
    "content": "The Standards statement specifies the standard of performance that should be achieved by the trainee by the end of training. Where viable and cost effective this should be aligned as far as possible to the Standard required in the Role. The statement must be detailed enough to accurately assess if a trainee has achieved the standard or not. As for the derivation of the Role PS, standards can either be product standards (minimum absolute standards) or process standards (certain procedures that need to be followed in a particular sequence) or a mixture of the two. Good practice in specifying Role Standards is generally applicable to specifying training Standards. When determining TO Standards the nature of the performance (which could be dangerous, critical or an emergency task), consequence of not meeting the standard and the training category should be considered, as the standard required is likely to eventually affect how that performance is taught and how the trainee is tested. Some TOs may be subject to external rules and regulations, i.e. the standard is dictated. Some examples of topics where this applies are: Health and Safety. Nuclear. Weapons handling. Flying regulations e.g. Civil Aviation Authority. Legal requirements, both national and international. If a performance is affected by such factors, the document or regulation should be clearly referenced in the Standards statement, e.g. in accordance with Publication/Law/Act, Section X, paragraph Y, Date and Version. It should be noted that any restrictions in training Conditions might constrain the training Standards that can be achieved. The training Conditions and Standards must be compatible. (i.e. a process Standard requiring electrical isolations to be made by staff in the Ship Control Centre may not be fully achievable if training is being conducted on a part-task trainer in a laboratory ashore; a Standard should be proposed which reflects this process standard as fully as possible while being cost-effective). TOs must be tagged to identify them as a Core (training) requirement, Legal requirement and/or Accreditation requirement, which is denoted using a letter (C, L, A). To ensure that training is allocated to all tasks, the link between tasks and TOs/CTOs should be shown through an auditable numbering/identification system. This can be achieved is by using the task numbers from the Role/Team PS to identify their dependent TOs/CTOs."
  },
  {
    "id": "62f40b55-a674-4d28-9a95-fdf73367f9ed",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "FIDELITY ANALYSIS",
    "content": "Fidelity Analysis (FA) considers each Task in the RPS to assess the extent to which it is necessary for the training environment to replicate the workplace (real) environment to enable training to be effective. Results of FA may modify the provisional Training Categories derived from DIF analysis and are also used later in the TNA during the Training Options Analysis (TOA). This analysis should be conducted as a result of the production of a RPS derived from the RA and include any existing performance standards. Decisions made at this stage can have a significant impact on the nature and cost of training solutions, as fidelity can be a significant cost driver so it is important not to ‘gold plate’ the fidelity requirements, but instead determine the appropriate level of fidelity that is essential to prepare a trainee to carry out the Task. Fidelity Categories. Fidelity can be divided into 4 categories and sub- categories, combinations of which may apply to each Role PS task being analysed. Physical fidelity. Physical fidelity analysis assesses the need to familiarise trainees with the visual, spatial and tactile characteristics of equipment, consoles, compartments, platforms and threats (including applicable reference manuals, Standing and Emergency Operating Procedures and so forth). Physical fidelity can be broken down into these sub- categories: Layout. Position of the controls etc., relative to each other. Look. Shape, colour, luminescence and size of interface. Feel. Feel and movement of the interface during use. Functional fidelity. Functional fidelity analysis assesses the need to provide trainees with exposure to equipment functionality, doctrinal procedures, and maintenance routines which are required to be exploited in order to deliver the desired military effect. Functional fidelity can be broken down into these sub-categories: Format. Format of data displayed or action taken. Content. Information displayed or heard, frequency, text colour etc. Response. Data change rate and display response times. Environmental fidelity. Environmental fidelity analysis assesses the need to prepare or ‘acclimatise’ trainees for the conditions they will be operating under, and simulate some of the conditions that can hinder Performance. It can be easy to ‘gold plate’ environmental fidelity requirements beyond what is essential to provide the necessary cues, stimuli and responses, but high levels of environmental fidelity may be necessary for exposing trainees to complex operating environments and ‘fog of war’ type issues. Environmental fidelity can be broken down into these sub-categories: Sound. Background noise, conversation and sympathetic resonance. Motion. Incidental movement of the system, equipment or platform. Ambience. Heat, light, smell, smoke, humidity etc. Geographic features. Effects on sensors, infrastructure, SOPs etc. Tactical and cultural fidelity. Tactical and cultural fidelity assesses requirements that enable individuals and teams to ‘train as they intend to operate’. Exposing trainees to the types of units, threats, allies (including neutral or ‘white’ forces), cultural issues and geographical locations that they will experience on operations, can also be used for mission rehearsal training or tactical development. Modern training technology, particularly simulation, enables accurate representations to be included in training quickly and cheaply. Tactical and cultural fidelity can be broken down into these sub- categories: Threats. Enemy characteristics (number, tactics, equipment etc.). Allies / Neutrals. Allied and neutral forces characteristics (number, tactics, equipment, culture etc.). Conflict character and location. Type of operation, presence of media and / or Very Important Persons (VIPs), cultural / religious behaviours, historical implications, infrastructure and building implications etc. Team interactions. Command and control (C2) relationships, communications, situational awareness. Fidelity Factor. Every relevant task within the RPS should be analysed for its respective Fidelity requirements, based on the applicable Fidelity Categories. Depending on the complexity of the capability involved, it may also be necessary to articulate fidelity requirements at the sub-task level; It should not be assumed that Sub-Tasks will share the same Fidelity requirement profile as their parent Task, or other Sub-Tasks of the parent Task. Team/collective performance. Analysts should also consider the fidelity requirements of any team/collective Performance criteria that have been established in support of the new or revised capability, to contextualise the individual training need. Four indicative levels of fidelity are defined in the table below; these indicate the level of fidelity judged necessary if training is to effectively prepare an individual for performance of that task. Figure K-1 Fidelity Factors Fidelity factors alone will not give meaningful guidance to designers of the eventual training solution. Analysts should also include specific justification of the fidelity requirements for each Task/Sub Task within each applicable Fidelity Category and sub-category. An example of a completed Fidelity Analysis (FA) for a Task is shown below. Detailed records of FA, detailing Fidelity Factors and full justifications, should be kept by the analyst(s) and made available to the customer/sponsor. This information will be used again within the Training Options Analysis."
  },
  {
    "id": "c2c3bed7-19c0-4472-9294-14c050694394",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "MEASURE OF TRAINING EFFECTIVENESS (MOTE)",
    "content": "The MOTE seeks to derive an objective measure of a training medium’s effectiveness in satisfying a set of training requirements. It is fundamental that this is a direct measure of effectiveness for each task rather than a calculated score derived from weighted combinations of a number of component factors. Collecting scores from a panel of suitable Subject Matter Experts (SMEs) significantly reduces subjectivity in the MOTE. SMEs should be accepted as such by the Training Steering Group to ensure the validity of any assessment. The SMEs involved in the TOA form a MOTE assessment panel that reports to, and is accountable to, the Training Steering Group. It is stressed that authority still rests with the Training Steering Group who will ultimately be responsible for judging the accuracy and validity of the analysis. Where in this Annex the term ‘Option’ is found, it is important that the analyst is aware that an ‘Option’ consists not solely of one media or method, but of a suite of media and methods. It is essential that a single media is not discarded simply because it performs poorly when its effectiveness is judged in a stand-alone mode. The media discarded may well be the most effective for certain training requirements without off-setting the cost parameters too much. This media, when combined with another at little cost, may well prove to be the most cost effective solution available."
  },
  {
    "id": "b5209ea9-05e1-464e-919a-7c560c97a248",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Management of the MOTE Assessment Panel",
    "content": "The composition of the MOTE assessment panel should be sufficient for the scale of the project. As a guide, small scale training equipment procurements might just need a single assessor who will typically be the TNA author or SME with knowledge of both the training requirement and the capabilities of the method and media options. Larger scale projects might have a broader panel with representation from the analyst, training and/or equipment SMEs. To maintain a workable process it is expected that membership of the panel would be limited to a maximum of 6 members. The TNA Analyst will chair the panel and be responsible for routine management of the MOTE Panel and associated process. The chair will co-ordinate assessments and meetings conducted to verify assessments. Records of any MOTE panel meetings are to be taken to contribute to the TNA audit trail. Once nominated, members of the MOTE panel are to be briefed on the process and their responsibilities. This briefing should cover the general principles detailed in this COA plus any information specific to the project. Once briefed they are to be provided with blank assessment sheets for each of the options. Once all returns are received, collated and analysed the panel should meet for one or more alignment meetings as required to discuss areas of divergence in the assessment of the options. The primary purpose of these meetings is to ensure that the panel assesses consistently and to document the reasons behind extreme scores. Once the MOTE panel has completed its assessment, the results, associated data and records may be incorporated in the TOA and audit trail."
  },
  {
    "id": "943b68c5-228a-4c9c-be3f-8928d64f40b1",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Conducting the MOTE",
    "content": "A number of factors potentially affect the training effectiveness of a particular option. Typical factors that might be considered are detailed in Table 1. At the outset of the analysis the factors to be considered should be listed and prioritised in terms of importance. The list of factors and associated criteria should be given to the MOTE panel and explained to the assessors to ensure consistent assessments. It must be realised that whilst the elements in Table 1 marked (*) do not affect the effectiveness of the training in its true definition (Effectiveness of Training: the degree to which training prepares people for their jobs), they will influence the long term effectiveness of any training solution, and hence it’s Through Life Cost. Meeting the Role Performance Statement (RPS) in the immediate case is determined by how well people are prepared by the training. If the training solutions are to be assessed solely on their ability to meet the RPS, without consideration of flexibility or long term viability or risk, then the elements marked (*), should not be included. An alternative approach is to consider those marked with an asterisk as non- scoring items but to consider their impact within the text. Table L-1 Factors and Associated Criteria Affecting the MOTE The list of MOTE criteria is used to arrive at an assessment of the overall effectiveness of each Group/option pair. Scores are to be given in a range of between 0 and 1 in increments of 0.1, in accordance with Table 2. A score of 0.8 indicates an option meets the requirements of the criteria. Other scores will typically be assessed bearing in mind this critical boundary. Marks of 0.5 and below should have an amplifying comment recorded to indicate where the critical areas of deficiency are perceived – important for identifying any subsequent training gap. Scores of greater than 0.8 have been allowed in order to discriminate between similar options and to allow for those which provide benefits in addition to the bare requirement. Any score of greater than 0.8 should have an amplifying comment to indicate where the additional benefits are perceived to exist. It should be borne in mind at all times that the score relates to training effectiveness i.e. the ability of the option to meet the RPS. As such the coarse assessment of effectiveness will be directly associated with meeting the RPS and Fidelity requirements, with consideration of the other main factors allowing fine adjustment of the score. Table L-2. Definition of MOTE Scores"
  },
  {
    "id": "b3d6f9e1-3a7d-43e7-a677-e0bcfe4f2487",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "MOTE alignment process",
    "content": "Once all the individual assessments are collected they should be summarised and averaged for each option in a tabular form, indicating the assessors’ scores for each Group. A suggested format is given at Table 3: Option: Insert Option Name e.g. CBT Table L-3. Tabular Score Sheet This data and the individual score sheets are to be available at the alignment meeting, the purpose of which is to investigate extreme scores and extreme divergence of scores. Any Group for which the range is greater than 0.2 should be discussed and a record made of the reason for the divergence. Where the alignment meeting highlights misunderstandings or misapplications of the marking guidelines, the individual’s score may be amended. For example, the option scored above might be genuinely effective but scorer 1 did not realise that the option could actually address the shortcomings which caused an assessment of 0.7 to be given at 1.2. Compliance. Each average score is compared with the threshold for compliance to determine whether the option is compliant for that Group. The boundary for compliance is typically 0.8 – just effective. However, in some cases a shortfall might be acceptable in which case the threshold could be lowered. Should RPS complexity or TNA auditability demand, subjectivity in assigning an overall effectiveness score to each Group/option pair can be further reduced by sourcing each individual component score through a weights and measures approach, based on the criteria in Table 1. With this approach the reasoning behind each individual score can be made clearer, together with an indication of where the scorer has place priorities. Each TOA needs to be assessed against its own specific criteria, but an example of this approach can be seen in Table 4. The determination of an overall effectiveness score can be of particular use in creating a detailed audit trail of the thought processes involved in each TOA. Table L- 4. Weights and Measures Approach to Effectiveness Scores If this approach is utilised, however, the definition of the term ‘effectiveness’ must be borne in mind at all times. For the RN, should the option meet the RPS requirement, and to a sufficient degree of fidelity, it must be deemed to be effective. Any other criteria should not be overriding factors on the assessment of true effectiveness. The two criteria - ‘Meeting the RPS’ and ‘Fidelity’ - should therefore have significantly higher weightings than any other criteria."
  },
  {
    "id": "90eaf9ef-fffd-4ca9-999e-4c095a62b8aa",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Calculating the MOTE",
    "content": "Once the alignment meeting has reviewed all the Group/option pairs the revised scores, together with the records of assessment, form the audit trail for the MOTE. Conversion of the raw data into a measure of effectiveness is a largely arithmetic process which may be automated using a spread sheet. The MOTE for a particular option is calculated by simply averaging the scores for each Group (not-weighted or weighted, as required). Using table 4 figures: Calculate the average score divided by the total number in the group MOTE = 0.63 + 0.8 + 0.87  =  0.77"
  },
  {
    "id": "18cb924f-c89f-4888-8707-b9f7df6bf080",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Calculating Confidence bands for MOTE.",
    "content": "In order to provide upper and lower estimates for the MOTE, the Min and Max individual scores are entered into the same process as above. Calculate the maximum individual score for each and divide it by the total number in the group for each option. MoteMax\t= 0.7 + 0.9 + 0.9\t= 0.83"
  },
  {
    "id": "62de843a-2116-4357-9211-949622c7e19d",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "3",
    "content": "Calculate the minimum individual score for each Option and divide it by the total number in the group for each option. MoteMin\t= 0.6 + 0.7 + 0.8\t= 0.7"
  },
  {
    "id": "b0b6ab34-7cca-4dd3-8b2b-e5220f597dfb",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Cost Benefit Appraisal (CBA)",
    "content": "21 The weights applied in Table 4. are for illustrative purposes only. There is some debate as to the worth of a weighting process within TOA and therefore weighting values, when utilised, should always be explained and justified within the TOA. Cost Benefit Appraisal (CBA) is limited by the availability and accuracy of cost data. The method identified below gives an auditable and sufficiently objective means of discriminating between training options. This must be tempered with a critical analysis of the outcome of the CBA. For each option the through life costs must be calculated on a consistent approach between media. If absolute costs are not available then the costs must be derived by identical means for each option. In most cases the costs will be based on additional Through Life Costs (TLC) comprising both capital and running costs. Typically, capital costs should include new building, training equipment/GFE (including installation), extra computer hardware/software, courseware development and new training aids. This figure is normally a one off initial payment but there may be periodic renewable elements across the TLC. Annual running/support costs should include instructional and support staff, maintenance, overheads etc. One way of producing this figure might be to obtain the trainee day cost for a particular course; this can be multiplied by the additional course length and annual throughput to give a broad order annual support costs. It should be noted that some options might cause savings that can be offset against TLC; these should be incorporated in the figures. Further detailed guidance can be found in JSP 507 - MOD Guide to Investment Appraisal and Evaluation. The data collected should provide a minimum cost, a most likely cost and a maximum cost. Rough Order of Magnitude (ROM) costs may be sufficient to discriminate between options; however if that is not the case it may be necessary to refine these figures further."
  },
  {
    "id": "246d479f-3e4c-4d72-af11-b118bf599b12",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Graphical Representation of the Data",
    "content": "The CBA data can be simply and intuitively displayed as a graph of MOTE against Net Present Value as demonstrated in Fig 5 below. The error bars in the horizontal direction represent the spread in terms of the training effectiveness scores awarded by the SMEs. The error bars in the vertical direction represent the spread in terms of ROM costs. It is important that the analyst notes that at first glance option C appears to be more expensive but provides a higher level of training effectiveness than Option B. However the case may be that Option C is more expensive but yields a lower training effectiveness score (when noting the overlap of error bars in the vertical direction) than Option B. Figure L-5. MOTE vs NPV"
  },
  {
    "id": "2c3ca9cc-2cf6-43a3-8425-daa5e3120c30",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Calculation of a CBA Measure",
    "content": "Cost effectiveness can be coarsely assessed by dividing the MOTE by the NPV. This can give a Max CBA, a most likely CBA and a Min CBA. CBA = MOTE Cost As MOTE is a number between 0 and 1, and costs are usually significant, in order to have a useful CBA measure it is usual to use a relative cost. Dividing the cost of an option by the cost of the most expensive option derives the relative cost figure. This will give a relative cost between 0 and 1 and a useable CBA measure. The three CBA figures are calculated as below:"
  },
  {
    "id": "77c7f7c5-c05d-4f98-a4f7-dacc3e6e5be7",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "Interpretation of the MOTE/CBA Data",
    "content": "It should be noted that the MOTE represents averaged values and so should be treated with caution. In particular they should not be blindly used to reject options. The MOTE and CBA figures are there for guidance purposes, the analysts should consider each option’s score carefully before rejecting or ranking the options. It should be noted that other influences might affect the ranking of options. Care should be taken when discriminating between options to compare on a like for like basis. Typically we might have two approaches; either to compare on level effectiveness or to compare on level cost. In the case at Fig. 5 we might reject option B in favour of option C on the basis that their costs are broadly similar but C is more effective. A consistent model should be applied to compare options. In the case above (Fig 5) options A and B might be rejected as under compliant. This should not be done without consideration of how these options could be brought to compliance. In the case above the cost of making A compliant might be less than selecting option C. In most cases the solution for reaching compliance might include some form of OJT, therefore careful consideration should be given to the calculation of these costs. Several approaches of costing the impact of OJT might be used: OJT could be counted in terms of the cost of providing the OC, for example the cost of 3 days OJT for Command Team Training might be assessed as 3 days of running costs for the particular platform. The cost of OJT might be calculated in terms of interruption to ship’s activities multiplied by capitation rates of those involved. Another strategy might be to calculate the cost of “contracting out” the activity while the personnel are being trained. Whatever the approach, thought should be given to the particular problem and whatever method used must be acceptable to the Steering Group. In some cases the options considered might be variants of a single option. In such cases consideration of raising option effectiveness might be inappropriate as another option might be an enhanced version of the under compliant option. It is vital that an analyst makes a case by case assessment of the options based upon the underpinning data and presents this analysis in the Training Needs Report for Steering Group approval. No hard and fast rules for interpreting the data can, or should be given as the circumstances for individual projects can differ. Certain tasks might be deemed critical in which case an option which was otherwise compliant (MOTE ≥ 0.8) might be rejected as it was deficient in these areas and similarly the converse might apply. Fundamental to a satisfactory TOA is the analyst’s ability to present a coherent and reliable case."
  },
  {
    "id": "fafa0baf-ca99-4712-9fe5-2fcee65501b6",
    "document": "Maritime Acquisition Training Guide (MATG) Part 2 Training Analysis Standards V2.0.docx",
    "section": "TRAINING NEEDS EVALUATION (TNE)",
    "content": "The TNE should evaluate: Management of TNA Phases 1 and 2. Training effectiveness - has the chosen solution met the need? This is fundamentally an external validation where the following general approach is recommended in categorising any training non-compliance: Evaluate against the TNA solutions and recommendations that were fully implemented. Identify any capability shortfalls as a result of TNA solutions and recommendation not being implemented. Identify any capability shortfalls, which resulted from not addressing in, or de- scoping from, the TNA. Training efficiency (i.e. cost effectiveness). Availability, reliability and maintainability of any training equipment. The management of the training delivery. The results of the TNE should be presented as a report and distribution of the report to appropriate stakeholders. The TNE report should include the following: Aims of the TNA TNE. Aims and objectives of the acquisition project. Training system acquired. Summary of the findings from the TNA PPE. Review of the processes: Review of the development techniques and procedures. Review of the project management techniques and procedures. Adherence to standards and effectiveness of the standards. Performance against budget (i.e. cost of SME input, cost of contracted out TNA). Quality of the design. Review of the products: Functionality. Performance. Ease of use. Availability, reliability and maintainability of the training equipment. Upkeep and support aspects. Security. Documentation. Training effectiveness. Training efficiency. Actual running costs compared with estimates. Assessment of existing requested changes. Conclusions. Recommendations."
  },
  {
    "id": "6cf9f1c6-ea0a-4436-a6bf-799a7a2bbecd",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Uncategorised",
    "content": "JSP 822 – Defence Training Support Manuals Governance of Individual Training Edition: 2023 Version: 1.0 Contents"
  },
  {
    "id": "11779f7e-b700-4678-a785-c9db2502619c",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "How to use this Manual",
    "content": "Defence Training Support Manuals (DTSM) have been developed to support the understanding and implementation of the policy contained in JSP 822. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. DTSMs will be published every December, following the publication of the latest version of JSP 822. Throughout the year, different versions of the latest DTSM edition may also be published. When every new edition is published, the versions will reset to 1. Using the DTSMs is entirely optional, and users may find there are alternative resources available to help them understand and implement the policy contained in JSP 822. Throughout this document there are references to other DTSMs, these references contains hyperlinks that will take you to the DTSMs that are held on the   SharePoint site. The DTSMs currently available are:"
  },
  {
    "id": "e6868858-1caa-495f-ad12-839bdeff6790",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Governance of individual training is the process through which decisions are made that determine the long-term strategy, direction and organisation of individual training across Defence. Individual Training Governance provides the framework through which training stakeholders are accountable for continuously improving the quality of their provision to meet Defence requirements. Governance of individual training is managed primarily through boards such as Customer Executive Board(s), Working Groups and Steering Groups. In Defence, individual training is conducted in a variety of single Service, Joint, and Defence training settings. The principles for the governance of Joint, Defence and single Services training requirements are the same. However, because of the additional complexities of Joint and Defence Training, there are differences when it comes to the structures and roles involved in the governance. Although JSP 822 does mandate specific governance activities for all training across, TLBs do retain significant levels of autonomy on the governance of individual training, that falls under their command. It is therefore essential that users of this DTSM also consult local policy documents that may exist, and are managed locally by training policy teams within the TLBs. Along with governing individual training, it also is important to govern the Defence policy that provides direction and guidance on individual training. This manual also provides details on the processes and frameworks in place when it comes to the governance of individual training policy."
  },
  {
    "id": "36aebca2-7576-4f66-8869-4fc1a42f67cc",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "An Individual Training governance structure refers to the framework and system of rules, roles, responsibilities, and processes that a Defence organisation puts in place to ensure that the development, delivery, assurance and management of individual training remains on track, and appropriate to the organisation’s requirements. Within Defence, an Individual Training governance structures usually takes the form of the traditional hierarchical structure, which is commonly found in other areas of Defence, and most large organisations. A hierarchical governance structure is a type of organisational structure in which authority and decision-making are organised in a top-down fashion, with a clear chain of command and defined levels of management. In this structure, individuals and teams at each level have specific roles, responsibilities, and decision making powers, and they report to higher levels of management. By using a hierarchical governance structure, organisations from across Defence ensures that there is a direct link between the trainee undergoing the training activity and the heads of the various Top-Level Budgets (TLBs) that exist within Defence. Figure 1: A Straightforward Hierachial Training Governance Structure used in Defence Figure 1 displays a straightforward governance structure, however, across Defence, governance structures tend to be more complex with additional groups to support the main governance groups. Examples are provided in Section 2.2. Within this chapter, we have separated governance structures in to 3 types of training environments: Defence Training, Joint training, and single Service training. The principles around governance structures are the same, however, due to the more complex nature of Defence and Joint training, there are some differences around the formation of the structures. JSP 822 volume 10 defines Defence Training and Joint Training as: Defence Training: “Multiple learning events that may be delivered to individual sS audiences but achieve the same output for all Services.” Joint Training. “A learning event where two or more Services participate together.” Although not defined in JSP 822, this DTSM uses the term single Service training as any training event that is delivered to a single TLB, instead of more than one. It must be noted however, that a single Service training event may only be required by part of the TLB instead of the whole of the TLB. Even though it appears Defence and Joint training are the same, Joint training becomes Defence training once the number of Services participating spans to the whole of Defence."
  },
  {
    "id": "47befbc5-9373-48e3-a1b8-c6bf0f657cf1",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Structures in single Service Training",
    "content": "As highlighted in para 6, single Service training is a training event that is delivered only to one TLB. This means that the TLB, or more likely, the organisation within the TLB, is responsible for the analysis, design, delivery, assurance, management, and governance of the training event. As TLBs are responsible for the governance of the single Service training that they develop and deliver, they are therefore also responsible for establishing the governance structures. Training governance structures and governance groups are identified and/or established during the development of a training activity. Depending on the circumstances surrounding the training, new governance structures and groups may need to be established, or it may be more appropriate to use ones. Across Defence, TLBs broadly have similar structures where individual TLBs have common governance groups that sit above CEBs. These groups have the responsibility for the governance of all individual training for that TLBs. Figures 2 provides an example of a TLB training governance structure. Figure 2: Army Training Governance Structure1 1 Taken from ACSO 3248 The following contacts / documents provides more detailed information on governance structures across Defence."
  },
  {
    "id": "2e192127-10ce-4669-a40b-4ba43043c51d",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Structures in Joint Training",
    "content": "As highlighted in para 6, Joint training involves training events that may be delivered to one or more TLBs, but not all TLBs. Only those TLBs participating in a particular Joint training event will have involvement in the governance of that training. In principle, Joint training uses the same hierarchical structure used in single Services training, however, due to the complex nature of Joint training, establishing the governance structure of a Joint training event may not be as straightforward. As with all training, JSP 822 mandates that Joint training must have a CEB. The CEB is similar to a CEB in single Services training, however, the composition is different. More information on a CEB can be found in Chapter 4, Sect 4.2. Once established, it is likely a Joint training CEB will fit in to an already established governance structure. Although Joint training is delivered to more than one TLB, it is likely the 2* governance group for the training event will be an established single Service governance group. The 2* single Service governance group membership will likely have representatives from the additional TLBs participating in the training. Example: Joint Helicopter Command (JHC) reports to the 2* Army Training Committee (ATC). Training Establishments that deliver Joint training will likely have local governance policy that instructs TRAs on governance structures. For more information on single Services training governance policy, the following contacts / documents can be consulted."
  },
  {
    "id": "73a3635b-193c-423a-a46b-71840d0d7918",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Structures in Defence Training",
    "content": "As highlighted in para 6, Defence training involves training events that may be delivered to all TLBs within Defence. In principle, Defence training uses the same hierarchical structure used in single Services training and Joint training, however, due to the complex nature of Defence training, establishing the governance structure of a Defence training event may not be as straightforward. As with all training, JSP 822 mandates that Defence training must have a CEB. The CEB is similar to a CEB in single Services training, however, like a CEB in Joint training, the composition is different. More information on a CEB can be found in Chapter 4, Sect 4.2. Once established, it is likely a Defence training CEB will fit in to an already established governance structure. Although Defence training is delivered to all TLBs, it is likely the 2* governance group for the training event will be an established governance group within one of the TLBs. The TLB governance group membership will likely have representatives from the additional TLBs that participate in the training. Example The Defence College of Technical Training (DCTT) reports to 2* RAF Training Requirements Oversight Committee (TROC) Training Establishments that deliver Defence training will likely have local governance policy that instructs TRAs on governance structures. For more information on single Services training governance policy, the following contacts / documents can be consulted."
  },
  {
    "id": "ac1f1044-a080-4226-bd37-257aabcb8e78",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Governance roles in training refer to the specific positions or responsibilities within Defence that are focused on ensuring effective training governance and oversight. These roles play a critical part in the managing the training, making strategic decisions, and ensuring compliance with policies, laws and regulations. This chapter only lists the roles that are common across the whole of Defence, in reality there are numerous roles involved with governance of training, and some of these are unique to specific TLBs. It is therefore essential that users of this DTSM also consult local policy documents that may exist, to establish specific governance roles within their TLB. For more information on single Services training governance policy, the following contacts / documents can be consulted."
  },
  {
    "id": "2ff72764-6ccc-4d04-a8cf-f566076aed91",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Requirements Authority (TRA)",
    "content": "Overview of the TRA The Training Requirements Authority (TRA) represents the end-user of the trained output and is the ultimate authority for the derivation and maintenance of the Role Performance Statement (Role PS) and/or Framework(s). The TRA is responsible for the evaluation of the effect of the training in achieving the Role PS and/or Framework(s) wherever the training is delivered. TRA within single Services Training The TRA often sits at the Service Command (SC) level and sets the requirement for a new training activity, or a variation to an existing one, as well as some aspects of the assurance of the training. The TRA is often a nominated post at 2* level but it is common practice for TRA responsibilities to be delegated, by letter, to an individual (or organisation) who has more knowledge of the specific requirement. TRA within Defence / Joint Training For Joint or Defence outputs the nomination of a Lead TRA is required who takes account of the requirements of two or more TRAs, usually but not exclusively from different Services or Commands. The Lead TRA will sign the TrAD on behalf of any subordinate sS TRAs (usually at a Customer Executive Board (CEB)) but only with their agreement."
  },
  {
    "id": "fc3fd176-69f6-4250-9597-e13a0dae785a",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Delivery Authority (TDA)",
    "content": "Overview of the TDA The TDA is the organisation responsible for training delivery, but not always for the conduct of the actual training itself. If a SC so wishes, the TDA role can be a nominated post. Examples of the types of Roles associated with the TDA are: Designer, 2nd party auditor or inspector, and Training Line of Development (TLoD) Owner in the case of projects, programmes or capabilities."
  },
  {
    "id": "fac633cb-baac-4fee-a679-9fdf8ba01509",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "To ensure effective governance of individual training, various groups or committees are established. The specific groups involved in governance can vary widely depending on the training to be governed, size of the organisation, and the governance structures. This chapter only lists the groups that are common across the whole of Defence, in reality there may be many different groups involved with governance of training, and some of these are unique to specific TLBs. It is therefore essential that users of this DTSM also consult local policy documents that may exist, to establish specific governance roles within their TLB."
  },
  {
    "id": "2d1fc24d-c209-4b28-8638-989edb319697",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Customer Executive Board (CEB)",
    "content": "The purpose of the CEB is to provide a mechanism for stakeholders to develop the scale and content of training to match the Defence requirement within the available budget and in accordance with relevant Defence and sS policies. In doing so, the CEB will: hold all parties to account for the execution of their responsibilities in relation to the quantity, quality, timeliness and effectiveness of the training. hold the TRAs to account to provide a clear fully justified requirement and their priorities for training. manage the key documents which drive CEB business: the TrAD, the Role PS and/or Framework(s), the FTS the SOTR/SOTT (These must be tabled at the CEB and agreed/signed off by relevant stakeholders). Each CEB should be chaired by an appropriately empowered representative who will be responsible for maintaining focussed discussion and ensuring clear articulation of actions and holding to account personnel/organisations that have received tasking. Unresolved issues and risks should be raised via the TSLD governance structure. The CEB is generally chaired by the TDA; the rationale being that the TDA will be required to affect the implementation of any requirement changes such as updating the training documentation. The TDA will also be best placed to provide the necessary training data. Additionally, the TDA also usually holds the budget for the training. However, the TRA (or Lead TRA) plays a vital role and is the individual/organisation responsible for escalating any risks and issues unresolved at the CEB up the Chain of Command, and for ensuring that appropriate governance and assurance activities are being undertaken. For certain CEBs (e.g. where there are several TDAs, or where the TRA controls the resources, or where the TDA is a contractor), the TRA may decide that it is more appropriate for them to chair the CEB. Chairship should be clearly articulated in the ToRs. The TRA must ensure that a CEB is normally held biannually and both TRA and TDA should attend the CEBs2. Where there are matters that cannot be resolved as part of the CEB (e.g. a TRA believes the requirement is not being met or a TDA does not have the resource to deliver a requirement), these are to be escalated to a higher level within the relevant Chain of Command/TLB for resolution. Joint/Defence Training. In the case of training where a Lead TRA has been nominated, matters that cannot be resolved should be referred to the TSLD PAG via SO1 Trg Pol, TSLD, in the first instance. To bring more clarity to the way that CEBs operate, JSP 822 states that documentation for each CEB must include: ToRs. A tailored ToR for each CEB is to be produced using the suggested format in Annex A. Whilst this suggested format provides the wording that will be generic to all CEBs, it is important that each CEB contextualises their ToRs accordingly; separate ToRs are to be produced for CEB WGs. Membership should be articulated by the specific organisations/posts that should be in attendance (e.g. they should not simply 2 If Joint/Defence training, then both Lead/Associated TRAs/TDAs should attend. state that the TRA should attend but should list the relevant TRA(s) posts that are required). Agenda. A comprehensive agenda is critical to fulfil the objectives of the CEB. A number of core standing agenda items must be included at all CEBs. Other items can then be added to address any issues relevant to that CEB. A suggested format for an agenda with the core items3 is contained within Annex B, with agenda items to include: Training Delivery. Discussion of any issues pertinent to training delivery both current (i.e. in Training Year (TY) 1, e.g. trainer numbers) and future (e.g. re-location of training) and a concise report on the actual training delivered in the previous TY. Endorsement of the FTS and Assessment Strategies that have been agreed between the relevant TRA and Training Providers. The delivery of Distributed Training (DT) is to be considered under this agenda item. Near-term Training Requirement (Content). Discussion of issues associated with training content to include clarification that the TRA has provided the TDA with a clearly articulated requirement and confirmation that they are satisfied (or otherwise) with the standard of the trained output. Acceptance of the Role PS from the appropriate TRA. In a Joint or Defence context, the development of appropriate Joint or Defence training. Near-term Training Requirement (Volume). Contribution towards development of the SOTR and then acceptance of the endorsed SOTR from which to develop the SOTT. Endorsement of the SOTR for TY 2 (i.e. the next TY commencing the following Apr) and clarification on the implications of any future changes to TY 2. De-confliction of any resource requirements that arise from late notice (less than 12 months from commencement of training) budgetary/SOTR imbalance by trading sS training priorities against available funding. Reporting uptake/performance against the SOTT. Retention of an audit trail to show why differences between SOTR and SOTT have occurred. Trainee Flow and Future Requirements (Volume). To ensure the optimisation of training, including the efficiency of training pipelines and that appropriate co- ordination is in place between multiple CEBs, where they exist. Consideration (in broad terms) of the training requirements currently predicted for TY 3 and 4 and the anticipated ability to deliver that requirement with the resources available. DSAT QMS Compliance. Monitoring adherence to the DSAT QMS to ensure training documentation is effective and that there is an up-to-date TrAD, Role PS (noting the requirement to review the Role PS at least every 5 years) and FTS. Monitoring and reacting to training effectiveness feedback including consideration of any assurance reports (external Ofsted inspections, 2nd party audit observations, InVal and ExVal reports). Monitoring rectification of audit non-compliance. Injuries in Training. In addition to the core objectives, there is a requirement for CEBs to consider whether it is necessary to report on any injuries in training and to ensure that all training risk assessments have been conducted. 3 For a CEB to be successful, CEB members should have access to high quality training information. Wherever possible this should come from the Defence training management system in use (such as TAFMIS-T and in the future DLMC). Management of Risks. Training risks must be discussed, with level of risk identified and mitigation measures outlined on a risk register. An example of a Risk Matrix suggested format is contained within Annex C, but sS may use their own formats if these conform to standard risk management practice. Discussion of Statistics. Discussion of statistics is to not only report in-year figures but should also report back on trend analysis (e.g. has the SOTR increased over time and if so, have resources correspondingly increased in numbers?). Pre-decision Support Information. For each CEB to operate effectively it is essential that pre-CEB decision support information is collated prior to the CEB. This will enable the focus of the meeting to be orientated towards decision-making and help avoid excessive background discussion/updates. Pre-CEB decision support information must clearly link to items on the agenda and support the key information required within the CEB output report. Pre-decision information should include assurance reports, SOTR/SOTT figures, statistics on pass rates, injuries, PVR trends etc. Record of Decisions (RoDs) / Action Grid. Each CEB occurrence must result in RoDs or an Action Grid that captures the relevant details, agreed leads and target dates."
  },
  {
    "id": "04ce2feb-3cf4-46b4-8699-392c0b2bb7d3",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "CEB Working Group",
    "content": "CEB WGs are a forum where subject matter experts representing Customers, the TRA, TDA and Training Providers will meet to discuss each training activity in detail. The aim of the WG is to review training requirements, agree training levels and targets, examine the results of recent, and schedule future, assurance activities (such as audits and evaluation) and to highlight any emerging themes, issues and risks of concern up the CEB Chain of Command. The CEB WG is the preparatory phase of the CEB and will prepare training data for ultimate endorsement by the TRA. Issues that cannot be resolved at working level (e.g. a mismatch between the SOTR and SOTT) and areas of risk should be raised for discussion at the CEB. The chair of a CEB WG should be an appropriately delegated representative of the TDA/TRA. Given that the size and length of training activities varies substantially, TRAs/TDAs should use their judgement to determine which rank is most appropriate to chair and attend the WG(s) and highlight this in ToRs."
  },
  {
    "id": "6c061acf-be31-49ce-841c-7318902d3235",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Equally important to the governance of individual training, is the governance of the policy behind it. This chapter focuses on the governance of developing, implementing, and overseeing Defence Individual Training policy, which can be found within JSP 822. It involves a structured approach to policy creation, maintenance, and enforcement to ensure that Individual Training policies align with Defence’s strategies and goals, and comply with laws and regulations."
  },
  {
    "id": "d81d3398-898f-4ec7-9665-096a6aa1307e",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Structure",
    "content": "The governance structure of Defence Individual Training policy is relatively straightforward, and like training governance it uses a hierarchical structure. Defence Individual Training Policy can be found in JSP 822, and it is the responsibilities of the organisation Talent, Skills, Learning and Development (TSLD) to develop, manage and maintain JSP 822, and the policies contained within it. Defence Individual Training Policies are owned by SO1s that work within TSLD. The SO1s along with their teams, are responsible for developing and managing their policies on behalf of the Head of TSLD. See section 7.3 for more information on governance stakeholders. To help develop their policies, the TSLD SO1s chair their own OF4-level working groups with representatives from across Defence forming the membership of each group. The Working Groups form the first level of governance on the Defence Individual Training Policy governance structure. See section 7.4 for more information on the working groups.. The OF4 working groups are accountable to a 1*-level governance group called TSLD Policy Assurance Group (TSLD PAG), which is chaired by the Head of TSLD. The TSLD PAG membership contains 1* representation from TLBs across Defence. See section 7.4 for more information on the TSLD PAG. The 1* TSLD PAG is accountable to a 3* chaired governance group called People Leadership Team (PLT) which is chaired by the Chief of Defence People (CDP). The PLT membership contains 3* and 2* representation from TLBs across Defence and is the highest-level governance body for Defence individual Training Policy. See section 7.4 for more information on the PLT. The groups mentioned above make up the governance structure of the Defence Individual Training Policy found in JSP 822 and is illustrated in Figure 5. Figure 3: Defence Individual Training Policy Governance Structure"
  },
  {
    "id": "9eac33ca-b36f-4ca2-a2e8-e9a7a7b1cfa7",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Stakeholders",
    "content": "There are several stakeholders, from across the whole of Defence. who play essential roles in the governance of Defence Individual Training policies. Effective communication and collaboration among these stakeholders are crucial for the successful governance of the policies. Each stakeholder brings a unique perspective and responsibility to ensure that the policies align with Defence’s strategic goals, comply with regulations, and contribute to the development of a skilled and capable Defence workforce. TSLD Stakeholders As mentioned in para 3, TSLD is responsible for the Defence Individual Training Policy contained within JSP 822. The Head of TSLD is People-TSLD-Hd OF6. Each volume that makes up JSP 822 is owned by an SO1 / OF4 grade member of TSLD, who is responsible for development and management of the policy in their volume(s). Figure 6 displays the TSLD policies that are predominantly linked to individual training, and those individuals responsible for those policies. Figure 4:TSLD Roles and Responsibilities (Individual Training only)4 4 As the name suggests, TSLD is responsible for various policy areas in addition to individual training policy. Figure 6 only reflects the main policies linked to individual training, and does not shows all of the policies managed by TSLD, and all of TSLD’s personnel."
  },
  {
    "id": "8b0ec680-84a4-4bcb-9876-6c34602e78e0",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Governance Groups",
    "content": "People Leadership Team (PLT) The PLT is a 3* chaired Defence level Board that is chaired by the Chief of Defence People (CDP). It is the highest-level governance body for training issues. Amongst other objectives, the PLT manages training strategic performance and risks, and provides the governance and management of Defence Training and Education. TSLD Policy Assurance Group (TSLD PAG) The TSLD PAG is a 1* Defence level group chaired by Hd TSLD and provides strategic Direction on Defence Training, Education, Skills, Recruiting and Resettlement matters. It is the principal forum for the governance and assurance of such activities throughout Defence. Defence Level Working Groups (WG) There are several standing Defence level WGs that assist with policy, assurance and governance of training across Defence."
  },
  {
    "id": "a181d376-ac12-48c2-a2ca-51fc8449e597",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "C - Suggested Format for CEB Risk Management",
    "content": "Suggested Generic ToRs for CEBs ANNEX A TO DTSM 1"
  },
  {
    "id": "3cdda73d-f797-4d84-8035-9006a9c4253a",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Accountability and Governance Detail who is accountable to whom as agreed on the TrAD5. Governance of the CEB process ultimately rests with the PLT. Add any additional reporting mechanisms appropriate to the CEB (e.g. contractual relationships, project teams etc). Membership Detail core and representative membership and, as required, to include: chair6 to be generally provided by TDA (but could be TRA if this is deemed more appropriate). TRAs7 (clearly identifying who is being represented). representation from the appropriate sS or Defence policy organisation(s). additional stakeholders (as appropriate)8. representative(s) of the SOTR Co-ordinating Organisation(s). Training Provider(s). It should be clearly articulated exactly who is representing the TRA/TDA and stakeholders. This is especially important for the larger CEBs which may cover a variety of different requirements. Where a Lead TRA, TDA or Training Provider has been nominated, this is to be clearly articulated in the TORs. Resources Identify who holds the resources and financial responsibility. This is important when bidding for additional resources or managing cuts. It is also critical for the governance and assurance of the training. 5 In a Defence training context, if the interests of a sS are not satisfied by the CEB or its Chain of Command, the issue may be pursued through the relevant Principal Personnel Officer (PPO) within extant Defence people governance structures or the TSLD PAG. 6 In all cases, the chair of the CEB should be at a rank that is appropriate to the requirement. 7 If the TRA is a committee, its Chair will represent it at the CEB. To also include contractors. 8 In a Defence training context this will include representatives of sS organisations with involvement in the management of the training pipeline. Specific Tasks It should be clearly stated which requirements and training activities are within the scope of the CEB. During meetings, each CEB must address the 6 core agenda objectives, supported by pre-CEB decision support information. Each objective should be considered on a risk, assumption and issue management basis. The 7 agenda objectives are: training delivery, including DT. near-term training requirement (content). near-term training requirement (Volume). trainee flow and future requirements (Volume). DSAT QMS compliance and assurance activity. injuries in training. management of risks. Relevant stakeholders should be tasked to provide analysis that includes Distributed Training in order to gain a greater level of assurance of DT at CEB level. The aim is to ensure that SCs and TLBs are assured that all areas of the training pipeline are being managed and governed appropriately and risks are captured where required. Below are suggested questions for CEBs to ask: How many courses are run and what is the number of trainees attending in this TY? What is the overall success rate trained in DT (this TY and predicted for next TY)? What is the overall First Time Pass Rate in DT (this TY and predicted for next TY)? Which will be your top 5 most resource intensive courses (time/cost/workforce) / how can you reduce costs? Which courses have an entry test criteria / what is the % that fail the entry test / what is your mitigation? Which courses were undersubscribed last TY / what is the mitigation this TY? Which courses had the worst pass rates last TY / what is the mitigation this TY? Which courses/ iterations had to be cancelled last TY / what is the mitigation and impact this TY? What % of courses has been subject to audit? What were the key findings from audit? How is Good Practice shared? How are areas of concern communicated? What are your total numbers of courses vs iterations (ratio shows overall changes in customer demand)? Are there plans to move any Training from distributed into central locations or vice versa – what are the reasons for such moves, and have they been agreed by all organisations? What ExVal has been conducted this year? What is planned for next year? What are the top 3 risks and issues within DT for your organisation? Were all course iterations delivered iaw the Course specification, especially in terms of time allocated and trainer to trainee ratio? All areas within the CEB are to capture DT within the reporting process in order to gain a true picture of training pipelines i.e. training optimisation, assurance, resources and funding, risk and strategic direction. Each CEB must produce RoDs or an Action Grid and risk register. Authority The CEB is designed as a decision-making forum. If required, the chair must commit to seeking additional direction and guidance which should then be communicated Out of Committee. The chair is authorised to task WGs in pursuance of the CEB’s primary purpose. The CEB has the authority to liaise with other sS and Defence departments as appropriate, and Service establishments in pursuance of its primary purpose. Frequency of Meetings CEBs should normally meet biannually; additional CEB forums and WGs may be called at the discretion of the chair. ANNEX B TO DTSM 1"
  },
  {
    "id": "1456c51a-ec2a-438e-adad-318ce2e7dabe",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Suggested Format for CEB Agenda As a general guide the WG will produce all the information at a lower level and hold detailed discussions whilst the CEB will serve to address Identified risks, assumptions and issues, agree proposed COA and seek further Direction and Guidance as required. Suggested Format for CEB Risk Management Frequently = Daily, Regularly = Weekly, On Occasion = Monthly ANNEX C TO DTSM 1"
  },
  {
    "id": "9451a8f9-295b-4071-9e71-4b0d10307417",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Coverage",
    "content": "This DTSM supersedes all previous DTSMs on Governance of Individual Training The totality of DTSMs included in the DTSMs Suite, of which this document is a part, are listed on the DTSMs SharePoint site"
  },
  {
    "id": "f516283a-9c8e-4657-aa19-2674c2f3ce5b",
    "document": "DTSM 1 Governance of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Editions / Versions",
    "content": "Annual editions of this DTSM will be published every December in time for upcoming year relevant to the DTSM. Throughout the year, different versions of the current edition may also be published. When every new edition is published, the versions will reset to 1."
  },
  {
    "id": "4253a96d-a545-4a08-b353-6413c5524d59",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Uncategorised",
    "content": "Defence Training Support Manual 2 Analysis of Individual Training"
  },
  {
    "id": "e100b616-3105-4827-bc2e-8d1a5352ea73",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 Edition",
    "content": "Version: 1.0 Contents"
  },
  {
    "id": "66c6f052-2c85-4683-97fe-fe65ca1df443",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "How to use this Manual",
    "content": "Defence Training Support Manuals (DTSM) have been developed to support the understanding and implementation of the policy contained in JSP 822. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. DTSMs will be published every December, following the publication of the latest version of JSP 822. Throughout the year, different versions of the latest DTSM edition may also be published. When every new edition is published, the versions will reset to 1. Using the DTSMs is entirely optional, and users may find there are alternative resources available to help them understand and implement the policy contained in JSP 822. Throughout this document there are references to other DTSMs, these references contains hyperlinks that will take you to the DTSMs that are held on the   SharePoint site. The DTSMs currently available are:"
  },
  {
    "id": "617414ac-af9d-4ddb-b6ec-089f04334f27",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "1.\tThis Section of the Guidance outlines the Defence approach that allows training specialists to adopt a structured, methodical approach to the analysis of the training need, or requirement. It sets out the various activities, collectively termed the TNA, which may be used in order to conduct a TNA, which informs subsequent Elements and forms part of the overall Training System.",
    "content": "Overview of the TNA A TNA is a structured analysis of training need arising as a result of new equipment acquisition, doctrinal change, organisational change, or changes to policy/legislation. It generally includes an analysis of different training Methods and technologies, with a view to recommending the optimum training solution which balances cost and quality. It is a highly flexible procedure with the choice of supporting tools and techniques to suit different Training Systems. In all cases, however, a TNA is an output based, iterative process that provides an audit trail for all decisions and is closely mapped to the requirements of the QMS. A TNA does not, and should not, imply that training will be the only solution. If training is not the solution, this will become apparent in the Scoping Exercise, after which, analysis activity will cease. The TNA provides an audit trail of analysis to determine the need for training and, if required, enable design of a training solution. The process described below is a 3-stage process with a number of specified outputs. However, it should be emphasised that this recommended approach is not necessarily linear nor does it have to be followed prescriptively. In many cases there may not be a requirement to produce all of the suggested output products, and there may be merit in conducting stages or activities concurrently. The principal activities of the TNA process, grouped together into the 3 Stages, are: TNA, Stage 1. Scoping Exercise Report. This identifies the management of the TNA, programming and resourcing issues, policies, constraints, risks and assumptions. The key output is the Scoping Exercise Report (which recommends possible training solutions). It also identifies if training is not the solution and no further analysis is required. TNA, Stage 2. Role Analysis (RA). This identifies the Role(s) that need to be trained for, the supporting duties, tasks, sub-tasks and task-elements, then analyses these to generate Performances, Conditions and Standards. The key outputs are the Role PS and/or Framework(s)1. Training Gap Analysis (TGA). This states the training gaps in terms of KSA. The key outputs are the Statements of Training Gaps. Initial Training Objectives (TOs). This is an initial draft of the TOs, based upon the Role PS and/or Framework(s), which are the key outputs. It may be that the initial TOs created at this stage are sufficient and do not need further refinement but they are certainly not endorsed at this stage. Training Options Analysis (TOA). The TOA considers each relevant Task in the Role PS / Competence Framework to assess the extent to which the training environment should replicate the workplace (real) environment to enable training to be effective. This is known as the Fidelity Analysis. The implications of locations and environment for training and Methods & Media options are then considered. The key outputs are the realistic options for Methods & Media and refinement (based upon fidelity, locations and environment) of the possible training solutions. Cost-effective options which take account of Whole Life training requirements (including refresher training) are considered. Training Needs Report (TNR). The Training Needs Report analyses the cost benefits and then evaluates the merits of the training options, before confirming the TNASG endorsed training solution. The report includes the Role PS and/or Framework(s). The key output is a recommendation as to the most cost-effective training solution, which inputs into the SOTR. An implementation plan is also included. 1 E.g. Comptency or Competence Frameworks. TNA, Stage 3 (conducted at DSAT, Element 4). Training Needs Evaluation (TNE). This assesses and reports on the effectiveness of the TNA process as well as the ability of the implemented training solution to meet the Defence requirement. The TNE is conducted in 2 parts: evaluation of the process, and evaluation of the training solution. The key output is an assessment of how well the TNA outputs contributed to the provision of a training solution that meets the Defence requirement. This completes the TNA process. TNE is covered in DTSM 5. Why or when should a TNA be conducted? Before a TNA can begin, a clear evidence-based Statement of Requirement (SoR) is to be produced, preferably in a written format (letter, e-mail, request form or tasking order, for example). Then, prior to the commencement of the analysis, a scoping exercise is conducted which may identify that the most cost-effective means of achieving the required Defence need, is a training solution2. Once the requirement for training has been established, a TNA should be undertaken to ascertain the type and scope of the training requirement that meets the Defence need. It should be noted that a TNA may range from a simple interview to a process lasting several months. See DTSM 1 for more information on a SoR. Responsibility. It is expected that the Training Requirements Authority (TRA) will take the lead on the production of the DSAT activities, processes and outputs required to be completed during Element 1. The TRA may wish to delegate specific tasks, but will retain overall responsibility for them. The TRA will also be expected to ensure that those activities deemed critical to the development of the Training System are conducted. A key activity is the establishment of a TNA Steering Group (TNASG), upon receipt of a SOR, or other authority, to begin the TNA process. The TRA is ultimately responsible to the Customer for the work conducted during this Element. See DTSM 1 for more information on a TRA. Considerations with a TNA Training activities should meet Defence outputs; and, should these change, the training need should be re-analysed, via a TNA, and if necessary, adapted to support the new requirement(s). If a TNA is to be conducted, the user should consider: the requirement being raised and the need to carry out a TNA. forming a TNA Steering Group (TNASG)3. assurance of the TNA process. There may be different reasons for undertaking a TNA: In support of a new fielded force or training equipment or service. In support of an enhancement to any equipment or support system already in service. A change in policy/legislation. 2 Equally, it may not recommend a training solution, in which case the TNA would cease. 3 Across Defence this SG may be known by alternative names. A change to the doctrine underpinning the deployment of a capability. Changes to organisational structure, or changed competence requirements. As a general rule, a TNA should be used when a change in Defence capability is likely to have a significant impact on the training resources required to generate trained output. The TNA should be fit for purpose, provide an auditable trail and determine the most cost- effective training solution. The TNA may vary in complexity from a simple scoping exercise to an extensive process requiring a dedicated team of Needs Analysts. Non-training specialist involvement in a TNA. Stakeholders often have a limited knowledge of the MTS and are unfamiliar with the TNA process. At the start of a TNA, time is often well spent in educating those who are to be involved in the TNA about the process. They should be aware of their responsibilities, including the provision of information and staffing routines. Whilst it is not usually the TNA author’s responsibility to the implement the training solution, post TNA, it is possible that they may be involved in subsequent working groups, to provide training support advice. Exploiting existing training activities. The need to design training from scratch on a ‘blank sheet of paper’ is a very unusual occurrence, as it is much more likely that existing training can be modified. It follows, therefore that it is often desirable to analyse the current training first. Where current role information, Role PS / Framework(s) or TOs do not exist for any current training, more comprehensive RA may be required, before any determination of a training requirement can be made. Analysis of similar, existing, training is also useful to support this. Audit trail. A TNA should generate a clear audit trail which plots the sequence of events and decisions leading to a training solution. The justification and supporting evidence used as the basis for these decisions should be readily apparent (such as: references to, and/or copies of, academic research literature; the deliberations of the Analysts; minutes of TNASG meetings and Defence/Contractor publications). A quality audit trail requires full disclosure of, and rationale for, the methodology, tools and data sources used in the analysis, with copies of any specialist or bespoke software made available to the TNASG. Iterative/selective nature of TNAs. Whilst a TNA is carried out by completing a number of activities in sequence, it is important to note that the process is iterative in nature. Many influencing factors, risks and assumptions are liable to change during the conduct of a TNA. It is therefore important that at every stage of a TNA, the key outputs are reviewed to ensure their continuing validity, and that stages of the process be repeated if necessary. Processes for reviewing the TNA outputs should be capable of amendment where changes are required. Tight control should be exercised by the TNASG, which approves all changes to the TNA. Follow-on changes to the training requirement and the impact on training may be managed through a system of configuration control but this does not remove the responsibility of the TNASG for ensuring that changes are reflected in the TNA. It should be noted that the cheapest option is not necessarily the most cost-effective option in meeting the training requirement. Also, the cheapest option is not necessarily to continue existing training within existing resources. Therefore, ‘effectiveness’ is the key as it is the extent to which the training has prepared the individual for the Defence effect which matters. Cost is ‘efficiency’ focused to optimise the use of resources to enable the execution of training (and required learning) and ensure Value for Money (VfM)."
  },
  {
    "id": "413eaab7-267d-4de6-b059-5109918ed68c",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The name TNA Steering Group (TNASG) is commonly used for this this governance group; however, it may be known by alternative names example: Training Steering Group (TSG). Although TNA SG is used within JSP 822 and the DTSMs, personnel should consult local policy documents to see if a preferred, alternative name is in use. For most training, the Chair of the TNA SG will normally be filled by the TRA, however, under certain scenarios e.g. Short Term Training Requirements, the role of Chair may need to be filled by an alternative individual e.g. Member of a Project Team. TNASG membership may include: Training Requirements Authority (TRA). The complexity and size of the training requirement will dictate the level of involvement of the TRA and whether responsibilities are delegated. Training policy and training support representatives from the TRA should direct the TNA Scoping Exercise and the TRA will normally nominate the chair of the TNASG. See DTSM 1 for more information on the role the TRA. Defence Equipment & Support (DE&S). Where the training need is derived from new equipment or a service being brought into service by DE&S, representation from the Project Teams, or equivalent, is key to ensuring that the training requirement meets the technical needs of the new capability. Training Delivery Authority (TDA). The TDA will need to be represented at the TNASG as it is responsible for the design stages of the DSAT process and will likely be closely tied to the Training Provider. See DTSM 1 for more information on the role of the TDA. Training Provider. It is not vital for the Training Provider to be represented at the early stages of TNA, unless a specific Training Provider is obvious from the outset. In that case, it is sensible to include the Training Provider in the TNASG. See DTSM 1 for more information on the role of the Training Provider. Formation Command. The Formation Command4 is the final user of the new capability. The Formation Command therefore should be represented as it will be integral to achieving the balance of training between that delivered by the Training Provider and the remainder by the Formation Command in the workplace. Workforce Authority. The identification of appointments/posts/billets affected by a new Defence capability, as well as training throughput to resource it, are key aspects of the scoping exercise and RA. The involvement of the relevant Workforce Authority is therefore critical to the validity of the TNA and important in ensuring that the issues that overlap between personnel/workforce and training are fully integrated and understood by all parties from the outset. Training SME. If necessary, a training management SME should be represented in order to advise the chair on TNA management and methodology, ensure that the TNASG is representative of all stakeholders, compliant with the DSAT process, and that an audit trail exists. Other members. Membership can be extended as needed to include any other interested parties. For example, it may be prudent to include representation from Diversity and Inclusion (D&I), legal or security staffs. Role of the TNASG. The TNASG is responsible for ensuring that the training requirements are identified and met. It should therefore perform the following tasks, which should form the basis for its ToRs: develop and maintain a TSP. quality assure all TNA activities, particularly the (Stage 1) Scoping Exercise. brief potential Contractors and act as a point of contact for any requests for information or subject matter expertise. co-ordinate the activities of all contributors to the TNA. review and co-ordinate amendments to TNA outputs. endorse proposals affecting the TNA process or that amend outputs. endorse the most cost-effective training solution recommendation. assist in the design and delivery of the chosen training solution. Subjectivity. TNA governance is often complicated as individuals who act as stakeholders often double as the steering/working group representatives and are therefore closely involved in the development of the TNA. In other words there is potential for an element of subjectivity in the final decisions made. The TRA may have already decided on a training solution and wants the TNA to justify it. SMEs may have pre-conceptions regarding the operation/use of different Methods & Media (SMEs may not be training professionals and may not be fully aware of the options available); so the user should be aware of the potential to influence their decisions or statements. It is therefore much more 4 Such as, for example: a Warship, a Brigade, or an Air Wing. effective for a TNA to explore all possible options and identify the most suitable and cost- effective solution."
  },
  {
    "id": "7afcf7c8-fe1b-494f-8a00-92d55b572faf",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Support Plan",
    "content": "The TNASG should manage the TNA via the production and maintenance of a TSP. The TSP should identify any constraints on the TNA in terms of training policy or funding, ensuring that all the actions required to produce cost-effective training support are identified and the appropriate agencies tasked. The TSP should also specify when the TNA activities are to be conducted, who is responsible for the management and conduct of the TNA process and when and how the outputs are to be assured. Figure 2 illustrates the TSP in the wider TNA context. The TSP, governed by the TNASG should identify the milestones sufficient to meet the RFTD5. A RFTD should be considered at this stage, agreed and stated later as a ‘hard stop’ point, as part of the Training Authority Document (TrAD), which is produced at the end of Element 2 (Design). Figure 1: Training Support Plan (TSP) in the TNA Context 5 RFTD is defined as the point at which all the necessary resources required to conduct training have been accepted by the TRA."
  },
  {
    "id": "8af3431e-3109-4293-980c-afdd4a3b4df9",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The scoping exercise involves the initial analysis of the requirement and, where applicable, suggested options for meeting the requirement including a broad order estimate of the resource implications associated with each option. This is articulated in the Scoping Exercise Report. The scoping exercise should be completed as early as possible and starts by acquiring as much relevant information as possible about the training need and the Customer requirement. It defines the TNA management, risk, programming and resourcing within the boundaries of policy, assumptions and constraints. It also highlights issues that impact upon, or will need to be considered, during Stage 2. It will advise the TNA strategy for the proposed training solution and provide the parameters of the new or changed Defence requirement where TNAs will be, or have been, carried out. The scoping exercise does not have to be a long and protracted document and can utilise electronic references such as minutes of meetings, records of conversations to provide an auditable trail. Provided that a training need is confirmed then a search of existing training activities across Defence, including the DLE, is to be conducted to ascertain if training, already designed, could satisfy, or partly satisfy, the need. The scoping exercise should then outline the aim, constraint, assumptions, proposed methodology and timescales, and provide an estimate of the resources required for the subsequent analysis and design stages. The scoping exercise is the initial investigation and should derive a strategy and tentative solution for meeting the need for a training intervention. As this investigation progresses, decisions about how to apply the DSAT process should be made. For example, is it necessary to complete a full Role Analysis (RA) from first principles, or is it sufficient to confirm that an existing Role PS / Framework is still valid? Likewise, the strategy may recommend the process focuses on certain elements of a Role/task Performance which need further development or perhaps recommends targeting the TOs to ensure they support a Role PS and/or Framework. It may be decided that the sequence of training be reviewed if this is highlighted as a potential problem or that further consideration is given to current refresher training intervals. The scoping exercise should also cover a list of the resources required to complete the subsequent activities and an agreement as to which organisation(s) will provide them."
  },
  {
    "id": "48288664-191f-47be-97e8-f127926477ef",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "TNA Terms of References",
    "content": "It is important that clear TNA ToRs are produced to guide the subsequent analysis stages. They should be agreed and clearly understood by the TRA, stakeholders and the personnel undertaking the DSAT activities. A considerable amount of resources may be required to carry out these analyses and these should be made explicit within the ToRs. Although the layout of ToRs may be adjusted to meet specific circumstances there are a number of key areas that should be considered: the scope and size of the TNA. constraints, risks and assumptions. outputs and reporting procedures. timescales and resources available. the methodology to be adopted."
  },
  {
    "id": "8527acc6-20fd-4994-914b-107596ff21a3",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "TNA Plan",
    "content": "In order to estimate the timescales for the TNA it may be necessary to generate a plan, for inclusion with the ToRs. A plan should detail the milestone dates for each activity to enable reviews by the relevant stakeholders. The TNASG is responsible for ensuring that these activities take place. It need not be detailed but as a minimum it should include what is to be done, by whom and when."
  },
  {
    "id": "391713e9-b1e6-43ae-90bd-f179343b51f5",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Audience (and Throughput) Description",
    "content": "An estimate of who will be affected by the new or changed Defence requirement is required to ensure that it is representative and to determine throughput and input standards. It should include an estimate of the population to be trained in terms of their personal characteristics, the annual throughput and the input standard6. This information can then be used to inform and refine the SOTR (5.5). Identification of personal characteristics. In the course of analysing a particular role, it is often the case that to carry out the role effectively, an individual should possess certain characteristics. If this is so, then it is important to determine an appropriate balance between selection and training in order to provide people who have these characteristics and who are, therefore, capable of doing the role. The training audience is the group of learners for whom the training requirement is intended. The purpose of this description is to identify the: training audience groupings, the number and type of groups that need to be addressed (e.g. operator, maintainer, manager, train-the-trainer; individual, team, unit etc). social and demographic characteristics of each of the training audience groups. subject matter competence (in terms of KSA) of each of the group on entering training. This could include identifying any key entry standards. size and annual training throughput requirements of each of the training audience groups. Training audience. Analysts should consider potential members of the training audience from across the training continuum, from individual through team to collective. This is critical to assist in determining cost-effective training options. Individual. Users should identify all individuals who require training, and possibly at what stages in the training continuum they will be required to be trained. If possible, analysts should also identify the relevant individual career training pipelines and identify the optimal stage for any new training to be delivered. Users should identify the appropriate rank and branch/specialisation of all individuals requiring training; and consider individuals who could require training from across all Defence Lines of Development (DLoDs), and not limit thinking to a single area. Team and sub-team. Seldom will individuals operate alone; they will almost always constitute part of a team. Users should therefore identify the teams and sub- teams that will require training.  A team is a sub-division of an individual unit’s 6 The Defence Human Factors Integration Policy for Defence Systems (JSP 912) also requires the development of a Target Audience Description so there is the potential for re-use of information here. personnel, (e.g. a ship would comprise teams operating on the bridge, in the operations room, in the ship control centre etc). Teams can sometimes then be sub- divided further into sub-teams. Users should identify the individuals who will constitute the teams/sub-teams so that the capacity and size of any potential team training solution can be determined. Social and demographic characteristics. Social and demographic characteristics of the training audience provide an early training analysis that assists in determining appropriate and cost-effective training solutions. The type and scope of information required for each training audience should be determined by the complexity of the performance requirement and the size and complexity of the training audience. This list, whilst not exhaustive, should serve as a guide as to what to consider: Physique, health and appearance. Such as particular requirements for eyesight, hearing, manual dexterity height, weight, fitness standards, build and appearance. Cognitive ability. It may be important to indicate either the general cognitive ability required, or minimum scores required on specific tests. Special aptitudes. Such as special aptitudes for mechanical ability, manual dexterity, skill with words, skill with figures, artistic ability, musical ability. Digital literacy. Information and Communication Technology abilities and wider digital literacy characteristics should be considered and not assumed. This analysis should include the abilities of the trainees, trainers and course designers. Interests. A personal particular interest in a career-type, e.g. nursing or policing require people who have a desire to do this sort of work if they are to be successful at it. Disposition. Some roles require people with initiative while others require someone who can tolerate routine and repetitive work. Learning styles. Such as reading ability, attitudes towards potential training delivery systems, impact of Specific Learning Differences (SpLD), ICT etc. Motivation. Such as willingness or motivation to attend training or career implications and career cycles as they relate to the training. Personal data. Such as age, sex, rank, length of Service, ethnicity, cultural characteristics/biases etc. Geographic location / organisational distribution. These factors may result in certain constraints/considerations. Subject matter competence. Information needs to be collected on (or assumptions made about) the role-related competences (KSAs) in which the training audience is already proficient. The training audience’s level of KSA with respect to the Performance requirements is a factor, which depends mainly on previous related training, experience and recruitment profiles. Information should be obtained on: experience with the training performance (and how it was obtained). ability to perform any part of the requirement. knowledge of the subject matter (and how it was acquired). positive or negative perceptions of the subject matter. perception of the impact of mastering the Performance requirements on self, work, career. Existing competences. When identifying the training audience, analysts should also establish whether individuals will be required to have any existing competences or experience levels prior to exploiting the new capability (pre-requisite analysis). Some of these competences may also be required by trainer/training support staff to enable them to assess performance and develop training activities. Example criteria include: establishing whether or not an individual’s existing competences are sufficient for them to safely operate or maintain the new capability. identifying what level of rank is required to exploit the capability. establishing the minimum level of experience required (such as, number of flying hours, previous command experience, specific operational experience etc). establishing the minimum qualification required (such as, charge qualified, command qualified, category ‘A’ nuclear watch keeper etc). Pre-requisites analysis. Pre-requisites analysis can be used to inform the training solution recommendations and is an important measure of competence/entry standard prior to training. This enables more accurate measures of competence ‘before and after’ training to be taken, thereby facilitating measures of effectiveness of the training solution in delivering the required output standards. Training throughput. An estimate of training throughput numbers (total audience and annual throughput requirements) will inform requirements for the size and capacity of the potential training solution and must be made available to inform the SOTR process. The SOTR forecasts annual throughput requirements 4 years in advance, in order to help generate the required capability. Throughput numbers may be required in support of a variety of related training solutions for each distinct training audience group. Throughput figures should be calculated separately for each type of training required and for all affected Defence people, MoD civilians and Contractors. Training throughput figures should be presented in table or graph format, along with any throughput assumptions. Training throughput figures for all training audiences can then be used as separate requirements to be considered by users in generating potential training solutions. These factors should be considered when estimating the throughput numbers: average lengths of assignment. per cent posted to similar role in a different location (such as, will not need to be retrained to assume role responsibilities). recertification issues (such as, how long is the training valid for). promotion cycle and its potential impact on training numbers (such as, number of target audience who will be promoted during their assignment). historic data on pass rates, if applicable. any known contractual constraints. consideration for civilians and contractors who may need to attend the training. any known throughput constraints on pre-requisite training. potential competition with other training activities."
  },
  {
    "id": "3a4d1e06-1ef4-45db-b31f-1a820e25bd3f",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Constraints Analysis",
    "content": "Any constraints affecting the TNA need to be analysed and highlighted to ensure that risks regarding financial, safety and technical issues are addressed. The TNA process should initially focus on satisfying the strategic need with the caveat that proposed training solutions are compared with the initial constraints as part of the TOA and/or EA. Further constraints are the timing/development of the TNA, accessibility to SMEs and Intellectual Property Rights (IPR). The TNA may be directed to examine a particular potential training solution, however, without prejudicing the final outcome. Constraints may also be identified in strategic trends, doctrine, concept documents (e.g. the Concept of Employment for a capability) or can be determined through contextual analysis (such as via PESTLE7 or other frameworks). They should also involve consideration of all the Defence Lines of Development (DLoDs)8. Key constraints include: Policy. On occasion, Defence Policy will dictate the Methods and Media to be used. The TNA should adhere to the DTEL Rules9 and Defence Policy for Modelling & Simulation (M&S) (), as well as taking account of policies on the use of the  10 and Human Factors Integration for Defence Systems (). SCs may also mandate the use of specific training environments or solutions, which should be documented. Cost. Restrictions may be placed on the TNA by affordability considerations, which may restrict the number or scope of training options but could also take into account Value for Money (VfM) through-life (e.g. where investment has already been 7 Political, Economic, Social, Technological, Legal and Environmental. 8 Training, Equipment, Personnel, Information, Concepts and Doctrine, Organisation, Infrastructure and Logistics, along with Interoperability. 9 Contained within Volume 6 of the JSP 822. 10 See made in training and, for economic reasons11, it is advisable to build upon existing capability rather than acquire new systems). Any analysis of cost constraints should always consider capabilities through-life. Time. Analysis is invariably conducted under time pressures, including the need to meet deadlines such as Initial or Full Operating Capability (I/FOC). Therefore, the TNA should consider any prioritisation that needs to be taken account of and then constrain the analysis accordingly. Safety. Training environments can be constrained by safety considerations, such as on the use of live fire or requirements imposed by safety cases. Note that, regardless of training solution, there is likely to be a requirement to conduct operating assurance through the use of live equipment. Legal. There may be restrictions on training due to legal requirements, such as mandated hours for aircraft control duties or flying, as well as Care and Welfare responsibilities. Acts of Parliament may also influence training options. Resource. Analysis should take into account the unavailability or limited availability of both training audiences and potential training support requirements12. Given the significant impact these constraints may have, the TNA should commence with their identification and risk management13, noting the potential impact and options for mitigating any threats or the consequences of constraints. From this analysis, a constraints table, risk register and an assumptions register (including a Master Data Assumptions List as required) should be compiled and maintained by the analyst and reviewed by the TNASG, noting that a constraints analysis is an iterative process and may determine that a training intervention is not the most appropriate way to address the Defence need."
  },
  {
    "id": "25c23d3d-ff43-4e20-ab7c-af392457074b",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "The Scoping Exercise Report",
    "content": "The scoping exercise report is an output of the Scoping Exercise, detailing what is appropriate to the training need and, importantly, make training solution recommendations. It should include: references to the relevant training policies. assumptions, freedoms and constraints14. 11 That is, in order to potentially optimise efficiency and effectiveness. 12 For example, access to training areas and the capacity of existing training solutions or infrastructure. 13 To be undertaken in accordance with the Cabinet Office’s Management of Risk Best Practice Guidance. 14 Including current resourcing such as course design and the digital skills of trainers and designers. the conclusions, outputs or recommendations of previous relevant studies (if any). membership of TNASG that will oversee the subsequent analysis stage. recommendation to continue with the TNA if appropriate. TNA outputs. TNA Terms of Reference (ToR). confirmation (or otherwise) that there is a training requirement that will fulfil the SOR (if there is not, the DSAT process should then cease). recommended possible training solution option(s) to be taken forward into the analysis and design stages. a section on risk. Training solution recommendations. Training solution recommendations should be examined by the relevant stakeholders at the TNASG. Taking into account time and resources, it will decide the most appropriate way of taking the requirement forward. Where a training solution is recommended and agreed at the TNASG, a plan for subsequent analysis and design activities should be produced. If a training solution is not recommended, the DSAT process should be halted at this point. However, a response to the question, ‘what should we do to address these deficiencies?’ should be given. The problem may not have anything to do with training and may require: a revision of procedures and/or improvements to management and supervision. production of role/task aides and/or the reallocation of tasks. changes in the approach to personnel selection. acquisition of equipment. workforce incentives, such as pay and civilian qualifications. The Scoping Exercise Report may include as documented evidence to inform future decisions: Summary of new/changed requirement. A summary description should outline the proposed capability or technology/equipment and the benefits of the new or changed training requirement in the context of the Defence effect. This will enable the identification of the nature of the training gap and underpin areas requiring analysis (e.g. are there any changes to CONOPS; what changes are system/equipment function related; are there any impacts upon workforce structures?). Policy. Influences concerning policy 15 can affect the TNA strategy and can include various freedoms and constraints placed upon the Training Provider, such as: roles, tasks, structures, workforce levels, finance limits, Health and Safety 15 Particular reference should be made to the Service policies/directives for individual training requirements, minimum qualification levels for prospective role holders and/or tasks, and any accreditation or legislative issues. Previous/associated studies. Reference to and use of previous or associated studies is strongly recommended. Information sources include previous TNAs, Human Factors (HF) studies and evaluation reports on similar requirement(s). For major projects, where more than one TNA is being undertaken, it can be useful to indicate the relationship between the various TNAs. Potential training services. The major types of training Methods & Media likely to be considered or examined should be included at this stage and then re-examined later. This will reflect the current training policy and should specify any areas requiring particular attention, such as the possible need for synthetic training, embedded training or Public/Private Partnership or Private Finance Initiative (PPP/PFI) solutions. These are only possible options and may change during the TOA/EA as a result of developments in policy, technology etc. An estimate of the cost of these services should be provided. Any new training solutions may have to utilise existing training facilities and associated established support elements (ie course design) which should be recorded in the report. Methodology. The TNA methodology should be tailored to suit the specific training requirement but should always provide a full audit trail. For example, in the case of a small change to training policy, a TGA followed by a TOA to establish the most cost-effective Methods & Media would be sufficient. Equally, if the training is to fit into an existing training activity using similar delivery techniques and Media, then a full blown TNA may be unnecessary. The outputs from the scoping exercise and subsequent analyses should be agreed during Stage 1 of the TNA, which will allow the user to select the correct methodology and tools based on the constraints and information available at the time. Analysis should not be conducted as a ‘check list exercise’, but should only be undertaken if it adds value to the TNA. TNA is an iterative process and the TNA outputs are therefore subject to continuous review. Resources. An estimate of the resource allocation should be made to include the following: sources of information required including documentation and access to SMEs. procedure for the review and TNASG endorsement of the Training Needs Report. Cost of Ownership (COO) concerning the responsibility and allocation of funding across the affected budget holders for the design, installation, operation and supportability of the recommended training solution. sources of SME assistance, if applicable, the training workforce and facilities currently available."
  },
  {
    "id": "806a235f-011a-4f39-bf20-d8915196fd96",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The duties, tasks16, sub-tasks and task-elements performed by an individual constitute ‘the Role’17. The RA is the process of examining a specific Role in detail, in order to identify all the component duties and tasks, the Conditions under which the Role is performed, and the Standards to be achieved when performing the Role. The ‘person in the Role’ should also be considered. In this way, it will be possible to identify the Knowledge, Skills and Attitudes/behaviours necessary for effective performance. The RA should examine: role objective and responsibilities. principal duties and supporting tasks, i.e. the Performance and the Knowledge, Skills and Attitudes required to perform the Role. levels of supervision. the conditions which cover environment, work conditions and equipment, for example. Role Standards. aspects of the Role found to be distasteful or unpleasant. frequency of task performance and percentage of personnel performing the tasks. likely job changes and consequences of inadequate performance. task criticality. Role-related factors influencing knowledge and skill fade (or competence retention). 16Task is a major component of a Role or duty that can be produced, compiled, achieved and/or accomplished by itself. 17 A ‘job’ can be made up of many Roles. Therefore, it can be argued that jobs (in the traditional sense of a person conducting a single task requiring a single skill, for example) seldom exist. Accordingly, it is more appropriate to analyse a Role that a person will fulfil. An example would be a RN Catering Services rating, who is trained in the primary Role but routinely has other Roles and duties aboard ship that are not related to the primary role (such as firefighting and First Aid). Training that person for the job of Catering Services/Fire Fighter/First Aider is impractical, but training that person for the primary Role , then the Role of fire fighter and the First Aider makes more sense. Thus RA is a more logical term than Job Analysis and more reflective of what this analysis actually does."
  },
  {
    "id": "166f6807-a23f-47f6-958d-2e3700de0ca9",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Identification of Role",
    "content": "There is a danger of concentrating wholly on the Role and so there is a requirement to widen the perspective to consider it in context. A Role does not exist in isolation but within the context of a particular organisation and situation. This context may affect not only the way the RA is conducted but also the eventual design of the training solution. As part of the identification process, users may wish to produce a Role Specification 18 and/or Role Description within the context of the individual Role, taking into consideration the factors listed below. Any identification process should consider: higher level context, including strategic context operational doctrine and team/collective scenarios. external context, including wider environment and conditions, for both individual and team/collective, and number of personnel fulfilling the Role. internal context, such as organisational structures, Role dependencies, relationships and responsibilities, and the training audience, throughput and selection processes. As part of the Role identification process, it may be useful to consider: Role objectives. Main. A short, concise statement of the main objective of the Role, phrased in terms of the Performance expected. It should begin with a verb denoting action. Vague terms such as ‘to know’ or ‘to understand’ should be avoided. Subsidiary. Written in the same format, these either amplify the main objective by showing what must be done to achieve it or indicate additional areas of Performance within the Role. Duties and tasks. Duties are the principal activities of the Role holder, are directly related to the Role and are subordinate to the overall Role objectives. They can then be broken down into their component tasks, sub-tasks and task-elements. This is achieved through the Production of a Role Scalar which is discussed later. Standards. The Standards necessary for the satisfactory Role Performance should be considered and recorded. Conditions. The Conditions under which the Role is performed. An exhaustive list of every trivial condition is not necessary and only the important Conditions should 18 TAFMIS has forms entitled ‘Role Specification’ and ‘Role Description’ to assist with this process. be recorded. The breakdown of Conditions into categories of ‘physical’, ‘intrinsic’, ‘social’ and ‘psychological’ may be used. Responsibilities. Responsibilities should be listed under the headings of ‘to superiors’ and ‘for subordinates’. It would also be convenient to include under ‘responsibilities’ information to the degree of supervision exercised over the Role holder and the extent to which they would be held accountable for their own work or the work of others. This helps set the context. Difficulties and distastes. This information can indicate the areas that need to be emphasised in training. Criticality. The relative criticality of a task within a given Role should be listed using pre-defined categories (e.g. high, moderate, low). This information can be used to inform risk management activities and decision-making relating to refresher training requirements. Role-related factors influencing skill fade. An identification of key factors influencing skill fade. It will be useful to consider both positive and negative influences on skill fade so that the impact of changes to the design of the Role (e.g. increased or reduced complexity, modifications to equipment design and associated resources) can be assessed. This information, along with the KSA, Difficulty, Importance, Frequency (DIF) and criticality analyses will help to inform the identification of appropriate training Methods & Media for both the acquisition and refreshment of Role-related skills and knowledge."
  },
  {
    "id": "ab9cfc68-6835-4f49-925c-c5c2ab849d4b",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "5.7\tProduction of Role Scalar",
    "content": "A Role Scalar is produced by analysing the duties, tasks, sub-tasks and task-elements (Performance) that have to be performed and recording them diagrammatically. The Production of the Role Scalar is a key part of the RA process as it defines the minimum Performance to be achieved in the Defence environment. Tasks within a Role should contain an object, a verb19 and sometimes a qualifier. An example of a task statement would be: 'perform a daily routine service on a diesel engine’. A task can be defined as: a specific action. performed by an individual. recognised by a definite beginning and an end. 19 The choice of verb is critical when writing tasks, sub-tasks (and, later, training objectives). Verbs must be observable and measurable. More guidance on this aspect of Analysis and Design is given on the DSAT courses delivered at DCTS. performed for a relatively short period of time (could be hours but rarely days). observable and measurable. The four levels within a Role Scalar are as follows: Duties. The major functions, or areas of responsibility, of the Role. They have no specific start or finish and tend to be general in nature (e.g. act as Unit Health and Safety Advisor). Tasks. Major components of the Role that can be produced, compiled, achieved and/or accomplished by the individual. Each duty usually contains a number of closely related tasks that are essential for carrying out the duty. Sub-tasks. Sub-tasks are the component parts of each task. Task-elements. Task-elements are the sequenced step-by-step component of each sub-task. The usual convention for the levels of a Role Scalar is shown in Figure 3. Figure 2: Role Scalar Levels Numbering system. It is important to employ a hierarchical numbering system within a Role Scalar, as often it is cross-referenced to other training documentation. The numbering system should indicate the level and relationship of the particular components of the Role. An example of a numbering system is shown in Figure 4. Figure 3: Role Scalar Numbering System Role Scalars are particularly useful tools for: displaying a structure to the Role that may not be apparent in real life. illustrating the relationship and interdependence of the various parts of the Role. The impact of a failure to perform any particular task can therefore be determined. showing areas of commonality and difference between closely related Roles, thus indicating where rational restructuring could take place. showing tasks to be performed with new equipment, related to existing Roles, and thus help assess the impact of new equipment. the production of a Role PS, Framework(s) and TOs. Role Scalars also have disadvantages that should be considered: they do not contain Standards and Conditions and appear to give all tasks an equal importance. An important consideration in developing the structure of a Role is the aim to describe what the Role holder does, or should be capable of doing, and not what they need to know. Determining the knowledge that is required to successfully perform a task happens during the KSA Analysis. Role Scalars cannot in themselves be used to design training and should be supported by a full Role PS and/or Framework(s). However, they are a vital step in the production of required outputs such as a Role PS, Framework(s) and TOs."
  },
  {
    "id": "c4ed71b4-f14f-4627-9e94-7867f05b3709",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "DIF Analysis",
    "content": "DIF Analysis is a method of analysing Role information through the Difficulty, Importance and Frequency (DIF) of tasks and sub-tasks, with the aim of enabling early training decisions, such as the generation of Initial Training Categories20. DIF Analysis provides an indication of the priority and standard to be applied to the training. The DIF Analysis assesses the difficulty, importance and frequency of tasks using a simple algorithm, which is shown in Table 1. Table 1: A DIF Analysis Algorithm 20 In TAFMIS, Initial Training Categories are listed as DIF Training Categories. As DIF Analysis relies on subjective data it is essential that each level is clearly defined to try and increase the reliability of the data. Suggested definitions used within the DIF Analysis are as follows: Difficulty assesses the chance of performance error by asking the question: “What is the possibility of inadequate performance from the average job holder?” The range can be defined by using two extreme statements, namely, ‘The task is easily performed once learnt’ to, ‘The task requires constant practice and supervision’. Importance, assumes that performance error is made and assesses the impact of the error by asking the following question: “What is the impact/consequence to operational capability, safety, lost revenue and public relations if the task is performed inadequately?” Once again the range can be defined by using two extreme statements, for example, ‘Failure is unlikely to have any impact upon operational capability or well being of personnel or equipment’ to ‘Failure will have an immediate and severe impact upon operational capability or risk of severe injury or damage to equipment’. Frequent tasks may or may not be Important or Difficult and scales may range from ‘Once or more a day’ to ‘Once a year’ to ‘Never’ (if the task has changed then the requirement to carry out specific sub-tasks may have reduced to nothing). Task frequency becomes significant, however, when considering retraining, since frequently performed tasks do not require retraining if performance is adequate. The following factors may be included during analysis to collect information for future use: Relative time spent on the task (very much above average, above average, below, average, average, very much below average). Actual time spent on task. Frequency of performance (day, week, month, year). An assessment of difficulty encountered in carrying out each task, the importance of each task to the achievement of the main job objective and the frequency with which tasks are performed, are key factors in making training decisions and priorities. DIF analysis is a useful technique which contributes to providing a rational basis for making decisions on the design of training which is superior to guesswork or intuition. However, other criteria may be used to decide upon levels of training; including numbers of service personnel performing the task, ease of training within the unit, how soon after training someone is expected to perform the task and how much time is spent performing the task."
  },
  {
    "id": "55199028-dc06-4c97-816b-06bfe7d9a003",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Knowledge, Skills and Attitude Analysis",
    "content": "A KSA Analysis is a systematic analysis of ‘Performance’ and/or ‘Standards’ in order to identify the necessary KSA required to perform a Role. A KSA Analysis moves on from what the Role holder does (captured in the Role Scalar), to identifying the KSA that have to be learned to perform the task. The results of an Initial KSA Analysis will help with the generation of Training Objectives and Enabling Objectives and the selection of the most appropriate training Methods & Media, during Element 2 (Design). Two examples of Initial KSA Analysis relating to a Role are at Annex A. Knowledge. Knowledge is information acquired through experience or education; the theoretical or practical understanding of a subject. Knowledge generally involves recalling information, e.g. the knowledge of rules and regulations, names, sequences, classifications, methodology, events, principles or theories. Whenever a task is performed, knowledge is required. When carrying out a task, a possible pre-requisite is knowledge of: When to perform; what are appropriate tactics, techniques, procedures, tools or materials? Where are the tactics, techniques, procedures, components, materials and/or equipment? How to use/operate the tactics, techniques, procedures, materials, tools and/or equipment? What are the safety procedures or constraints; what possible dangers are there? What are the testing or checking requirements and procedures involved? What constitutes task completion? It is important to note that a Role PS can refer directly to a requirement for knowledge when it is linked to the practical performance in a Role as stated in the Role PS. KSA Analysis identifies the supporting knowledge required for task performance. Training should only contain knowledge which is essential to the satisfactory performance of a task. For example, where key references are available at the time a task is performed, there may only be a requirement to learn how to access the information rather than learn the contents. Wider knowledge acquisition and application is the remit of education. Skills. A skill is defined as an organised and co-ordinated pattern of mental and/or physical activity. It is the ability to do something well. It is built up gradually by repeated correct training or practice. At Initial KSA analysis, the skills listed are kept quite high level. Later on in the Design process the split into mental and physical/practical skills can be further refined: Mental skills. These constitute the knowing how (procedural knowledge) as opposed to the knowing what (facts) (e.g. knowing how to calculate percentages, knowing how to interpret technical data, knowing how to classify sonar contacts). It would not be possible for the trainee to learn all of these things as facts because too many individual instances exist. The mental skills the trainee learns, therefore, enable them to respond to entire classes of situations, e.g. to make decisions when presented with information and alternative courses of action. Physical/practical skills. These can be described as learned capabilities of performing actions in an organised and fluid manner. They are overt and observable during their performance. Skills may be discrete (operate a switch) or continuous (fly/drive a vehicle). These skills are learned in connection with common activities such as using a computer, driving a car or playing a musical instrument. Many tasks performed in Defence can be categorised as having a large physical component, e.g. stripping and assembling a weapon (discrete), flying an aircraft (continuous) and tying a bowline (discrete). Complex physical skills can often be broken down into smaller sub-skills, which can be learned separately and then put together for total performance. An example of this is swimming, which has 3 sub-skills (arm action, leg action and breathing technique), which can be learned and practised separately and then performed as one. More complex skills such as flying/driving, are similarly broken down into their component parts and taught as discrete skills in discrete lessons. Attitudes. An Attitude is a way of thinking and feeling about something, often but not always demonstrated through behaviour. The identification of Standards relating to personal qualities and Attitudes is perhaps the most challenging part of the KSA Analysis. This is because Attitudes cannot always be observed directly and hence the creation of definable standards can prove difficult. Attitude is defined as a predisposition resulting in a tendency to act or react in a certain manner when confronted with another person, group, object, situation or idea. It is important to understand that this predisposition to think and feel in a certain way does not necessarily result in observable behaviours. An example of this could be an individual who holds an Attitude that all dogs are dangerous. However, this attitude may not be obvious to others when the individual is handling a dog with which they are familiar and have learned is friendly. Table 2 illustrates how Attitudes can manifest themselves. Table 2: Attitudes Within each role there are tasks that have an attitudinal component related to their performance. Initial KSA Analysis identifies Attitudes associated with role performance to determine the required direction of that attitude. At this stage the Analysis of Attitude can be quite high level. The depth of the analysis within the attitudinal domain will occur at course design stage/A Spec stage. Once the Attitudes required to fulfil a Role are identified, training can be designed to achieve them. Knowledge and skill training can be wasted if attitudinal training is ignored. A lecture on computer security may be successful in imparting information on how viruses are transmitted but unless it develops an attitude of security consciousness the trainees may not use the knowledge they have gained on the subject. To assess an attitude, behaviour must be observed, possibly over a period of time. To assist subjective judgements on attitude an objective criteria should, where possible, be used to support the decision. Defining the negative, what is unacceptable behaviour, can result in a simpler and more precise Standard. A Behaviourally Anchored Rating Scale (BARS) is an example of a tool which can be used to assess observable behaviour objectively. Although a BARS (Table 3) can be used to measure attitude indirectly through observing behaviour, much care is needed when inferring Attitudes from observable behaviours alone. Attitudes may also be directly measured using validated questionnaires or other psychometric instruments21. Some examples are presented in Table 3. Note that whilst BARS is predominantly a tool used in the training environment, forming part of the ASpec if appropriate, it is mentioned here because it is useful to bear it in mind at the RA stage. COMMUNICATION Table 3: Behaviourally Anchored Rating Scale Although Attitudes may be inferred from observable behaviours this is prone to biases (e.g. a group of soldiers may set up an Observation Point (OP) with no attempt to camouflage their position.  This might infer that they do not care (Attitude) about 21 Defence uses a Continuous Attitude Survey which measure and captures Attitudes towards many aspects of military life. concealment. However, they may simply not know (Knowledge), or have forgotten about concealment rather than not care about it. Similarly, they may lack the ability (Skill) to properly conceal their OP). Before remedial training is implemented, identifying the correct domain is critical. Targeting an Attitude may be inappropriate if the knowledge or practical Skill is lacking. In order to develop an optimised training system it is important to consider both how Knowledge, Skills and Attitudes are acquired and how they are retained over time. Understanding the rate at which different types of Knowledge and Skills fade can inform training design and the setting of refresher training intervals. In order to conduct refresher training interval analysis, it can be useful to use a more detailed breakdown of Knowledge and Skills than that discussed in DSAT activity – Initial Knowledge, Skills, Attitudes (KSA) Analysis. Literature from psychology and cognitive science suggests that Knowledge and Skills can be broken down as shown in Table 4. Table 4: Knowledge and Skills Domains Without practice, continuous psychomotor skills and explicit knowledge are retained for the longest; discrete psychomotor and decision-making skills have moderate retention over time and procedural skills fade the most quickly. The retention of Knowledge and Skills over time is moderated or influenced by how often the task is performed or practised. Table 5 shows the impact of task performance frequency on the retention of the different types of Knowledge and Skills. For example, if discrete psychomotor skills are performed very frequently then the retention level is High. However, if performed infrequently then the retention level is reduced to moderate. Table 5: Effect of Task Frequency on Knowledge/Skill Retention The retention level of the Knowledge and Skills for a given task should be taken into account when setting refresher training intervals. It is important to note that a number of role-related factors (in addition to frequency of task performance) can also influence Knowledge and Skill fade, e.g. designing equipment, job aids and operating procedures in accordance with good practice (which includes built-in user feedback for equipment and interfaces, logical steps within procedures). Training methods, media and assessment regimes which ensure the effective acquisition of knowledge and skills in the first place also help to reduce skill fade. Table 6 provides a summary of training ‘strategies’ which can be used to improve knowledge and skill retention. The first column indicates which types of knowledge and skill the strategy is relevant to. Table 6: Training Strategies to Improve Retention of Knowledge and Skills"
  },
  {
    "id": "97b9d0e3-032c-4463-84f1-71c86e3758bc",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Initial Training Categorisation",
    "content": "A thoroughly conducted RA will be wide ranging and will include consideration of levels of supervision, work conditions, task criticality, difficulties and distastes, frequency of task performance, Role-related skill fade factors, percentage of personnel performing the Role and consequences of inadequate performance. All of this information, in conjunction with information on trainee entry standards, trainee throughput and knowledge of the likely training environment, can lead to conclusions regarding the balance between training delivered as part of the TPS and training delivered as part of the WTS. These conclusions are expressed through the use of training categories. A number of techniques may be used to derive training categories, with the main analytical tool being the DIF Analysis already conducted. Training categories are defined in Table 7. Table 7: Training Category Definitions22 Other criteria influencing training categories. Once a suggested training category has been selected (using information from the DIF Analysis), it should be subject to further review as other factors may result in an increase or decrease in category. Other criteria that may influence the training categories that relate to the Role environment are listed below: How many people perform the task? This may determine the need for training and the priority given. How much time is spent on the task? This can sometimes be more important than frequency. Realism and safety. These considerations may make it impossible to conduct any training. Tasks falling into this category, and how they are dealt with, are covered in the next section (Element 2, Design, 2.2.3, RTGS). Degree of supervision in the workplace. If closely supervised when performing a task, the training category may be reduced since the supervisor can detect errors in- role and then correct them. Time interval between training and first performing the task. The training Standards may deliberately be higher than the required Defence standard in terms of timing or accuracy to avoid knowledge/skill fade. 22 It is recognised that Training Categories require further review to reflect the blended approach to Defence training. Legislation, regulations and government policy. Regardless of training category, a task may have to be included in training if those trained are to be authorised to carry out the task. Legally mandated civilian accreditation. The inclusion of training for a task originally allocated a low category may be critical for obtaining legally mandated civilian accreditation, which is a mandated requirement of that Role. An example is the requirement to obtain a civilian driving licence before progressing to driving military vehicles."
  },
  {
    "id": "8b9fe591-c186-4d2d-a1d5-446068f579a4",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Role Performance Statement",
    "content": "A Role PS is produced and maintained by the TRA and is a detailed statement of the tasks, sub-tasks and so forth that are required to be undertaken by an individual to achieve the articulated workplace Performance. It includes the Conditions under which the tasks will be undertaken, the Standards that must be achieved, and adds an indication of the importance of the training required to achieve the task Performance. It forms the basis for all subsequent work leading to the production of TOs. This ensures that the need for training and associated resources is justified by the needs of the Role. It also ensures that the training undertaken remains focused on the Role. Whilst a single Role PS can be produced to cover all the duties associated with a Role, a Role PS may alternatively be written for a specific duty where it is shared across many Roles (such as the duty of firefighting). The Role PS is developed using: Role Scalar. Carry across the duty, task and, if appropriate, sub-task statements from the Role Scalar. The numbering system used should be used on the Role PS to ensure the two documents are linked. Conditions. Identify and list the important Conditions under which the tasks will be performed (an exhaustive list of every trivial condition is not necessary). The Conditions statements should specify the physical location, level of supervision and any other particular environmental factors associated with the task. It may be helpful to breakdown the Conditions into categories of ‘physical’, ‘intrinsic’, ‘social’ and ‘psychological’. Standards. Identify and list the Standards to which the tasks will be performed. They will be either: Product Standards. Minimum absolute Standards, such as time, accuracy and safety limits. Process Standards. It may be important that certain procedures are followed in a particular sequence in order to successfully achieve the Performance. Often these will be listed in a technical manual and the Standard may include a reference to this. If not, these steps may be given as process Standards and are the essential sub-tasks and task-elements from the HRA. Combination of Process and Product Standards. Where Standards are defined in more detail in other documents, the references should be in full and include the issue number and date. Where publications change frequently reference may be made to the ‘most recent issue’23. Training category. As covered in training categorisation (Section 3.3), this states the training level required to achieve the task Performance and the balance between training to be managed and/or delivered by the TDA (e.g. in a training establishment) and training conducted in the workplace. Tasks not requiring any training should also be identified. Performance, Conditions and Standards. It is essential that the Performance, Conditions and Standards identified reflect the realities of the Role. An example of a detailed Role PS format is at Annex A."
  },
  {
    "id": "95d14f71-d4ab-4e91-b792-ef64905b663b",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "8.7\tFrameworks",
    "content": "The user may wish, as a result of the RA (particularly the KSA Analysis), to consider the production of either a competence framework or competency framework, or both; either in addition to, or instead of, a Role PS. This could be done if a people focus, rather than pure task focus, is required. Competency & Competence. The human element of operational capability is a complex area to analyse. It is, however, important to understand both the people and training aspects, as different methodologies of analysis fit different needs, and, within the Defence context, they are sometimes confused. The relationship between competency, competence and performance needs to be understood in a consistent manner: Competency (plural: competencies) is the underlying characteristic(s) of an individual which results in effective and/or superior performance within a Role. OJAR/SJAR is an example of an organisational level competency framework that is common to all Service personnel. Professional competency frameworks can also be used in order to provide guidance to defined professional groups, such as the Royal Navy’s Command Competency Framework, where there is a need for longer term individual professional development and/or selection. Competence (plural: competences) is the measured ability of an individual to consistently perform a particular occupational skill or range of skills to a required Standard, under prescribed Conditions. The Role PS serves as the statement of the 23 In this instance, however, analysts must ensure that their references are up to date. Competence performance required for Defence under the DSAT model, articulating the skill orientated requirements of a Role. Although linguistically similar, competence and competency are distinct concepts. The essential distinction is between aspects of the role at which the individual is competent (the competence), and aspects of the individual that enable them to be competent (the competency). The relationship between competence, competency and performance is illustrated in Figure 5. INDIVIDUAL\tJOB What they are like\tWhat they can do Select & Develop COMPETENCY Source: Young, M. (2005). ‘A model linking competency, competence and performance’. Competency and Emotional Intelligence. Summer 2005. Figure 4: Relationships between Competency, Competence and Performance Figure 5 illustrates that both competency and competence are essential enablers of individual performance; they are not mutually exclusive. Selection, development (including education) and training have key roles in growing necessary competencies and competences. Therefore, effective human capability development should not neglect either; instead, consideration of both will result in optimal requirement setting and solution development. Competence development (in the form of a Role PS and associated training solutions) is covered under the DSAT training analysis process contained within this policy. Furthermore, DSAT derived training solutions may either require some competencies as a pre-requisite or be developed during a training solution (often at the EO level). Competence Frameworks Competence frameworks are not the sole preserve of Defence and many external bodies and organisations utilise and develop them. Where an external awarding body has already developed an appropriate competence framework (usually in the form of job-related standards/qualifications grouped under competence areas) it is acceptable within the DSAT process to utilise this, as appropriate, rather than developing bespoke a Role PS from scratch. This has the added benefit of easing the accreditation process and aiding skills transfer from both within Defence and externally (particularly during transition to civilian life). Furthermore, where similar competences are employed over a wide range of roles across Defence (e.g. more than one TLB), it may be appropriate to develop a competence framework for particular professions/trades in Defence. The use of an established competence framework does not absolve the analyst from capturing both the requirement and solution within the TrAD along with the necessary documentation; ensuring it is endorsed by the CEB. In particular, where a competence framework is used, CEBs should assure themselves that the solution does not greatly exceed the requirements of the role just in order to meet desirable external accreditation or to save resource expenditure on the analysis phase, which may be detrimental to the final training solution. Competency Frameworks Similarly, competency frameworks are also used outside of Defence as they are recognised to have applications across a whole range of developmental activities, including training. Competency frameworks are now seen as an essential vehicle for achieving organisational performance through the development of ‘human capital’ by reviewing individual capability and potential. Essentially, competency frameworks are a human resource tool and are generally used at organisational or functional level and can be used in selection, performance development and training. Competency frameworks are used to document required organisational behaviours, under grouped competency areas; such as Leadership, Communication, Problem-solving and Team-working. Where competency frameworks exist, it is acceptable to use them within DSAT, if the behavioural descriptors are appropriate within the context of Defence."
  },
  {
    "id": "b72d7e00-5b92-420d-a178-12bd972c194f",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "8.7  Recommended Further Reading",
    "content": "Competence Retention Analysis Handbook. Competence Retention Analysis (CRA) is a scientific methodology developed as a practical approach to predicting the retention of different knowledge and skills that underpin military tasks at the workforce level. CRA is intended to assist Defence to reduce the impact of skill fade and enhance competence retention. It is relevant to two audiences as follows: Training analysts can use the outputs of CRA during the Training Needs Analysis (TNA) process to justify training solutions and the training budget; and Training designers can use the outputs of CRA during the design phase to inform the scheduling of refresher training or practice intervals, and during the development of training to mitigate knowledge and skills fade. CRA can also be used retrospectively to improve training design and to inform decision making about the specification of training priorities (initial and refresher), where issues are identified during the TNA evaluation process. Link:"
  },
  {
    "id": "ab23e0f1-da26-4061-a475-b70760053151",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The purpose of the TGA is to identify the additional training requirement of the affected Role holders by determining the training gap between the Performance as stated in the Role PS / Framework(s), and any existing training Performance Standard(s). This analysis also enables the impact upon Defence capability to be assessed if the new or changed Defence capability is implemented without additional training. The TGA should provide: an update of the information contained in the Scoping Exercise Report and RA (if required). the additional learning requirements, if any, of the Role holders in terms of KSA at the sub-task and task-element levels. a summary statement of the tasks identified for training. statements of Training Gaps24, in terms of any Performance delta, between the requirements of the Role PS / Framework(s) and any existing TOs. The decision whether to provide additional training or not, by providing a summary of the implications of the new Performance requirements when compared to existing training. This should be presented as statements for each task, identifying additional workplace and unit training requirements with a statement of any associated penalties regarding reduction in capability. If the option to continue existing training with existing resources is an acceptable risk for all Role PS identified in the RA, then the TNA is complete and a TOA may not be required. Whilst the TNA is designed to look at the gap that cannot be delivered by existing training, it should also consider the resource implications on existing training activities and the ability of those Training Providers to deliver in respect of a change in training throughput. 24 There may be multiple training gaps. For example, there will be two gaps if some personnel are migrating from a predecessor system to a new system, while others are coming directly from basic training to the new system. Early knowledge of workforce plans is important; if this information is unavailable, assumptions must be made and clearly stated."
  },
  {
    "id": "b032ca04-d376-49af-8500-09b9c0836644",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Statement of Training Gaps",
    "content": "These are statements in terms of the Performance delta between the requirements of the Role PS / Framework(s) and any existing TOs and EOs, including associated specialist qualifications, for each affected Role holder. These gaps represent the impact on the training requirement for the continuation of existing training using existing resources."
  },
  {
    "id": "b4be1ba3-e6f3-4798-9475-04fc46288446",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Objectives",
    "content": "TOs ensure that the training activity has a definite purpose such that the Defence need is met. They help ensure that the associated trainers, support staff and trainees have a clear understanding of what the trainees are required to learn and to be able to do at the end of the lesson/learning event. TOs form the basis of the detailed design of each of the training lessons as well as identification of appropriate training resources. They may also be used in support of the award of civilian accreditation. Therefore, the development and maintenance of accurate TOs is essential. TOs are drafted during Element 1 and then these draft TOs should be further refined and developed during Element 2 (Design). TOs are precise statements of what tasks a trainee should be able to do, post training, in the Role that the training was designed to prepare them for. A TO is measurable and has three constituents: the Performance required, the Conditions under which the trainee must perform, and the Standard to which the trainee must perform. These statements should be in the form of observable and measurable behaviours which allow the achievement of the TOs to be confirmed through assessment. A TO defines what a successful trainee is able to do at the end of a period of training, i.e. the learning outcome25. It does not describe the learning process or any learning experience. TOs should be derived from the respective Role PS / Framework(s). The determination of TOs is a skilled process and the product must accurately reflect the needs of the Role. The production of TOs may be an iterative process and should be reviewed at each stage of the design process. The three component parts of a TO are summarised in Table 9: Table 8: Individual Training Objectives (Performance, Conditions, Standards) 25 A lesson, series of lessons, a course, exercise, or training activity. Performance. The Performance (and sub-Performance) element of a TO states what a trainee should be able to do at the end of training and should be derived26 from the task (stated in the Role PS / Competence Framework) and therefore has an active verb as the first word in the performance element. When writing a TO performance for a task, the wording may need to be adjusted: if the task wording is not precise if the task has more than one objective. to make the Performance absolutely clear to any reader. The choice of verb for the Performance element of the TO is critical. To ensure the trainee has achieved the desired behaviour, a response must be witnessed. Performance elements need to use action verbs27. Conditions. The Conditions element of a TO, specifies the actual Conditions, or circumstances, in which the training Performance will take place. In training, the ideal solution is to provide the same Conditions normally experienced in the Role, e.g. using the real equipment. As this is not always possible, the Conditions element must clearly indicate what the training environment can provide. The Conditions element should fully describe the environment in which the trainee should carry out the task. Conditions can be considered in these broad categories: Limitations to the range of Performance.\tSuch as, security, safety or legislative. Equipment. Such as tools, role aids, clothing, equipment. General situation. Indication of location, terrain, weather, daylight, climate, the threat, psychological, physical and social factors under which the training Performance is delivered should be detailed. Support. People, agencies, orders, standard and emergency operating procedures, manuals, references, check lists etc that are available to the trainee. Standards. The Standards element specifies the Standard that should be achieved by the trainee at the end of training. This should be related as far as possible to the Standard required in the Role. The Standards must be detailed enough to accurately assess if a trainee has achieved the Standard or not. Regarding the Role PS, Standards can either be product Standards (minimum absolute Standards) or process Standards (certain procedures that need to be followed in a particular sequence) or a mixture of the two. Determining the Standard of Performance required for all training environments is difficult. The nature of the Performance (which could be dangerous, critical, or an emergency task), the consequence of not meeting the Standard and/or the training category should be considered. The Standard required will ultimately affect how that Performance is 26 Derived from the task but not always a directly matching the task. 27 Verbs such as ‘know’ or ‘understand’ do not adequately define an action on the part of the trainee and are not observable or measurable. ‘Diagnose’, ‘assess’, ‘select’, ‘identify’, ‘distinguish’ are much more readily witnessed and can be assessed more easily. taught and how the trainee is assessed. For example, if a very high Standard is required, the trainee will receive a large amount of training for the Performance (creating the possibility of becoming over-trained) and may be subject to strict assessment, such as no mistakes. The Standard should be accurate. Some Performances may be subject to external rules and regulations, i.e. the Standard is dictated such as28: Health and Safety. Nuclear. Weapons handling. Flying regulations (such as Civil Aviation Authority). Legal requirements, both national and international. Any restrictions in Conditions may impact on the Standards. Differences may occur if the Standard cannot be achieved because the Conditions cannot be simulated. Standards in TOs should not be confused with the standards of tests. Whilst test standards should be set as closely as possible to those stated against the TO, there are certain areas where compromise may be necessary when setting test standards. The identification of Standards relating to personal qualities, attitudes and behaviours is perhaps the most challenging part of TO development. This is because attitudes cannot be observed directly and hence the precision associated with other Standards is rarely possible. For subjective judgements objective criteria should, where possible, be used to support the decision (e.g. what observable behaviour is the key indicator that a trainee has acquired the appropriate Standard?). Defining the negative, what is unacceptable behaviour, can result in a simpler and more precise Standard. TO Tagging and Numbering. TOs should be tagged to identify them as a Core (training) requirement, Legal requirement and/or Accreditation requirement, which is denoted using a letter (C, L, A) or a mark in the relevant column on the training statements with amplifying comments if appropriate. To ensure that training is allocated to all tasks, the link between tasks and TOs should be shown through an auditable numbering/identification system. This can be achieved by using the task numbers from the Role PS to identify their dependent TOs. An example is at Table 10. Table 9: Task Numbering System 28 If a performance is affected by such factors, the document or regulation should be clearly referenced in the Standards element, such as, “in accordance with publication/law/act, section X, paragraph Y, date and version.”"
  },
  {
    "id": "ebc7d887-62c5-46c4-97dd-f410dfbb6563",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The TOA should primarily make a recommendation as to a cost-effective training solution that meets the identified tasks or competences that require training. The TOA should comprise of a Fidelity Analysis29, Location/Environment implications and Methods & Media options."
  },
  {
    "id": "35e73340-026a-478f-b6df-5e6909983e2a",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Fidelity Analysis",
    "content": "The term ‘fidelity’ denotes how closely a set of procedures were implemented as they were supposed to have been30. Fidelity can be defined as, ‘the exact correspondence with fact or with a given quality, condition, or event; accuracy (e.g. the fidelity of the movie to the book or the degree to which an electronic system accurately reproduces the sound or image of its input signal’). This analysis should be conducted as a result of the production of a Role PS derived from the RA and include any existing Training Performance Standards. Fidelity Analysis considers each relevant Performance objective in the Role PS to assess the extent to which the training environment should replicate the workplace (real) environment to enable training to be effective. Decisions made at this stage can have a significant impact on the nature and cost of training solutions, as fidelity can be a significant cost driver, so it is important not to ‘gold plate’ the fidelity requirements, but instead determine the appropriate level of fidelity that is essential to achieve the desired training effect. The results of Fidelity Analysis will help inform the Conditions under which training should be conducted to adequately prepare trainees for their future Roles. Categories. Fidelity can be divided into four categories and sub-categories, combinations of which may apply to each Role PS task / Competence / Competency being analysed. 29 Not all organisations carry out Fidelity Analysis at this stage. Some organisations carry it out later on in the design process. 30 For example, if the Role conducted in the workplace environment (the real world) must be done at 100%, and the training environment can only replicate the workplace environment to 89%, then that is the fidelity to which the training requirement matches the role requirement. It is not to be confused with Gap Analysis, as fidelity is about replicating the totality of the real environment in training, rather than seeking the gap between existing training and new/changed training requirements. Physical fidelity. Physical fidelity can be useful to familiarise trainees with the visual, spatial and tactile characteristics of equipment, consoles, compartments, platforms and threats (including applicable reference manuals, Standing and Emergency Operating Procedures etc). Physical fidelity can be broken down into these sub-categories: Layout. Position of the controls etc, relative to each other. Look. Shape, colour, luminescence and size of interface. Feel. Feel and movement of the interface during use. Functional fidelity. Functional fidelity is useful in providing trainees with exposure to equipment functionality, doctrinal procedures, and maintenance routines which are required to be exploited in order to deliver the desired military effect. Functional fidelity can be broken down into these sub-categories: Format. Format of data displayed, or action taken. Content. Information displayed or heard, frequency, text colour etc. Response. Data change rate and display response times. Environmental fidelity. Environmental fidelity can be useful in preparing or ‘acclimatising’ trainees for the conditions they will be operating under and simulating some of the conditions that can hinder Performance. It can be easy to ‘gold plate’ environmental fidelity requirements beyond what is essential to provide the necessary cues, stimuli and responses, but high levels of environmental fidelity can be beneficial in exposing trainees to complex operating environments and ‘fog of war’ type issues. Environmental fidelity can be broken down into these sub-categories: Sound. Background noise, conversation and sympathetic resonance. Motion. Incidental movement of the system, equipment or platform. Ambience. Heat, light, smell, smoke, humidity etc. Geographic features. Effects on sensors, infrastructure, SOPs etc. Tactical and cultural31 fidelity. Tactical and cultural fidelity will help identify requirements that enable individuals and teams to train as they intend to operate. Exposing trainees to the types of units, threats, allies (including neutral or ‘white’ forces), cultural issues and geographical locations that they will experience on operations, can also be used for mission rehearsal training or tactical development. Modern training technology, particularly simulation, enables accurate representations to be included in training quickly and cheaply. Tactical and cultural fidelity can be broken down into these sub-categories: 31 To succeed on many operations, UK Armed Forces will need to understand and interpret the nuances of local cultures with and within which they will be operating. Introducing cultural elements into training will be essential in many cases - Future Operating Environment 2035, Development, Concepts and Doctrine Centre, 2015. Threats. Enemy characteristics (number, tactics, equipment etc). Allies/Neutrals. Allied and neutral forces characteristics (number, tactics, equipment, culture etc). Conflict character and location. Type of operation, presence of media and/or Very Important Persons (VIPs), cultural/religious behaviours, historical implications, infrastructure and building implications etc. Team interactions. Command and control (C2) relationships, communications, situational awareness. Fidelity Requirements Task and sub-task level. Every relevant task contained in the Role PS / Competence Framework should be analysed for its respective Fidelity requirements, based on the applicable fidelity categories. Depending on the complexity of the capability involved, it may be necessary to articulate fidelity requirements at the sub-task level if those stated at the task level do not adequately capture the relevant fidelity criteria details. Team/collective performance. Analysts should also consider the fidelity requirements of any team/collective Performance criteria that have been established in support of the new or revised capability, to contextualise the individual training need. Fidelity factor levels. Table 11 defines 4 levels against which each of the fidelity sub-categories can be measured for each task/sub-task. However, analysts should not state fidelity requirements simply as ‘high, medium, low, none’ as this is unquantifiable and gives no meaningful guidance to designers of the eventual training solution. Users should also include specifics of the fidelity requirements for each Performance criteria within each applicable category and sub-category. Table 10: Levels of Fidelity"
  },
  {
    "id": "6775c3f7-70b3-45e4-9a71-f0a900778eff",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Location / Environment Implications",
    "content": "The training environment and implications of location for each training solution may well require analysis at this stage. For example, constraints on training resources and the availability of real equipment for training may force the emphasis towards workplace training. The same would be true if it is not possible to replicate critical Role PS Conditions in training establishments or via distributed training. Alternatively expensive and scarce training equipment or qualified trainers may only be available in [some] training establishments. It is therefore important to determine an estimate of where the balance between training to be delivered in a training establishment and workplace training will fall. It is based on a careful analysis of exactly what the TRA requires, tempered by that which is deliverable and can only be achieved by consultation with the TRA and the Training Provider, who will have knowledge of existing training and current training facilities and resources. This will later result in the allocation of TOs to a TPS, WTS, or, where no training will take place, the Performance, Conditions and Standards to a RTGS32. The output from this work could be an amendment to the Initial Training Categories or recommendations that take account of both DIF Analysis results and the impact of all other Role, training and resource factors."
  },
  {
    "id": "4b478515-7a90-4155-abb0-19209d284593",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Methods and Media Options",
    "content": "Methods and Media Options. It is important to consider the most appropriate and effective blend of training Methods & Media options that provides the most effective balance of performance, cost and time in achieving the required KSA. These options should be further refined as part of the Design process by exploring, in order: Methods. These are the strategies or techniques used to achieve the required KSA. Media. These are the tools and means used to apply the Methods selected. 32 Which all form parts of the FTS. These are covered in Element 2 (Design, 2.2). FACTORS\tTO\tBE\tCONSIDERED\tWHEN\tDETERMINING\tTHE\tTRAINING EFFECTIVENESS OF DIFFERENT METHODS Learning factors. Type of learning. The Method used to deliver training depends on whether learning is categorised as Knowledge, a mental or physical Skill, or an Attitude. Each EO must be examined to determine whether it is primarily expressed as a KSA. This will suggest the appropriate choice of Method (e.g. a Skills-based EO must have some element of practice involved in the Method; whilst role-play is an example of a training Method suitable for a Behaviour-based EO). The aim must be to choose a Method that is compatible with the material to be learned. Learning a physical Skill may require equipment and machinery and a low trainee-to-trainer ratio as it tends to be trainee-centric. Knowledge learning is most effective and efficient via e-learning, in the form of a lecture, or with links to information. This works best in a flipped classroom, where learning is then consolidated through discussion. Retention ability. A basic categorisation of training Methods should state that these can either be trainer or learner centric. The appropriate selection of training Methods improves the effectiveness and efficiency of learning. Wherever possible, a learner-focused approach should be adopted although this is not always as simple as it seems as it can be time consuming and resource heavy. A learner-focused approach aids information retention by considering the needs of the trainees and increasing their involvement in the learning process. A trainer-focused approach, whilst increasing trainee-to-trainer ratios, is not as effective for aiding trainee retention. The more active the trainee is in the learning process, the higher the rate of retention. Learning preferences. Learning takes place when learners reflect on what they have done, or from what others have done. Therefore, it is imperative that for the effective and efficient acquisition of the required KSA, time is built into the programme, to facilitate learning through reflection. People learn from reflecting on their own, or others experience. Therefore, enabling experiential learning is the most effective and efficient way of enabling learning. Trainee characteristics. Motivation. Learners are motivated to learn when they know the relevance of the learning, and when they are enabled to learn through a learner-centric way. For knowledge acquisition, motivation best comes through a flipped classroom, where the learners are required to access the learning (through e-learning for example) before they consolidate and reflect on what they have learnt, in the classroom. Literacy level. Information should only be presented to learners in a form they can cope with. Information should not be at a level that they cannot comprehend, nor should it be at a level which will patronise. Key questions should include ‘What is the literacy level of the trainees?’ and ‘What is the most appropriate language for passing information?’ Numbers. How many trainees should there be in each group? A large group will make trainer demonstrations difficult to plan. A small group will limit trainee discussions and peer learning. Practical constraints. Facilities and resource availability are likely to limit the choice of Method and the most appropriate Media are not always practical or within budget. The medium may be unavailable; there may not be time to meet all the TOs; it may be difficult logistically or financially; or the group may be of mixed ability and unable to make the best use of the Media selected. Where resources to support the optimum training Method are not available, lack of availability is likely to affect the successful achievement of the TOs. Such constraints should be captured in the Constraints Analysis and/or the Risk Register. The TRA and Customer should be advised of this fact and made aware of the likely consequences. Trainer attitude and ability. A question that will need to be asked is: can, or will, the trainers be able to use the Media selected? Trainers are unlikely to use Media that they do not understand, which increases their workload, or which is complex to manage. If new teaching Methods are to be introduced, then due regard must be given to ensuring that trainers are both willing and able to cope. To avoid such issues designers should: involve trainers in the Design process as early as possible. identify any additional trainer training requirements. develop a trainer training strategy to enable trainers to explore new technologies followed by localised CPD activity to ensure awareness is maintained on TEL developments, including opportunities for TEL exploitation; as a minimum, trainers should be able to facilitate learning using the DLE. Training designers. Training designers should maintain awareness of emergent TEL and have a working knowledge of the DLE as a minimum. The requirement to design training to meet the needs of different types of learners, including skill fade and learner-centric approaches in an increasing resource constraint environment places the training designer at the centre of the training design process. Training Providers and 3rd Party Contractors will need to ensure their training designers are provided with sufficient training, expertise and resources in order to design training to meet the needs of Defence. The TDA should ensure the following: Liaison with the DLE Subcategory Manager for potential DLE inclusion. Creation of a DLE front page for every course iteration. For any NTS training design, key training design personnel should be invited to the TNA WG during TOA and TNR stage to plan for TEL interventions. Training Providers/3rd Party Contractors to develop a training designer training strategy and plan to enable training designers to intelligently utilise TEL to facilitate a blended learning approach as to optimise efficiencies. This should be followed by ongoing coaching CPD to ensure training designers maintain TEL and blended learning currency. Where applicable, ensure that Training Providers’/3rd Party Contractors’ training designers are provided with OEM Train the Trainer (TtT) training prior to RFTD for all NTS capabilities. Ensure the training designers are provided with all OEM TEL training documentation (hardcopy, electronic (Word, PDF, Interactive Electronic Training Manuals/Publications (IETM/Ps), media prior to any training design. Develop a trainer training strategy to enable trainers to explore new technologies followed by localised CPD activity to ensure awareness is maintained on TEL developments, including opportunities for TEL exploitation. As a minimum, trainers should be able to facilitate learning using the DLE. Time availability. Care should be taken to avoid false economies. A lecture may seem to be an attractive option for passing large amounts of information in a relatively short time, but the information received by the trainees may be processed at only the most superficial level. This is why lectures should be front-loaded into a flipped classroom. Need for transfer of learning. Apart from some types of workplace training, the training environment will differ to some extent from the work environment. It is therefore important that the training Method chosen should minimise this difference to make the transfer of KSA from the training environment to the work environment as easy as possible. Priority of learning. It is unlikely that the various subjects to be trained will all be of equal importance to the trainees in their future Role. Some Skills may be used on a daily basis while others may be only used sporadically but, when they are used, are essential. This requires Performance to be maintained at a consistently high Standard. The results of the DIF Analysis (1.3.3), the consideration of skill fade factors and/or the analysis of Critical Errors (1.3.3B) may have a significant influence on the Method selection. In subjects where the possibility of skill fade could have dire consequences, consideration must be given to ensuring that appropriate Methods & Media are implemented to enhance retention. This may or may not require the allocation of extra training time. THE DIFFERENT CHARACTERISTICS OF MEDIA Variety of Media. Consideration should be given to the characteristics of Media, in terms of whether they are essential or optional: Essential Media characteristics. Essential Media characteristics control the clarity of the message. For example, learning a foreign vocabulary requires print (to recognise words) and audio Media (to pronounce them). Training designers should consider: media that is appropriate to deliver the desired learning outcomes. media that provides an appropriate level of fidelity. media that can cope with trainee throughput. Optional Media characteristics. Optional Media characteristics improve the quality of the training. There are some considerations that can influence selection: attractiveness to the learner: colour, animation, illustration. the trainees’ study habits. the trainers’ style, habits and Skills. media that, from experience and research, improves learning efficiency. media that allows the efficient management of training. media that has low risk of failure (for whatever reason)."
  },
  {
    "id": "c4702307-809b-4d95-88df-91907150806e",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Cost Benefit Analysis",
    "content": "In accordance with Defence and HM Treasury guidelines, an examination of the broad order costs of various options to recommend the most cost-effective training solution must be undertaken. It is important that costing and investment appraisal are undertaken strictly in accordance with the current Defence and Service or Strategic Command policies and conventions. If training specialists become involved with costing or investment appraisal, they should obtain current advice from the TNASG or other authoritative body. CBA activity does not start at this stage of the TNA but the result of it is included in the Training Needs Report hence its inclusion here. Like many aspects of DSAT, CBA is an iterative process with initial activity commencing much earlier in the TNA process, as appropriate. The CBA will likely be further refined during the Method & Media selection process in Element 2 (Design). An estimate of the financial risks and/or opportunities associated with each training solution option should be undertaken. Training staffs are unlikely to be qualified to conduct financial risk analysis at anything other than a superficial level33. However, these analyses will be a significant factor in selecting training solution options. 33 Trainers should therefore seek specialist advice and support from Defence, or, for industry, from specialists in the field."
  },
  {
    "id": "1ac2e75e-4965-485c-af3c-15e47460dab3",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Options Evaluation",
    "content": "The final activity of the TNA is to decide on training options. To evaluate the merits of the training locations and/or environments one of them should be selected as a baseline option. The selection of a baseline will depend on the context, which then permits the construction of a table to display the relative merits of each option against the baseline. Options can be assessed via several criteria: The extent to which the option meets the requirements. Through-life cost 34 , including the costs of maintenance, trainers and integration with existing training locations/environments. Implementation time, which may prove important to meet an operational need or a RFTD. Trainer load, or any consideration of the availability and competence of trainers to support training. An assessment of the risk35 associated with the options. Flexibility, or the ease with which the new training can be integrated with existing and potential future training, as appropriate. It will typically be appropriate for the options evaluation to be undertaken in consultation with SMEs before presentation to the TNASG for endorsement. Table 12 provides an example format: Table 11: Example of an Options Evaluation Table 34 It may be necessary to break down costs into greater detail to conduct evaluation. 35 This may include safety considerations or it may be appropriate to assess safety separately."
  },
  {
    "id": "dbea2681-337c-44fc-a31f-32137ea8d6ba",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Recommended Further Reading",
    "content": "Guidebook of Decision Support Tools for Training Design and Delivery: Part 7 - Fidelity Analysis This guidebook is intended to support staff in the MOD, and contractors working for the MOD, in the challenges faced in understanding the effectiveness of training prior to it being delivered. The aim of the Guidebook is to review the range of tools, methods and approaches that is available and recommend the most suitable approach. Part 7 of the handbook provides checklists for training fidelity and instructional features to assist the training designer. Link: Guidebook of Decision Support Tools for Training Design and Delivery – Part 7 Fidelity Analysis"
  },
  {
    "id": "321bf792-6f1b-48da-a580-2a185469560d",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Needs Report",
    "content": "The Training Needs Report specifies the training requirement and recommends a training solution through the evaluation of options. It should include the resources required to design and support the training. Training Needs Reports should collate all the information from the scoping exercise and analyses stages, adding an Implementation Plan and TNE strategy. It should also include a description of the TNA methodology in terms of the data gathering and analysis techniques and clearly reference the data sources consulted. The TNA can then be written up as a Training Needs Report that provides or supports detailed user and system requirements. Training Needs Reports should include: Identification of the Performance requirement: a Role PS / Framework(s) for each Role holder, as identified in the RA. Identification of the training requirement: the results of the TGA. A Role PS and/or Framework(s) for the Role(s) affected by the recommended training solution with recommended training categories and supportive notes to amplify specific requirements to be included as appropriate to assist designers with the production of the FTS. Implementation plan, including where responsibilities lie (e.g. conversion training, date of new legislation and/or policy change, and design). At this stage the draft TOs endorsed by the TNASG should be available and expressed as Performance, Conditions and Standards to enable implementation by the design team. Any recommendation regarding estimation of resources, timings and assessments should be clearly referenced to aid the design team. Input to inform or refine the SOTR (for formal endorsement), to focus and direct the design stages. TNE strategy. The TNASG endorsed training solution, resulting from the CBA and final selection using the Options Evaluation. Fidelity requirements and associated risks, assumptions, constraints should be included in the Report."
  },
  {
    "id": "166d10e7-5dda-46ec-bc5e-cc8735032092",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "C – Fidelity Analysis Example",
    "content": "ANNEX A TO DTSM 2"
  },
  {
    "id": "8c913e3f-5f47-4790-a0f4-6529082d52cb",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Initial KSA Analysis (KSA) Example PDF / WORD Formats ANNEX B TO DTSM 2"
  },
  {
    "id": "a73a7edb-ff46-4776-89f6-b2a58304a21f",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Role Performance Statement (Role PS) Example PDF / WORD Formats ANNEX C TO DTSM 2"
  },
  {
    "id": "3d53d927-f945-49a0-aa19-4bf51c9be4c9",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Fidelity Analysis Example PDF / WORD Formats"
  },
  {
    "id": "b4b2182a-c46b-46ba-8336-dc461e880da8",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Coverage",
    "content": "This DTSM supersedes all previous DTSMs on Analysis of Individual Training The totality of DTSMs included in the DTSMs Suite, of which this document is a part, are listed on the DTSMs SharePoint site"
  },
  {
    "id": "8af4ae29-973e-466e-9f8f-f79df4c86f50",
    "document": "DTSM 2 Analysis of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Editions / Versions",
    "content": "Annual editions of this DTSM will be published every December in time for upcoming year relevant to the DTSM. Throughout the year, different versions of the current edition may also be published. When every new edition is published, the versions will reset to 1."
  },
  {
    "id": "9329bc5e-113f-4f43-9bd4-16f3bca68c0b",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Uncategorised",
    "content": "Defence Training Support Manual 3 Designing Individual Training"
  },
  {
    "id": "7bed8d88-d853-40ad-840b-2798addce182",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "2023 Edition",
    "content": "Version: 1.0 Contents"
  },
  {
    "id": "4dd48d68-082c-417a-aee7-ad2a9287eece",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "How to use this Manual",
    "content": "Defence Training Support Manuals (DTSM) have been developed to support the understanding and implementation of the policy contained in JSP 822. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. DTSMs will be published every December, following the publication of the latest version of JSP 822. Throughout the year, different versions of the latest DTSM edition may also be published. When every new edition is published, the versions will reset to 1. Using the DTSMs is entirely optional, and users may find there are alternative resources available to help them understand and implement the policy contained in JSP 822. Throughout this document there are references to other DTSMs, these references contains hyperlinks that will take you to the DTSMs that are held on the   SharePoint site. The DTSMs currently available are:"
  },
  {
    "id": "b33dd64e-47ed-4a2a-81ec-8f43b3eb9141",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Training design is the process that derives achievable Training Objectives from the outputs of an Analysis of a training need. It then establishes the assessment, Methods & Media and LSpec."
  },
  {
    "id": "de4b453e-5fb5-4905-bbad-d33ec2eaef35",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "The Principles of Defence Training",
    "content": "The effectiveness of training delivery will be measured by the Training Provider and appropriate governance body according to whether the intended outcomes (the TOs) have been achieved successfully. This is determined through the formal assessment process, but there will also be other, indirect outcomes of training (e.g. motivation to learn and creating independent learners) which will need to be considered when planning and preparing effective training. These are not as easy to measure, but they are important if trainees are to perform to the best of their ability. To ensure that all the desired outcomes are achieved when preparing training, the following principles of training delivery1 should be applied: Trainer as role model, Learner-centred training, Self-regulated learning, Technology in training, Inclusion in training, Standardising training."
  },
  {
    "id": "58150e49-1c00-4037-a0cc-5bf4b611aa6b",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "The Principles of Adult Learning",
    "content": "The art or science of teaching adults is often termed ‘andragogy’ (Greek for adult- leading) as opposed to pedagogy (child-leading) which is a more traditional trainer led approach to training. Adults are internally motivated and self-directed. Adult learners resist learning when they feel others are imposing information, ideas or actions on them. They prefer to have control over what they learn and when they learn it. Guide (rather than direct) students to foster their internal motivation to learn and move them toward more self- directed and independent learning. Adults bring life experiences and knowledge to learning experiences. Adults like to be given the opportunity to make use of their existing foundation of knowledge and life experience to support their new learning experiences. Identify and acknowledge students’ past experience and use active learning techniques that allow them to problem solve using logical reasoning and common sense. 1 Further advice on the trainer’s responsibilities for the preparation and delivery of training can be sought from the Defence Centre of Training Support (DCTS). The topic is also covered in DTC training. Adults need to know why they are learning something. Adult students become ready to learn when they recognise that they need to learn something in order to deal more effectively with real-life tasks or problems. Aim to increase the student's awareness of the need for the knowledge or skill presented. Adults need to know why they are learning something. Adult students become ready to learn when they recognise that they need to learn something in order to deal more effectively with real-life tasks or problems. Aim to increase the student's awareness of the need for the knowledge or skill presented. Adults want to know they can use learning straight away. Adult learners tend to prioritise their learning and so they want to know how the learning relates to their immediate goals. Provide opportunities to make use of (apply) new learning in a lesson in order to help students recognise the relevance and value of what they are learning. Adults learn by reflecting on what they have done, or what others have done. Active participation is important for adults and they generally learn best by starting with a problem, working to find a solution, and reflecting on the outcome in order to draw conclusions about how they will do it differently next time, in order to increase performance. Where possible use realistic tasks, situations and scenarios for problem solving exercises."
  },
  {
    "id": "ee2ba4a1-087e-4ded-bb8f-d3e027a57a90",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Trainers need to provide training in a way that recognises trainees’ life experiences and allows them to take ownership of their own learning2. In this way, they are motivated to learn and become independent and ‘agile’ learners. Learner-centred training means enabling trainees to actively take part in their learning, rather than passively receiving instruction. It means teaching trainees how to think and solve problems by drawing on their past experiences, using common sense and logic to research and evaluate evidence, then reflecting on their findings to reach conclusions. Learner-centred training uses active training techniques and lets trainees learn from each other and from their own mistakes. It promotes deeper learning, which is meaningful and memorable, rather than surface learning which is easily forgotten. It is the most effective and efficient way to provide learning. The DTCF sets out the requirement for “learning events to be learner- centric and structured to the learning process,” in Competency Group 2 and the requirement that “individuals are actively engaged in the learning process” in Competency Group 4. Application of the  (PAR3) model is identified in Competency 2.1 as appropriate for the promotion of active learning. Competency 4.1 identifies the need for trainers to manage both individual and group needs during learning events."
  },
  {
    "id": "24646a63-3296-4f91-8eb6-5bb137370a76",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "The PAR Model",
    "content": "The PAR model is chosen by Defence as the easiest to understand and employ. It should be used as the basis for planning and facilitating all lessons. Trainers should reflect regularly on how learner-centred their lessons are and share good practice where a particular learner-centred approach has worked well (or even if it has not). They should also seek feedback from their trainees on which methods and techniques are most effective from their point of view. People learn from reflecting on their experiences, i.e., they do something and reflect on how successful it was, in order to draw conclusions, supporting by the trainer, on what they will do differently next time. Whilst having the experience themselves is preferable, if this is not possible, then the next best option is to consider the experience that somebody else has had, reflect on how successful it was, and draw conclusions, supported by the trainer, on how they will do it differently to be more successful.4 2 The art or science of teaching adults is often termed ‘andragogy’ (Greek for adult-leading) as opposed to pedagogy (child-leading) which is a more traditional trainer led approach to training. 3 Petty, G. (2009). Evidence Based Teaching (2nd ed). Nelson Thornes. 4 Social Learning Theory, eg, Bandura (1977). Table 1: Lesson Structure and the PAR Model 7\tDTSM 4 (2023 Edition, V1.0)"
  },
  {
    "id": "7c81a4d8-7eab-48b3-96fe-e530217280d7",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Self-Regulated Learning",
    "content": "Making training learner-centred also encourages trainees to  their learning, i.e. they monitor their own knowledge and skills and make decisions on how they can progress. Trainees who self-regulate their learning are motivated to learn through-life and are confident of their ability to learn, and so they are more likely to take action to remain competent and current in their job role. Trainers can teach trainees to self-regulate by prompting them to set and reflect on individual goals, using feedback to then identify and review what they did to achieve the goal. Concentrating more on what the trainee did (or did not do), rather than the actual outcome, helps to develop these self-monitoring capabilities. Learning from mistakes is also a very effective tool in self-regulated learning and trainees need to be given the freedom to make mistakes where safety, time and resources permit. The DTCF sets out the requirement for “learning events to meet both organisational and individual goals” in Competency Group 2 and the requirement for trainees to “set realistic personal goals based on self-assessment and constructive feedback” in Competency Group 4. Competency 2.2 requires the trainer to apply the 5 components5 of the self-regulated learning process and Competency 4.2 highlights the importance of goal setting, feedback and learner self-reflection. Trainers should aim to use these basic coaching techniques both when delivering lessons and when working with individual trainees. Self-regulation in learning describes a process of controlling and evaluating one’s own learning6 and behaviour7. This process may be subconscious, but is more effective if a conscious activity. There are four stages17: task perception, goal setting, enacting and adaptation. 5 Readiness, Resourcefulness, Resilience, Reflectiveness, Responsibility. 6 Zimmerman, B.J. (2008). Investigating self-regulation and motivation: Historical background, methodological developments and future prospects. American Educational Research Journal, 45, (1), 166-183. 7 Zimmerman, B.J. and Campillo, M. (2003). Motivating Self-Regulated Problem Solvers. In J.E. Davidson and R.J. Sternberg (Eds.). The Psychology of Problem Solving. Cambridge University Press. 17 Winne, P. H., & Hadwin, A. F. (2008). The weave of motivation and self-regulated learning. In D. H. Schunk & B. J. Zimmerman (Eds.), Motivation and Self-regulated learning: Theory, Research and Applications. New York: Lawrence Erlbaum. Figure 1: Self-regulation in Learning Trainees who self-regulate their learning are motivated to learn through-life and are confident of their ability to learn, and so they are more likely to take action to remain competent and current in their job role. Trainers can teach trainees to self-regulate by prompting them to set and reflect on individual goals, using feedback to then identify and review what they did to achieve the goal. Concentrating more on what the trainee did (or did not do), rather than the actual outcome, helps to develop these self-monitoring capabilities. Learning from mistakes is also a very effective tool in self-regulated learning and trainees need to be given the freedom to make mistakes where safety, time and resources permit. Self-regulated learners are ‘Active learners’ who attribute their successes or failures to factors within their control e.g. effort expended on a task, effective use of strategies) within their control. They are aware of their strengths and weaknesses in learning, and they have a range of strategies they appropriately apply to tackle the day-to-day challenges of learning tasks. Table 2: Active v Passive Learner Trainee motivation is the key factor in adopting self-regulation. Trainers need to prompt learners to set and reflect on their personal goals and identify and review what they did to achieve the goal. In feedback, trainers should concentrate on mastery (strategies and processes) rather than the outcome (overall performance or product) itself in order to help learners develop self-monitoring capabilities. The Campaign for Learning (2013) 9 identified 5 attributes of the self-regulated learner: 8 Adapted from Petty, G. (2009). Evidence Based Teaching (2nd ed). Nelson Thornes."
  },
  {
    "id": "de140edf-9b64-40ef-a564-e27ff74da2c4",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "9",
    "content": "Figure 2: The 5 Attributes of the Self-Regulated Learner"
  },
  {
    "id": "0f19399d-9924-4597-83bb-d2219b0af830",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Training Objectives (TOs) ensure that the training activity has a definite purpose such that the Defence need is met. They help ensure that the associated trainers, support staff and trainees have a clear understanding of what the trainees are required to learn and to be able to do at the end of the lesson/learning event. TOs form the basis of the detailed design of each of the training lessons or collective training events as well as identification of appropriate training resources. They may also be used in support of the award of civilian accreditation. Therefore, the development and maintenance of accurate TOs is essential. TOs were drafted during Element 1, and these draft TOs should now be further refined and developed during Design Stage 1. TOs are precise statements of what tasks a trainee should be able to do, post training, in the Role and/or team environment that the training was designed to prepare them for. A TO is measurable and has three constituents: the Performance required, the Conditions under which the trainee must perform, and the Standard to which the trainee must perform. These statements should be in the form of observable and measurable behaviours which allow the achievement of the TOs to be confirmed through assessment. A TO defines what a successful trainee is able to do at the end of a period of training, i.e. the learning outcome10. It does not describe the learning process or any learning experience. TOs should be derived from the respective Role PS/Framework. The determination of TOs is a skilled process and the product must accurately reflect the needs of the Role. The production of TOs may be an iterative process and should be reviewed at each stage of the design process. The three component parts of a TO are summarised in Table 1: Table 3: Individual Training Objectives (Performance, Conditions, Standards) 10 A lesson, series of lessons, a course, exercise, collective training event or training activity."
  },
  {
    "id": "92018b51-0193-47e5-885c-051b84dd98bb",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Performance",
    "content": "The Performance (and sub-Performance) element of a TO states what a trainee/team should be able to do at the end of training and should be derived11 from the task (stated in the Role PS / Framework) and therefore has an active verb as the first word in the performance element. When writing a TO performance for a task, the wording may need to be adjusted: if the task wording is not precise. if the task has more than one objective. to make the Performance absolutely clear to any reader. The choice of verb for the Performance element of the TO is critical. To ensure the trainee has achieved the desired behaviour, a response must be witnessed. Performance elements need to use action verbs12."
  },
  {
    "id": "2cc6b82b-4d77-4645-975c-8e74387f5420",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Conditions",
    "content": "The Conditions element of a TO, specifies the actual Conditions, or circumstances, in which the training Performance will take place. In training, the ideal solution is to provide the same Conditions normally experienced in the Role, e.g. using the real equipment. As this is not always possible, the Conditions element must clearly indicate what the training environment can provide. The Conditions element should fully describe the environment in which the trainee should carry out the task. Conditions can be considered in these broad categories: Limitations to the range of Performance.\tSuch as, security, safety or legislative. Equipment. Such as tools, role aids, clothing, equipment. General situation. Indication of location, terrain, weather, daylight, climate, the threat, psychological, physical and social factors under which the training Performance is delivered should be detailed. Support. People, agencies, orders, standard and emergency operating procedures, manuals, references, check lists etc that are available to the trainee. 11 Derived from the task but not always a directly matching the task. 12 Verbs such as ‘know’ or ‘understand’ do not adequately define an action on the part of the trainee and are not observable or measurable. ‘Diagnose’, ‘assess’, ‘select’, ‘identify’, ‘distinguish’ are much more readily witnessed and can be assessed more easily."
  },
  {
    "id": "e0191676-2bed-4c42-a4bc-e04fbf515fd3",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Standards",
    "content": "The Standards element specifies the Standard that should be achieved by the trainee at the end of training. This should be related as far as possible to the Standard required in the Role. The Standards must be detailed enough to accurately assess if a trainee has achieved the Standard or not. Regarding the Role PS/Competency Framework/Competence Framework, Standards can either be product Standards (minimum absolute Standards) or process Standards (certain procedures that need to be followed in a particular sequence) or a mixture of the two. Determining the Standard of Performance required for all training environments is difficult. The nature of the Performance (which could be dangerous, critical, or an emergency task), the consequence of not meeting the Standard and/or the training category should be considered. The Standard required will ultimately affect how that Performance is taught and how the trainee is assessed. For example, if a very high Standard is required, the trainee will receive a large amount of training for the Performance (creating the possibility of becoming over-trained) and may be subject to strict assessment, such as no mistakes. The Standard should be accurate. Some Performances may be subject to external rules and regulations, i.e. the Standard is dictated such as13: Health and Safety. Nuclear. Weapons handling. Flying regulations (such as Civil Aviation Authority). Legal requirements, both national and international. Any restrictions in Conditions may impact on the Standards. Differences may occur if the Standard cannot be achieved because the Conditions cannot be simulated. Standards in TOs should not be confused with the standards of tests. Whilst test standards should be set as closely as possible to those stated against the TO, there are certain areas where compromise may be necessary when setting test standards. The identification of Standards relating to personal qualities, attitudes and behaviours is perhaps the most challenging part of TO development. This is because attitudes cannot be observed directly and hence the precision associated with other Standards is rarely possible. For subjective judgements objective criteria should, where possible, be used to support the decision (e.g. what observable behaviour is the key indicator that a trainee has acquired the appropriate Standard?). Defining the negative, what is unacceptable behaviour, can result in a simpler and more precise Standard. 13 If a performance is affected by such factors, the document or regulation should be clearly referenced in the Standards element, such as, “in accordance with publication/law/act, section X, paragraph Y, date and version.”"
  },
  {
    "id": "69a2b0be-81ca-4081-aed4-c6e6d75d71a0",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "TO Tagging and Numbering",
    "content": "TOs should be tagged to identify them as a Core (training) requirement, Legal requirement and/or Accreditation requirement, which is denoted using a letter (C, L, A) or a mark in the relevant column on the training statements with amplifying comments if appropriate. To ensure that training is allocated to all tasks, the link between tasks and TOs should be shown through an auditable numbering/identification system. This can be achieved by using the task numbers from the Role PS to identify their dependent TOs. An example is at Table 2. Table 4: Task Numbering System"
  },
  {
    "id": "21208364-9918-47c8-a1b9-8e085cb2cc98",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The FTS details the totality of the training that must be achieved to meet the requirements articulated in the Role PS and/or Framework(s). The FTS is made up of a Training Performance Statement (TPS), a Workplace Training Statement (WTS), and a Residual Training Gaps Statement (RTGS). The TPS details the TOs that are managed and/or delivered by the TDA. The WTS details the TOs that are managed and/or delivered by the employing unit. The RTGS details elements of the Role PS and/or Framework(s) that have not been allocated to any training activity (the gap). TOs are the key component of the subsequent training statements that form the FTS, the formats for which are at ."
  },
  {
    "id": "98acb5cf-d513-42f8-974b-47bf72f7cb67",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Training Performance Statement",
    "content": "The TPS details TOs (in terms of Performance, Conditions and Standards) to be attained by trainees. The TPS TOs are managed and/or delivered by the TDA."
  },
  {
    "id": "03960397-a989-4a54-bb35-adc4c7336e50",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Workplace Training Statement",
    "content": "The WTS details TOs (in terms of Performance, Conditions and Standards) to be attained by trainees following assignment to a Role. The WTS TOs are managed and/or delivered by the employing unit."
  },
  {
    "id": "b9a3284e-db59-4401-b9ab-da5986d87694",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Residual Training Gaps Statement",
    "content": "The RTGS is the difference between the totality of the training received and the Role PS / Framework. It is the gap where an element of the Role PS / Framework has not been allocated a training activity. The Residual Training Gap is expressed in terms of Performance, Conditions, and Standards. The RTGS also states the reasons and consequences of any identified RTG, and management of any associated risks."
  },
  {
    "id": "d6cb6390-b983-4ea3-8046-d172fcc59f5c",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "An Enabling Objective (EO) is defined as a statement of Performance, Conditions and Standards that describes the KSA necessary for the trainee to achieve all or part of a TO. An EO sets the destination of a learning event and specifies what trainees can do at the end of a period of training that they could not do at the start. Where Conditions and/or Standards are common to a number of EOs, there is no requirement to duplicate the Conditions and Standards elements. In hierarchical terms, an EO is subordinate to a TO. The material required to achieve the EO is further broken down into a number of relevant Key Learning Points (KLPs), derived from the KSA Analysis conducted in Element"
  },
  {
    "id": "151e1771-dda5-4114-98f5-5748f24d98e8",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Formatting and Numbering",
    "content": "The EO and subordinate KLPs have to be recorded. A numbering system is usually employed to show the relationship between the TO and EOs, and EOs and KLPs. The system also shows the sequence in which the EOs and KLPs will have to be achieved in order to achieve the TO. It is important that an audit trail allows the original task to traced through the TO to the EO and KLPs. One recommended method is a numbering system, such as that shown in Table 3. Table 5: Example of Task/TO/EO/KLP Formatting and Numbering"
  },
  {
    "id": "945c6f8d-bda2-43b5-8ae8-70ce31a6fafa",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Strategy",
    "content": "Assessment Strategy. Tests and assessments are used for a variety of purposes, but most importantly they are used to ensure that the TOs have been achieved by the trainees. The AStrat is the document describing the overarching assessment policy for the course/module and the associated rationale. It must include the consequences of failure of specified elements of the course/module and include any ‘Return to Unit’ policy for infringement of values and standards etc. It is also important to ensure these tests and assessments are reliable, valid and administered correctly. Assessment is usually a major consumer of resources, particularly time, and the AStrat can also influence Method & Media selection. It is, therefore, important that the AStrat is endorsed by the TRA and appropriate governance body (such as the CEB) once the EOs/KLPs have been determined. A carefully conceived AStrat will achieve: A justification for all testing on the basis of the overall assessment that has to be made, such that an individual is qualified to fill a Role or use equipment. In particular, the strategy should explain how the overall grade is determined. An overview of the sort of tests to be used, the points during the training when they will occur, where the testing tools (such as exam banks, observation forms, exercise scenarios) are held and how the results of tests are to be interpreted and acted upon. A record of decisions taken about the best approach to assessment and a guide for the later development of tests. Valid assessment where tests match the requirements of the TOs. Influencing the manner in which training is delivered (such as a weapons trainer knowing that a summative test will emphasise practical handling skills and wisely ensuring ample trainee practice during training periods). Improving reliability and integrity of tests through effective test administration. Elements of the AStrat. The AStrat should include clear direction for: The testing of each of the TOs. This should be based upon practical summative tests supported by selected enabling tests in either practical or theory format. At this point, a short description of the test is sufficient (e.g. ‘A practical test in which each trainee will command a tank during a troop advance’, or, ‘A theory test on the Highway Code’). The formative testing of trainee progress. This might include a statement of purpose, an assignment of responsibility, a caution about the use of formative test results, and guidance on test feedback to trainees. A policy for the assignment and interpretation of grades. A policy for the action to be taken upon trainee failure of a (valid) test. As appropriate action will depend upon many variables, it is recommended that this policy be flexible rather than restrictive (e.g. a statement guaranteeing (or denying) a re-sit will seldom prove practicable); it would be better to establish a procedure (such as, a trainee Review Board) during which each case will be considered against criteria such as: Resources required to repeat the test, without compromise of test conditions and assessment standard. Requirements for additional tuition and/or practice. Likelihood of trainee success during the re-sit. A policy for determining pass or failure. This can be a statement such as, “to successfully complete this training, trainees must achieve all TOs,” or, “pass all summative tests”. The inclusion of such a simple statement provides focus to the testing; it can also prevent misunderstanding or grievance later on. A policy for the maintenance of test records. This should state a clear requirement for: A record for each trainee which includes a summary of all test results (both formative and summative) as well as a record of formative action taken such as counselling notes or copies of written warnings. This record should be used to guide the preparation of the trainee report. A consolidated tabular record of summative test results. This record, accumulated over several repetitions of a training activity, provides valuable information for InVal of training in general and evaluation of tests in particular. A policy for other reasons to Return to Unit (RTU) a trainee such as cheating or a lack of core values and standards. Where testing is required14, the overall AStrat will be used to produce the ASpec, as well as tests. a policy 15 for the identification and prevention of malpractice, including malpractice involving use of generative Artificial Intelligence (AI)16. 14 Testing is not always required, e.g. on an ‘attendance course’ such as the Future Commanders’ Study Period at DefAc. 15 Guidance to help develop policy on malpractice will appear in future editions of this DTSM. 16 Until this guidance on AI malpractice has been developed, the following publications are recommended:   and CEC paper: use of AI in Assessment – King’s College London."
  },
  {
    "id": "17ea9d28-9a6f-4475-a858-294b18ba0faf",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Refinement of KSA",
    "content": "Prior to the development of the ASpec, from the AStrat, it is important to revisit the KSA Analysis which was conducted as part of Element 1. Refinement of the KSA Analysis and will ensure that the ASpec is appropriate to the requirement and ensures that assessment is developed taking into account what is to be assessed (i.e. assessing a Skill requires a different form of assessment than testing Knowledge or measuring Attitudes). The content of Section 1.2 in this Guidance on Initial KSA (1.3.4A) can be referred to again at this stage. Further Guidance is also provided when the ASpec (2.4.2) is discussed."
  },
  {
    "id": "8ee68209-a3de-4cd5-bf15-f2b0b96ced1f",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Specification",
    "content": "While the AStrat gives an overview of the training assessment, where testing is required, the detail is provided in the ASpec. An ASpec is defined as a specification describing the organisation, type of test, marking details, pass/fail criteria for the assessment of TOs and the consequences of failure. It provides practical details required to assess the achievement of the Standards specified by an associated TO. The suggested format for an ASpec is at Annex B. The factors listed in Table 4 should be considered. Table 6: ASpec Factors Testing terms and concepts. The terms and concepts for testing are: Purpose. The main purpose for testing is achievement measurement. This is designed to measure trainee learning and to use the measure taken as a basis for assessment (e.g. a Service person who dons a GSR in fewer than the requisite number of seconds (measurement) is deemed to have passed that element of the CBRN test (assessment)). Test suitability. The main factors affecting test suitability can be considered under: Test validity. Defined as the extent to which a test measures what it was designed to measure. Test reliability. Defined as the extent to which a test will provide the same measurement when it is repeated. To be considered reliable, a test must measure consistently and accurately. Test usability. A test may be valid and reliable, but will not feasible if it is impracticable to implement. Formative and summative assessments. Assessment (or test) results are sources of information that can be put to many uses. Tests can be classified by the type of assessment made using the results: Formative assessment. Also known as progress tests, formative assessments are administered at intervals during a training activity to gain data for feedback to trainees (and trainers) on trainee progress. They provide the basis for action to be taken by both parties to promote trainee success. The outcome of the assessment is to determine how much progress the individual or team has made thus far. Formative assessments should be used regularly to make trainees aware of their achievements and the areas in which they need to improve further. Summative assessment. Summative tests are used to determine whether trainees have achieved the TOs, or significant EOs, which are deemed prerequisite to further training. They provide the required data to assign pass/fail grades and are conducted at the end of training or at the end of each stage/module of training. The outcome of the assessment is to determine whether the individual or team is competent to carry out the Role or task without supervision. Frames of reference. Tests are designed as instruments to measure trainee Performance and ability. Like any measurement tool, tests require a frame of reference in which to operate, otherwise the measurement cannot be quantified. Tests can be categorised as using either of the following frames of reference: Criterion reference. These tests measure whether a trainee has achieved a certain Standard. The trainee either passes or fails by reference to the criteria set in the test (e.g. criterion referenced tests are the driving test (theory) and the driving test (practical)). Norm reference. These tests measure a trainee’s relative standing against their peers. They are used to rank or order trainees rather than measure the achievement of specific objectives. Once ordered, trainees may then be grouped into specific classes or grades. What to test. Trainees should at some point demonstrate that they can meet the required Standard of Performance for each TO. If areas are not tested, the Customer has no guarantee that the individual or team has achieved the required Standard. However, it is not always possible to test all training outcomes. Therefore, choices may have to be made, e.g. whether to test: All the Skills or Knowledge? All practical Skills? All TOs separately and/or in combination? All EOs/ KLPs? Test formats. There are two main ways in which tests can be presented: Practical tests. These tests are used to test the achievement of a Skill or Skills, both mental and physical. They can assess either the product of the Skill, or the process involved in employing the Skills and should have an associated checklist to ensure both reliability and objectivity in assessment. Examples of practical tests are Weapon Handling Tests, and simulator-based tests. Theory tests. Theory tests measure the Knowledge which supports Role skills by taking a sample of what must and should be known. These tests are usually in written form although oral tests can also be used. To achieve validity, theory tests require much care in construction and scoring. Marking of assessments. All assessments should be conducted in a reliable and equitable manner. This is to be achieved by ensuring the standardisation and moderation of the marking process. Standardisation. Defined as a methodology for ensuring trainee responses are judged using predefined criteria, in order to provide a consistent basis for assessing all trainees. Moderation. Defined as a methodology for ensuring the marking of assessments is equitable."
  },
  {
    "id": "1361e587-3803-44ba-a98e-63c4e229cef8",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "It is important to consider the most appropriate and effective blend of training Methods & Media options that provides the most effective balance of performance, cost and time in achieving the required KSA. These options should be further refined as part of the Design process by exploring, in order: Methods. These are the strategies or techniques used to achieve the required KSA. Media. These are the tools and means used to apply the Methods selected."
  },
  {
    "id": "ca4e4e21-93ab-4a98-a5a5-f8cd258926ef",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Learning factors.",
    "content": "Type of learning. The Method used to deliver training depends on whether learning is categorised as Knowledge, a mental or physical Skill, or an Attitude. Each EO must be examined to determine whether it is primarily expressed as a KSA. This will suggest the appropriate choice of Method (e.g. a Skills-based EO must have some element of practice involved in the Method; whilst role-play is an example of a training Method suitable for a Behaviour-based EO). The aim must be to choose a Method that is compatible with the material to be learned. Learning a physical Skill may require equipment and machinery and a low trainee-to-trainer ratio as it tends to be trainee-centric. Knowledge learning is most effective and efficient via e-learning, in the form of a lecture, or with links to information. This works best in a flipped classroom, where learning is then consolidated through discussion. Retention ability17. A basic categorisation of training Methods should state that these can either be trainer or learner centric. The appropriate selection of training Methods improves the effectiveness and efficiency of learning. Wherever possible, a learner-focused approach should be adopted although this is not always as simple as it seems as it can be time consuming and resource heavy. A learner-focused approach aids information retention by considering the needs of the trainees and increasing their involvement in the learning process. A trainer-focused approach, whilst increasing trainee-to-trainer ratios, is not as effective for aiding trainee retention. The more active the trainee is in the learning process, the higher the rate of retention. 17 See the Competence Retention Analysis (CRA) Handbook. Learning preferences. Learning takes place when learners reflect on what they have done, or from what others have done. This is the case for all learners, both in an individual and a collective setting. Therefore, it is imperative that for the effective and efficient acquisition of the required KSA, time is built into the programme, to facilitate learning through reflection. People learn from reflecting on their own, or others experience. Therefore, enabling experiential learning is the most effective and efficient way of enabling learning."
  },
  {
    "id": "63ab5847-e64b-469a-a43e-96631e1dcc5b",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Trainee characteristics.",
    "content": "Motivation. Learners are motivated to learn when they know the relevance of the learning, and when they are enabled to learn through a learner-centric way. For knowledge acquisition, motivation best comes through a flipped classroom, where the learners are required to access the learning (through e-learning for example) before they consolidate and reflect on what they have learnt, in the classroom. Literacy level. Information should only be presented to learners in a form they can cope with. Information should not be at a level that they cannot comprehend, nor should it be at a level which will patronise. Key questions should include ‘What is the literacy level of the trainees?’ and ‘What is the most appropriate language for passing information?’ Numbers. How many trainees should there be in each group? A large group will make trainer demonstrations difficult to plan. A small group will limit trainee discussions and peer learning."
  },
  {
    "id": "d1a993e8-a235-4afc-9c92-969cbf9d030b",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Practical constraints.",
    "content": "Facilities and resource availability are likely to limit the choice of Method and the most appropriate Media are not always practical or within budget. The medium may be unavailable; there may not be time to meet all the TOs; it may be difficult logistically or financially; or the group may be of mixed ability and unable to make the best use of the Media selected. Where resources to support the optimum training Method are not available, lack of availability is likely to affect the successful achievement of the TOs. Such constraints should be captured in the Constraints Analysis and/or the Risk Register. The TRA and Customer should be advised of this fact and made aware of the likely consequences."
  },
  {
    "id": "ef02a080-e3b9-451a-b009-9d7d37cc7f74",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Trainer attitude and ability.",
    "content": "A question that will need to be asked is: can, or will, the trainers be able to use the Media selected? Trainers are unlikely to use Media that they do not understand, which increases their workload, or which is complex to manage. If new teaching Methods are to be introduced, then due regard must be given to ensuring that trainers are both willing and able to cope. To avoid such issues designers should: involve trainers in the Design process as early as possible. identify any additional trainer training requirements. develop a trainer training strategy to enable trainers to explore new technologies followed by localised CPD activity to ensure awareness is maintained on TEL developments, including opportunities for TEL exploitation; as a minimum, trainers should be able to facilitate learning using the DLE."
  },
  {
    "id": "4dc72637-af76-49b3-be32-d6ddb842ebcc",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Training designers.",
    "content": "Training designers should maintain awareness of emergent TEL and have a working knowledge of the DLE as a minimum. The requirement to design training to meet the needs of different types of learners, including skill fade and learner-centric approaches in an increasing resource constraint environment places the training designer at the centre of the training design process. Training Providers and 3rd Party Contractors will need to ensure their training designers are provided with sufficient training, expertise and resources in order to design training to meet the needs of Defence. The TDA should ensure the following: Liaison with the DLE Subcategory Manager for potential DLE inclusion. Creation of a DLE front page for every course iteration. For any NTS training design, key training design personnel should be invited to the TNA WG during TOA and TNR stage to plan for TEL interventions. Training Providers/3rd Party Contractors to develop a training designer training strategy and plan to enable training designers to intelligently utilise TEL to facilitate a blended learning approach as to optimise efficiencies. This should be followed by ongoing coaching CPD to ensure training designers maintain TEL and blended learning currency. Where applicable, ensure that Training Providers’/3rd Party Contractors’ training designers are provided with OEM Train the Trainer (TtT) training prior to RFTD for all NTS capabilities. Ensure the training designers are provided with all OEM TEL training documentation (hardcopy, electronic (Word, PDF, Interactive Electronic Training Manuals/Publications (IETM/Ps), media prior to any training design. Develop a trainer training strategy to enable trainers to explore new technologies followed by localised CPD activity to ensure awareness is maintained on TEL developments, including opportunities for TEL exploitation. As a minimum, trainers should be able to facilitate learning using the DLE."
  },
  {
    "id": "18a8b5f6-0430-44ec-b23f-596c71109dfa",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Time availability.",
    "content": "Care should be taken to avoid false economies. A lecture may seem to be an attractive option for passing large amounts of information in a relatively short time, but the information received by the trainees may be processed at only the most superficial level. This is why lectures should be front-loaded into a flipped classroom."
  },
  {
    "id": "98c23097-b2ec-480c-9d60-d796056201c4",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Need for transfer of learning.",
    "content": "Apart from some types of workplace training, the training environment will differ to some extent from the work environment. It is therefore important that the training Method chosen should minimise this difference to make the transfer of KSA from the training environment to the work environment as easy as possible."
  },
  {
    "id": "ef76703b-bda2-47ce-aea1-c36af6ecebab",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Priority of learning.",
    "content": "It is unlikely that the various subjects to be trained will all be of equal importance to the trainees in their future Role. Some Skills may be used on a daily basis while others may be only used sporadically but, when they are used, are essential. This requires Performance to be maintained at a consistently high Standard. The results of the DIF Analysis (1.3.3), and the consideration of skill fade factors may have a significant influence on the Method selection. In subjects where the possibility of skill fade could have dire consequences, consideration must be given to ensuring that appropriate Methods & Media are implemented to enhance retention. This may or may not require the allocation of extra training time."
  },
  {
    "id": "680fc5ac-3b68-4af6-8fc7-3fa177d37f4d",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "The Different Characteristics of Media",
    "content": "Media factors. The process of selecting training Media requires a good understanding of the EOs and knowledge of the available resources. The main consideration in selecting appropriate Media must always be its effectiveness in supporting learning (both initial acquisition and refresher). Although the quality of ‘presentation’ must not be neglected, what really counts is content (consider: are the Media capable of presenting training stimuli for learning?). Often one medium is not enough for presenting the stimuli required and so a multimedia or ‘blended learning’ approach is required."
  },
  {
    "id": "67802f2c-47bc-41c5-84c0-4010ac345d76",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Variety of Media.",
    "content": "Consideration should be given to the characteristics of Media, in terms of whether they are essential or optional: Essential Media characteristics. Essential Media characteristics control the clarity of the message. For example, learning a foreign vocabulary requires print (to recognise words) and audio Media (to pronounce them). Training designers should consider: media that is appropriate to deliver the desired learning outcomes. media that provides an appropriate level of fidelity. media that can cope with trainee throughput. Optional Media characteristics. Optional Media characteristics improve the quality of the training. There are some considerations that can influence selection: attractiveness to the learner: colour, animation, illustration. the trainees’ study habits. the trainers’ style, habits and Skills. media that, from experience and research, improves learning efficiency. media that allows the efficient management of training. media that has low risk of failure (for whatever reason)."
  },
  {
    "id": "e198345c-6113-4f16-b506-f02306796204",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Methods and Media Selection Process",
    "content": "Methods & Media selection process. The selection of the most effective and efficient way to meet a training requirement involves identifying a range of possible training solutions, in terms of the Methods & Media options that can be used. The choice of options will be dependent upon the requirement, training policy, training throughput and established good practice. These are evaluated by comparing the training and cost-effectiveness of each option, from which the most suitable solution can be chosen and recommended with supporting justification. Typically it is the Knowledge category of the KSA spectrum which can be handled most flexibly through DLE. The DLE is the primary Virtual Learning Environment for Defence and should be considered in the first instance to facilitate various methods and media as part of a blended approach. Defence Direction for Technology Enhanced Learning (TEL) is contained within JSP 822, Volume 6. A particular training Media may appear to be best suited to a particular training activity but can only be adopted as the solution if all resourcing issues (effectiveness, workforce, equipment and facilities etc) combine to produce the most effective, efficient and economic overall through-life package. It is therefore important to determine the personnel, facilities and equipment required to train, and cost them over the lifetime of the training activity including Design, Delivery and Evaluation. Cost-effectiveness can be analysed at a simple level by comparing costs for a number of different areas. Examples where appropriate are: travel and subsistence costs. training equipment hardware/software (initial costs and running costs). equipment maintenance costs. training materials and production of their cost. classroom overheads. accommodation and food where appropriate. When developing a training solution it is important to make the estimates as accurate as possible and record the actual costs incurred in order to provide a basis for estimates in the future. Advice should be sought from budget/finance managers. Once cost and training effectiveness data have been gathered a balance should be made between the two. This may involve a broad qualitative comparison that assisted in the selection of the recommended training solution18. Approval for resources and expenditure should be sought as soon as possible so that training is in place in time to support the Defence need. The selection and subsequent development of the training solution should include the following elements: A list of Methods & Media considered. 18 This activity was initially conducted in Element 1 as a Cost Benefit Analysis (CBA). A description of the Methods & Media options that will partially or fully meet the training requirement, as described by the TOs. An estimation of the relative effectiveness of each Media option. The training penalties of each option stated in terms of the degradation of the Performance, Conditions and Standards as specified by the TOs. A refinements of the CBA using a broad order of costs."
  },
  {
    "id": "4b390d1e-f694-40a5-b556-a23322fe9a4d",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Learning Scalar",
    "content": "In order to assist with the development of the LSpec, it may be useful to order any EOs and KLPs that are linked to the TOs, into a scalar that will assist in the sequencing of the training activity. A Learning Scalar will also help to teach in order (building KSA), prepare lesson plans/events, and develop the LSpec. An example is at Figure 2 (note that EOs/KLPs can be expressed either vertically (taught in that order) or horizontally (taught in any order)). Figure 3: Example of a Learning Scalar"
  },
  {
    "id": "40577bdc-4be8-4639-83da-b257e4043132",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Learning Specification",
    "content": "A key aspect of the Training System is its execution, i.e. the training being delivered to trainees. It is therefore at this stage that the result of the previous Analysis stages and Design stages are brought together to enable the trainer to produce lesson plans, and/or collective training event plans, to ensure effective training wherever it is delivered. This is done through the generation of LSpecs; the main purpose of which is to control the execution of training i.e. what is taught and how it is taught. LSpecs are produced from the outputs from the Design stages covered previously that produce an AStrat and Methods & Media selection. The Defence format for LSpecs is at Annex A. Depending on the nature of training, LSpecs can be succinct or very detailed. They contain the details of the EO and associated KLPs, the relevant assessment/test, Method & Media selected, time allocated and resource requirements and essential references. Thus the lesson, or event, to be delivered and all the information needed by the trainer to deliver training, including the structure and sequence of training, is contained within the LSpec. It covers 2 main areas: administrative details of the course, and the execution parts of the training delivery. There may be more than one execution part if there are a series of lessons, or events, required to achieve a single EO. Administration. This part of the LSpec outlines the administrative details of the training activity. Execution. This part of the LSpec lists all the essential details of the lesson/s, including a summary of the structure (through the listing of the KLPs). It can also be used to evaluate the training delivery. The most important part of the LSpec is the Development section (within the Execution) as it deals with the material to be taught and includes the structure of the main body of the lesson, or event, via the sequencing and development of KLPs. It should include all essential information on content with reference to the use of any Methods, Media and teaching activity. All the material delivered is based on the TO as well as: EO. Each LSpec should be based on an EO which contributes to the main TO. However, there may be instances where more than one EO is covered within one LSpec (where the material is very closely related) and should therefore be taught as an integrated whole. An LSpec may also cover more than one lesson or event. KLPs. In order to achieve the EO, it is broken down into a number of relevant KLPs. KLPs are sequenced to ensure that the lesson develops logically and the EO is met. The main components that contribute to any LSpec are summarised in Figure 3. Figure 4: LSpec Contributing Components A suggested procedure for writing LSpecs is summarised in Table 5 and a more detailed LSpec is at Annex A. Table 7: Suggested LSpec Writing Procedure Management of LSpecs. If there is an inconsistency in what is taught, trainees may fail to achieve the KLPs, EOs, TOs and consequently the FTS. A system is required by Training Providers to ensure that LSpecs are controlled and managed. Management of the LSpec is important to ensure: a recognised amendment procedure to avoid unauthorised changes. the correct issue of an LSpec is being used. a record is kept of the current amendment state."
  },
  {
    "id": "6a6a8ba5-3859-4859-b15d-c2c451e8b6f1",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "C – Learning Specification (LSpec) Example",
    "content": "Formal Training Statement (FTS) Example"
  },
  {
    "id": "9e1fcd17-d1b4-4e04-809b-730318e3f0ee",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "19 C = Core, L = Legal, A = Accreditation."
  },
  {
    "id": "15339ae1-80ba-498f-a64b-18e835c68b6a",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Assessment Specification (ASpec) Example"
  },
  {
    "id": "483f2608-5a42-459f-a9ec-881d51971800",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "Learning Specification (LSpec) Example"
  },
  {
    "id": "7f81217e-45a8-4cda-80ce-d509af03301e",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Risk Assessment",
    "content": "Trainer is to make students aware of unit risk assessment register in relation to the training environment."
  },
  {
    "id": "77e7e449-e7f6-4459-8e5e-77b08b7003d1",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "SECTION 2: EXECUTION",
    "content": "20 The media indicated is a guideline. The instructor may use media of their choice to display the key points, e.g. PPT/Whiteboard/Flip Chart/Mag Aid. 21 The media indicated is a guideline. The trainer may use media of their choice to display the key points, e.g. PPT/Whiteboard/Flip Chart/Mag Aid. 22 The media indicated is a guideline. The trainer may use media of their choice to display the key points, e.g. PPT/Whiteboard/Flip Chart/Mag Aid."
  },
  {
    "id": "b57d68ab-cca3-4502-a7b5-3f9de28d5cbc",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Document Coverage",
    "content": "This DTSM supersedes all previous DTSMs on Designing Individual Training The totality of DTSMs included in the DTSMs Suite, of which this document is a part, are listed on the DTSMs SharePoint site."
  },
  {
    "id": "f462a01b-aa9d-4ef4-b8c7-5b92bccd60d9",
    "document": "DTSM 3 Designing Individual Training 2023 Edition V1.0.docx",
    "section": "Document Editions / Versions",
    "content": "Annual editions of this DTSM will be published every December in time for upcoming year relevant to the DTSM. Throughout the year, different versions of the current edition may also be published. When every new edition is published, the versions will reset to 1."
  },
  {
    "id": "f4486805-887a-4d2d-8e0a-f67fe701f945",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Uncategorised",
    "content": "Defence Training Support Manual 4"
  },
  {
    "id": "54b946fc-caa1-47d1-abca-6f62d7bcc70b",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 Edition",
    "content": "Version: 1.0"
  },
  {
    "id": "0ef1b6e4-1b06-455a-abed-4c6798d2a0f5",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "How to use this Manual",
    "content": "Defence Training Support Manuals (DTSM) have been developed to support the understanding and implementation of the policy contained in JSP 822. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. DTSMs will be published every December, following the publication of the latest version of JSP 822. Throughout the year, different versions of the latest DTSM edition may also be published. When every new edition is published, the versions will reset to 1. Using the DTSMs is entirely optional, and users may find there are alternative resources available to help them understand and implement the policy contained in JSP 822. Throughout this document there are references to other DTSMs, these references contains hyperlinks that will take you to the DTSMs that are held on the   SharePoint site. The DTSMs currently available are:"
  },
  {
    "id": "2013cc11-b182-4bc2-99b4-134713bc2011",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "The Principles of Defence Training",
    "content": "The effectiveness of training delivery will be measured by the Training Provider and appropriate governance body according to whether the intended outcomes (the TOs) have been achieved successfully. This is determined through the formal assessment process, but there will also be other, indirect outcomes of training (e.g. motivation to learn and creating independent learners) which will need to be considered when planning and preparing effective training. These are not as easy to measure, but they are important if trainees are to perform to the best of their ability. To ensure that all the desired outcomes are achieved when preparing training, the following principles of training delivery1 should be applied: Trainer as role model, Learner-centred training, Self-regulated learning, Technology in training, Inclusion in training, Standardising training."
  },
  {
    "id": "b3ebb88a-5d49-4569-8454-b543ec7efef9",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "The Principles of Adult Learning",
    "content": "The art or science of teaching adults is often termed ‘andragogy’ (Greek for adult- leading) as opposed to pedagogy (child-leading) which is a more traditional trainer led approach to training. Adults are internally motivated and self-directed. Adult learners resist learning when they feel others are imposing information, ideas or actions on them. They prefer to have control over what they learn and when they learn it. Guide (rather than direct) 1 Further advice on the trainer’s responsibilities for the preparation and delivery of training can be sought from the Defence Centre of Training Support (DCTS). The topic is also covered in DTC training. students to foster their internal motivation to learn and move them toward more self- directed and independent learning. Adults bring life experiences and knowledge to learning experiences. Adults like to be given the opportunity to make use of their existing foundation of knowledge and life experience to support their new learning experiences. Identify and acknowledge students’ past experience and use active learning techniques that allow them to problem solve using logical reasoning and common sense. Adults need to know why they are learning something. Adult students become ready to learn when they recognise that they need to learn something in order to deal more effectively with real-life tasks or problems. Aim to increase the student's awareness of the need for the knowledge or skill presented. Adults need to know why they are learning something. Adult students become ready to learn when they recognise that they need to learn something in order to deal more effectively with real-life tasks or problems. Aim to increase the student's awareness of the need for the knowledge or skill presented. Adults want to know they can use learning straight away. Adult learners tend to prioritise their learning and so they want to know how the learning relates to their immediate goals. Provide opportunities to make use of (apply) new learning in a lesson in order to help students recognise the relevance and value of what they are learning. Adults learn by reflecting on what they have done, or what others have done. Active participation is important for adults and they generally learn best by starting with a problem, working to find a solution, and reflecting on the outcome in order to draw conclusions about how they will do it differently next time, in order to increase performance. Where possible use realistic tasks, situations and scenarios for problem solving exercises."
  },
  {
    "id": "93d982c2-f795-466c-8782-fe4d2e36dcdf",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Trainers need to provide training in a way that recognises trainees’ life experiences and allows them to take ownership of their own learning2. In this way, they are motivated to learn and become independent and ‘agile’ learners. Learner-centred training means enabling trainees to actively take part in their learning, rather than passively receiving instruction. It means teaching trainees how to think and solve problems by drawing on their past experiences, using common sense and logic to research and evaluate evidence, then reflecting on their findings to reach conclusions. Learner-centred training uses active training techniques and lets trainees learn from each other and from their own mistakes. It promotes deeper learning, which is meaningful and memorable, rather than surface learning which is easily forgotten. It is the most effective and efficient way to provide learning. The DTCF sets out the requirement for “learning events to be learner- centric and structured to the learning process,” in Competency Group 2 and the requirement that “individuals are actively engaged in the learning process” in Competency Group 4. Application of the  (PAR3) model is identified in Competency 2.1 as appropriate for the promotion of active learning. Competency 4.1 identifies the need for trainers to manage both individual and group needs during learning events."
  },
  {
    "id": "58701c31-6a53-471f-ad19-c4a046e81b4c",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "The PAR Model",
    "content": "The PAR model is chosen by Defence as the easiest to understand and employ. It should be used as the basis for planning and facilitating all lessons. Trainers should reflect regularly on how learner-centred their lessons are and share good practice where a particular learner-centred approach has worked well (or even if it has not). They should also seek feedback from their trainees on which methods and techniques are most effective from their point of view. People learn from reflecting on their experiences, i.e., they do something and reflect on how successful it was, in order to draw conclusions, supporting by the trainer, on what they will do differently next time. Whilst having the experience themselves is preferable, if this is not possible, then the next best option is to consider the experience that somebody else has had, reflect on how successful it was, and draw conclusions, supported by the trainer,  on  how  they  will  do  it  differently  to  be  more  successful.  4 2 The art or science of teaching adults is often termed ‘andragogy’ (Greek for adult-leading) as opposed to pedagogy (child-leading) which is a more traditional trainer led approach to training. 3 Petty, G. (2009). Evidence Based Teaching (2nd ed). Nelson Thornes. 4 Social Learning Theory, eg, Bandura (1977). Table 1: Lesson Structure and the PAR Model 8\tDTSM 4 (2023 Edition, V1.0)"
  },
  {
    "id": "086e2739-d437-42c6-a6d5-87fad94293ee",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Self-Regulated Learning",
    "content": "Making training learner-centred also encourages trainees to  their learning, i.e. they monitor their own knowledge and skills and make decisions on how they can progress. Trainees who self-regulate their learning are motivated to learn through-life and are confident of their ability to learn, and so they are more likely to take action to remain competent and current in their job role. Trainers can teach trainees to self-regulate by prompting them to set and reflect on individual goals, using feedback to then identify and review what they did to achieve the goal. Concentrating more on what the trainee did (or did not do), rather than the actual outcome, helps to develop these self-monitoring capabilities. Learning from mistakes is also a very effective tool in self-regulated learning and trainees need to be given the freedom to make mistakes where safety, time and resources permit. The DTCF sets out the requirement for “learning events to meet both organisational and individual goals” in Competency Group 2 and the requirement for trainees to “set realistic personal goals based on self-assessment and constructive feedback” in Competency Group 4. Competency 2.2 requires the trainer to apply the 5 components5 of the self-regulated learning process and Competency 4.2 highlights the importance of goal setting, feedback and learner self-reflection. Trainers should aim to use these basic coaching techniques both when delivering lessons and when working with individual trainees. Self-regulation in learning describes a process of controlling and evaluating one’s own learning6 and behaviour7. This process may be subconscious, but is more effective if a conscious activity. There are four stages17: task perception, goal setting, enacting and adaptation. 5 Readiness, Resourcefulness, Resilience, Reflectiveness, Responsibility. 6 Zimmerman, B.J. (2008). Investigating self-regulation and motivation: Historical background, methodological developments and future prospects. American Educational Research Journal, 45, (1), 166- 183. 7 Zimmerman, B.J. and Campillo, M. (2003). Motivating Self-Regulated Problem Solvers. In J.E. Davidson and R.J. Sternberg (Eds.). The Psychology of Problem Solving. Cambridge University Press. 17 Winne, P. H., & Hadwin, A. F. (2008). The weave of motivation and self-regulated learning. In D. H. Schunk & B. J. Zimmerman (Eds.), Motivation and Self-regulated learning: Theory, Research and Applications. New York: Lawrence Erlbaum. Figure 1: Self-regulation in Learning Trainees who self-regulate their learning are motivated to learn through-life and are confident of their ability to learn, and so they are more likely to take action to remain competent and current in their job role. Trainers can teach trainees to self-regulate by prompting them to set and reflect on individual goals, using feedback to then identify and review what they did to achieve the goal. Concentrating more on what the trainee did (or did not do), rather than the actual outcome, helps to develop these self-monitoring capabilities. Learning from mistakes is also a very effective tool in self-regulated learning and trainees need to be given the freedom to make mistakes where safety, time and resources permit. Self-regulated learners are ‘Active learners’ who attribute their successes or failures to factors within their control e.g. effort expended on a task, effective use of strategies) within their control. They are aware of their strengths and weaknesses in learning, and they have a range of strategies they appropriately apply to tackle the day-to-day challenges of learning tasks. Table 2: Active v Passive Learner Trainee motivation is the key factor in adopting self-regulation. Trainers need to prompt learners to set and reflect on their personal goals and identify and review what they did to achieve the goal. In feedback, trainers should concentrate on mastery (strategies and processes) rather than the outcome (overall performance or product) itself in order to help learners develop self-monitoring capabilities. The Campaign for Learning (2013) 9 identified 5 attributes of the self-regulated learner: 8 Adapted from Petty, G. (2009). Evidence Based Teaching (2nd ed). Nelson Thornes."
  },
  {
    "id": "45bdbfc2-314e-45e7-a470-ba6f7a771c4b",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "9",
    "content": "Figure 2: The 5 Attributes of the Self-Regulated Learner"
  },
  {
    "id": "13a28901-2354-445e-ad64-deee8630e51a",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The Defence Systems Approach to Training (DSAT) Quality Standard (QS) requires a system of documentation to define and communicate the training requirement and to ensure that appropriate controls and procedures exist to guarantee that the totality of the formal training provided satisfies the operational/workplace performance requirement."
  },
  {
    "id": "07c24496-ac75-4417-a8c0-0594faf0d4b6",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Statement of Training Task",
    "content": "Once accepted by the appropriate governance body (such as the CEB), the SOTR is used as the source document to develop the SOTT. The purpose of the SOTT is to allow the Training Provider to take the agreed output-based requirement and develop it into a deliverable training solution for the following year. In addition to the information already contained in the SOTR, the SOTT should contain, as a minimum: The training activity profile (number of courses/exercises etc with start and finish dates). The total trainee input number and the disaggregated (the number of trainees per training activity) number by training activity. The SOTT may eventually differ from the SOTR. In-year changes to the SOTT should be managed by the CEB but an audit trail is to be maintained by both the CEB and the SOTR Coordination Organisation to show why differences have occurred. Where differences occur within a contractual arrangement, penalties may apply. Although not an exhaustive list, the following issues may result in changes to the SOTT from what was originally endorsed in the SOTR: Funding bid when the SOTR was agreed is not successful. Impact of any Urgent Operational Requirements (UORs). Changes to the Role/Team PS. Results of InVal. Any potential long-term gapping of trainers. Impact of in-year funding constraints. Recruiting targets not being met. Impact of operational tempo. Historic failure rates in determining input to achieve output SOTR."
  },
  {
    "id": "e7a9c778-dca4-4f12-8a89-4d43baacfb9f",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Learning Specification",
    "content": "Learning Specifications (LSpecs) contain the information the trainer needs to deliver training, including the structure and sequence of training (as detailed in the Learning Scalar). The main purpose of the LSpec is to control what is taught and how it is taught. The trainer should teach all of the KLPs as specified in the LSpec. If there is an issue with the KLPs (e.g. if they are no longer current or relevant) then the DTS, DTM or Chain of Command should be informed. The benefits of using the LSpec include: ensuring the material taught is based on the specified TOs. providing details of suitable Methods & Media, so the material is delivered in an effective manner. helping ensure consistency between trainers and different training activities. saving preparation time. The manner in which the KLPs are delivered is determined to some degree by the LSpec, but there is flexibility for the trainer to impart their own style and experience. If it seems that the LSpec is too prescriptive and is limiting the trainer’s ability to deliver the training effectively, then this should be discussed with the DTS, DTM or Chain of Command."
  },
  {
    "id": "ca7adc4b-a0b7-42fd-871d-6a334f01ebdf",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Strategy",
    "content": "The AStrat is useful as it ensures that the assessments are reliable, valid and administered correctly. An AStrat will give clear direction on: summative assessment of each TO. formative assessment of trainee progress. how grades should be assigned and interpreted. action to be taken upon trainee failure of a (valid) assessment. a policy for determining pass or failure. a policy for the maintenance of assessment records. a\tpolicy\tfor\tthe\tidentification\tand\tprevention\tof\tmalpractice,\tincluding malpractice involving use of generative Artificial Intelligence (AI). a ‘Return to Unit’ policy for infringement of values and standards etc."
  },
  {
    "id": "778d881f-b6d8-4e1b-9294-4fa955fe9256",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Specification",
    "content": "While the AStrat gives an overview of the training assessment, the detail of how the assessment is to be conducted is contained in the Assessment Specification (ASpec). It contains all the information needed to conduct a valid assessment including the type of test, marking details, pass/fail criteria for the assessment of TOs and the consequences of failure. Trainers should always use an up to date ASpec when planning an assessment. The main purpose of the ASpec is to control what is assessed and how. Trainers must assess all of the EOs and KLPs as specified in the ASpec and not make any changes that alter these. The manner in which the assessment is conducted is determined by the ASpec. Designers strive to provide as much realism as possible, sometimes by using simulation, instrumented or scenario-based activities and so unauthorised changes to the realism of a practical assessment may make it invalid. If limited resources make it difficult to deliver the assessment in the recommended way or the ASpec appears too restrictive, the DTS, DTM or Chain of Command should be informed."
  },
  {
    "id": "800c584f-3f4e-4db4-9ff4-a3052184073c",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Commander’s Risk Assessment",
    "content": "In addition to the ongoing process for assessing and registering risk, as part of the MTS, Training Providers should conduct a health and safety risk assessment of the training environment and all training activities. This assessment should be documented, maintained as a Quality Record, recorded in the training documentation and made available at the point of delivery. Trainees should be made aware of the risks associated with a particular training activity or training environment prior to the training activity taking place. Volume 4 of JSP 822 states the need for a CRA to be produced to ensure proper and appropriate risk management, and Care and Welfare support to trainees."
  },
  {
    "id": "eb7eaad9-0288-4178-867c-c110fe37223d",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Supervisory Care Directive",
    "content": "The Training Provider is responsible for the care of all personnel that live and work within the training establishment or environment. However, particular attention should be paid to the Care and Welfare of trainees, particularly those in initial training. To this end, Training Providers are to ensure that they meet the requirements as laid out in the Direction in Volume 4 of this JSP for the Supervisory Care for Phase 1 Recruits and Phase 2 Trainees which states the need for a SCD. Trainers and training support staff must be appropriately trained and checked and supported to ensure suitability to the unique responsibilities of working with trainees."
  },
  {
    "id": "cea55963-f2bc-4d9b-9d62-bf1138a4b2cd",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Quality Manual",
    "content": "The TQM is the CEB-endorsed document that sets the requirements, both in process and output terms, necessary to set and maintain the Defence-mandated QMS. Each TQM will be unique to the specific requirements of the Training System for which it is written. It is recommended that work begins on the TQM as soon as is practical. It is common for the Training Provider and TDA to produce the TQM but the document must also reflect appropriately the activities of the TRA."
  },
  {
    "id": "abdfd6e3-d6d1-4e26-bc38-3f472a60a04f",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Lesson/event planning is an essential part of the training delivery process. A good lesson plan considers all the needs and expectations of the training audience, prepares for any ‘what ifs’ and enables the trainer to feel confident that nothing has been left to chance. Lesson/event plans must be based on the LSpec and take a learner-centric approach. They are created by the trainer using the LSpec and a trainer should request support in developing their Lesson Plan should they need it10. One of the key benefits of planning learning is that it encourages the trainer to think about any potential barriers to learning and to plan how to overcome these. In addition to the information taken from the LSpec, lesson plans may also include information on: Timings. A key part of the skill is in planning timings. Time is at a premium in most training environments and a lesson/event which runs over time, or which fails to deliver all of the planned KLPs in the time allowed is likely to have a significant impact on other parts of the schedule. The environment. Clearly the environment can have an impact on learning, and, for the trainer, this is even more relevant, given that the environment could vary from a hi-tech simulation suite to a shell-scrape in a forest on exercise. Whilst it may not always be possible to choose the best environment in which to conduct training, good planning will ensure that the potential barriers presented by less than perfect surroundings are reduced or removed. Lesson/event plans should contain sufficient information on how the environment will be managed, including the safety brief and risk assessment. Motivation. A lesson/event where motivation has not been considered and planned for is unlikely to be very successful. Good trainers consider their training audience and plan approaches which will motivate trainees, both as individuals and teams. Awareness of possible demotivators is important as is how to remove or avoid them. Table 1 shows examples of both motivators and demotivators that might be relevant to military training whatever the training environment. 10 Examples of lesson plans are on the DLE Table 3: Training Motivators and Demotivators Trainee interaction. Even with full use of TEL and flipped classrooms to minimise lecture time in the classroom, some events in training may still need a more directed delivery approach. This is to be avoided whenever possible not least because it is the learner-centred approach that ultimately helps the trainee to develop confidence and competence. Facilitation of learning means the trainer will relinquish much of the power but none of the overall control. A good trainer should be able to let the trainees direct the pace and content according to their abilities while ensuring that the KLPs are still drawn out. Confirmation of learning outcomes. It is not enough just to deliver the lesson/event according to the LSpec; for training to be effective the trainer also needs to know that learning has actually taken place. It is therefore important to plan not only the activities but the Methods of confirming learning outcomes. This can be achieved by question and answer sessions and observing individual activities or by quizzes, tests or trainee summaries."
  },
  {
    "id": "e533bb73-f72d-4334-9f35-25baf0804329",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Lesson/Event Planning in the Workplace Environment",
    "content": "Whilst the generic guidance above on lesson/event planning is relevant to all training environments, there are some special considerations for training that is undertaken in the workplace. Lesson/event planning for workplace training is just as essential a part of the training delivery process. Depending on the delivery Method to be used, a workplace lesson and/or event plan similar to those used in a more structured training environment may be appropriate. Where TOs are delivered over a longer period of time in-role, the trainer will need to be much more flexible in their approach and the planning process should reflect this. The use of LSpecs and lesson/event plans remains the same. Where workbooks or portfolios are used to stipulate the training to be delivered, planning may focus more on identifying and organising opportunities for learning to take place in the work environment. In this case, the trainer may wish to plan a programme of workplace Tasks that will present the trainee with the opportunity to practise a Skill under supervision, or to learn new Knowledge and Skills through workplace experience. The Standards to be achieved should be clearly stated and the trainer should know the process for assessing and recording completion of the TOs. The workplace environment may be very different from a more structured training environment and will have its own advantages and disadvantages. Potential barriers to workplace learning include: Distractions. Learning in the workplace is a much more informal environment and the trainer may have less control over distractions like background noise and interruptions. While this may create a much more realistic context for the trainee, it may also hamper the delivery of new information and could impact on safety. Good planning will ensure that the risks are properly assessed and, where it is likely that noise or other distractions will impact on learning, the plan should contain information on how this should be managed. Trainee interaction. Workplace training is ideal for a learner-centric approach to training and ultimately helps the trainee to develop confidence and competence. In order to facilitate learning, the trainer must be prepared to step back and allow the trainee to learn from experience, even if this means allowing them to make mistakes where safety permits. Confirmation of learning outcomes. For workplace training to be properly effective, the trainer should plan not only the tasks and activities to be conducted but also the Method of confirmation to be used, whether this is just through question and answer session, observing completion of a task, summarising the KLPs at the end of a task or allowing the trainees to summarise themselves what has been learned."
  },
  {
    "id": "82092e79-4904-405e-82fe-b1d8c3124c83",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "In order to ensure that training is analysed, designed, delivered and assured to a set standard, Defence uses the Defence Systems Approach to Training. A great deal of work goes into the design and development of training to make sure that it is relevant, realistic and prepares Defence personnel properly for the jobs they have to do. Well-designed training, however, can still fail if it is not delivered in the way it was intended. Training deliverers must therefore comply with the specifications of the training design when they deliver their lessons. The DTCF sets out the requirement for trainers to employ “relevant DSAT course documentation to identify desired learning outcomes and plan collective learning events” in Competency 2.1 and to adapt “delivery according to trainee response while still achieving planned outcomes” in Competency 4.1. Trainers must ensure the overall objectives or the lesson are met and that the relevant Learning Specifications (LSpecs) and Assessment Specifications (ASpecs) are adhered to. Course documentation (specifically the LSpec, AStrat and ASpec) is the trainer’s crucial link to the DSAT process. It provides the authority to deliver standardised training and forms the basis for the production of course programmes, lesson plans and assessments. Training must be delivered in accordance with the relevant specifications and so if any part of the course documentation is not available for a specific course or lesson, trainers should inform the course manager immediately. Trainers or trainees may highlight issues with training content, for example, pertaining to currency or relevance. In this case, it is important to use the DSAT system correctly to highlight shortcomings. Alterations to Training Objectives (TO), Enabling Objectives (EO) or Key Learning Points (KLPs) within the course documentation can only be achieved by following local course change processes, which must include the Training Delivery Authority. Trainers must be absolutely clear on their boundaries when adjusting lesson content and should be fully briefed on the process for requesting updates or amendments to course documentation."
  },
  {
    "id": "b9f33ca3-ad95-49ae-ad6b-3e1627834894",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Resourcing training. Resourcing the training activity is intimately tied into its programming and scheduling. The Training Provider, supported by the TDA and other stakeholders, should ensure that the activity is properly resourced. This is in order to implement and maintain the Training System, continuously strive to improve its effectiveness, and enhance Customer satisfaction by meeting the TRAs training requirements. Human resource. The personnel involved in all aspects of DSAT, particularly in the delivery and evaluation of the training activity should be trained and competent to carry out their Roles. It is the responsibility of the TDA, enforced by the Training Provider, to ensure that all training staff are provided with the appropriate training and have relevant experience. Infrastructure and environment. The Training Provider, supported by the stakeholders, should also determine, provide and maintain the infrastructure and working environment needed to achieve the trained output, which includes: buildings, workspaces and associated utilities; training equipment and support equipment (both hardware and software) and training estates (with associated facilities); supporting services."
  },
  {
    "id": "c359a1b9-c68c-4348-88de-f85b371a2e0b",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Programming training. The Training Provider should produce and maintain an annual programme of all training activities. Any changes which arise within the current Training Year (TY) should also be reflected in the annual programme of training activities. There is no suggested methodology for programming. A common sense approach should be used and a clear understanding of the freedoms and constraints available to programmers will ensure that training activities: Use available resources efficiently and to maximum effect; Match the most effective and efficient Method & Media to the desired learning outcome; Generate variety, stimulation and interest; Programme different activities intelligently (such as not programming a lecture directly after a session of PT) that build progressively from basic individual Skills lessons through to team and collective training events; Build in time for movement, administration, rest, meals and breaks; Consider environmental, seasonal, weather or light factors if required (for outdoor practical and collective training); Use a standardised programming format that builds routine and publish changes to the norm early; Simulate, replicate or use realistic or real Conditions; Have a method of informing trainees and trainers of unavoidable, short notice changes to the programme; Minimise the administrative or non-training burden to the trainee. Programming is usually carried out by a centralised design cell or Training Provider as a headquarters function. In larger Training Providers it is essential that trainers adhere to the programme as resources will need to be carefully managed to meet the needs of a high number of trainees on different training activities."
  },
  {
    "id": "8dab19d0-5eb3-43f7-865d-edbd8f053596",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "To help identify any issues or problems early, a pilot course or pilot collective training event should be conducted. Piloting of a training activity is defined as, 'the first delivery of a newly designed training activity under ‘realistic’ conditions'. The purpose is not only to prove what works, but also to highlight problem areas so they can be revised as necessary. Checking the training activity in this manner will ensure it is cost-effective and, therefore, meets the requirement. The aim of a pilot is to establish how well the following perform when used for real with actual trainees: programme. documentation. materials. lesson/event plans. location/environment. resourcing, training support and administration."
  },
  {
    "id": "f3408a79-9197-4ac1-b509-75094f2f9c2f",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Planning the Pilot",
    "content": "Planning the pilot requires answers to the following questions: when will the pilot be conducted? which trainees will be on the pilot? which trainers will be used? how much time is required? are all the resources available and allocated? what revisions can be made during the pilot? (i.e. what alternatives are available?)."
  },
  {
    "id": "7ad099d0-04e9-4dbe-a62b-8c0bf5bed6f2",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Pilot Stages",
    "content": "Ideally, there should be 3 stages to the pilot: Stage 1: One-to-One. An initial assessment of the training material should be conducted using 1-3 SME individuals or small teams as ‘guinea pigs’. Stage 2: Small Group. 6-12 people, or medium teams, who are representative of the intended trainee group, undertake the training together. Those conducting the pilot observe closely and frequently gather trainee and trainer opinions by questionnaires and interviews. Stage 3: Field. The first fully staffed ‘production’ course or collective training event, with genuine trainees and all the allocated training resources and administrative support. 100% of the training delivered is monitored. In practice, resources rarely permit the full application of one-to-one and small group trials, and training activities tend to commence with a field trial. Nonetheless, these procedures should be applied to test and revise at least those portions of a training activity which involve high cost Methods & Media and/or where failure to achieve Standards has to be avoided at all costs. During the pilot, it is important to safeguard the interests of the trainees. The trainees should not be disadvantaged because they attended a pilot. The following actions should therefore be considered: trialling parts or all of the materials before the pilot (e.g. a particular demonstration to ensure it works and how much time it takes). allocate additional time to the pilot to allow for changes and revisions. adopt intensive InVal procedures during the pilot, so issues are identified early and where possible rectified. ensure that trainees that fail part or the whole of the pilot have the opportunity to be retrained and/or retested."
  },
  {
    "id": "7d569ff8-ba50-42f1-a56a-79fc41c5bb49",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Data Collection",
    "content": "Data collection. A major activity during the pilot will be data collection. A comprehensive system of obtaining feedback is the only way of interpreting what is happening. Table 3 provides suggested information for data collection. Table 4: Data Collection Information It is important that the methods chosen to collect data can be used to both evaluate and assess the pilot. All data collected has to be analysed to determine what conclusions may be drawn and what implications they may have. The result of this process is a list of realistic recommendations, supported by the data that should be compiled as a report and submitted to the appropriate governance body (such as the CEB) for approval and action. The data collection and analysis for the pilot should consider: how will the data be analysed (e.g. using statistical methods on test results)? how often will the data be analysed during the pilot and recommendations provided? how will the data be presented, (e.g. bar charts, summary tables etc)? who will be involved in the analysis and final recommendations?"
  },
  {
    "id": "561df53b-b614-45e2-bd8c-fd4662196dcb",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Stakeholder Involvement",
    "content": "Depending on the type of Training Provider there may be up to 7 key stakeholders involved in the pilot: training management staff. training design staff. InVal staff/cells. trainers. dedicated exam staff (where employed). trainees. TRA. Each stakeholder has distinct responsibilities, but few are mutually exclusive. The success of the pilot relies heavily on a collaborative approach to achieve all the tasks. Many activities rely on input from more than one stakeholder. Feedback from InVal will result in changes to the training activity during its lifetime. It should be made clear who is responsible for implementing these changes and maintaining the training activity."
  },
  {
    "id": "5f0b3ab7-1d21-4a4a-a93d-21a31ac01768",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Managing risks to the trained output (i.e. the KSA of the trainees undergoing individual training) is different from assessing and managing risks associated with the Training System. The responsibility for the management of training deficiency lies with the Training Provider. Where risks or issues resulting from identified training deficiencies cannot be mitigated by the Training Provider such training deficiency-based risks should be elevated for treatment or toleration etc. Identifying and raising training deficiencies shows the stakeholders where training shortfalls exist or where risks have been taken owing to either an inability to train certain TOs (due to weather constraints or equipment casualties, for example) or a training failure that has been picked up through the assurance process. Such deficiencies suggest that trainees may not hold the competences that the training should have delivered. These are essentially unplanned but unavoidable training gaps which should therefore be captured and the appropriate governance body informed so that a decision can be made to treat, tolerate or transfer11 the training deficiency. A Training Deficiency is different from the Residual Training Gap. The Residual Training Gap is agreed by the TRA early on in the DSAT process and is articulated in the RTGS. 11 To the receiving unit."
  },
  {
    "id": "84fe052a-88f1-4462-a75e-df9ac40f23a4",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Trainee performance is directly related to trainee potential and to any barriers which prevent them from performing effectively. All trainers will be required to work with a mix of trainees who may be affected by one or more of these barriers. Failure to address this can have a significant impact on trainee motivation, performance and retention. Trainers must therefore ensure that everyone has the same opportunity to learn, develop and succeed. That means preventing barriers from arising where possible and helping individuals to deal with barriers when they do arise. This is known as inclusion in training. The DTCF sets out the requirement for learning events to be “aligned with trainee motivation” and for resources to “actively engage the learner” in Competency Group 2. The requirement for trainees to “feel supported and able to relate their learning and development goals” and that their “achievement is used as a motivational tool” is set out in Competency Group 4. All the competencies in Group 2 and Competency 4.1 and 4.2 highlight the importance of considering both group and individual needs when planning, preparing and facilitating learning. Lessons should be planned to provide both support and challenge for trainees, so that all ability levels can achieve progress. Trainers must be able to support trainees in dealing with a range of different barriers to learning, including those linked to welfare, discipline and specific learning needs. Where the barrier is linked to trainee attitude, e.g. confidence, motivation or stress, the trainer will use coaching techniques to assist the trainee in dealing with this."
  },
  {
    "id": "bc502f97-6d13-45e3-b00f-91bcd6cf6d38",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "14Remedial Training",
    "content": "Consideration should be given to developing a remedial training strategy (which would form part of the overall AStrat) that is appropriately programmed and resourced. There is further Direction on Remedial Training in JSP 822, Vol 2, Ch 6, Sect 6.3. Trainees that fail assessments or otherwise do not meet the required standard of performance within the prescribed conditions should be given all available and practical opportunities to be provided with additional, or remedial, training in order to both give the trainee the best possible opportunity to pass the training activity. This will ensure the costs and resources expended on training are not wasted. Re-testing should only be conducted once the trainee has received remedial training to fill the Knowledge, Skill or Attitude gap. Re- testing without remedial training will likely be a waste of resource. A remedial training strategy should consider: the resources, time and trainer capacity necessary to deliver additional training. the most cost-effective way to deliver additional training (such as integrating remedial training with other or later training activities). programming in revision and refresher training and conducting regular summative assessments to minimise the chances of failure (‘training in’ rather than ‘selecting out’). assessment variability (such as question banks) to ensure that trainees do not learn how to pass the test rather than learn the subject. identifying as early as possible trainees that are likely to need additional training (i.e. catching the problem early, where it will take less effort to correct than it would at the final assessment). use of blended learning methods to provide additional training opportunities. clear policy that explains the conditions under which trainees may expect additional training and where they may not; the policy should also lay out the trainee’s responsibilities for taking charge of achieving their own learning outcomes."
  },
  {
    "id": "122f3e69-a56f-47e2-bf10-f332731aeddb",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Quality Manual",
    "content": "The Training Quality Manual (TQM) is the CEB-endorsed document that sets the requirements, both in process and output terms, necessary to set and maintain the Defence-mandated QMS. Each TQM will be unique to the specific requirements of the Training System for which it is written. It is recommended that work begins on the TQM as soon as is practical. It is common for the Training Provider and TDA to produce the TQM but the document must also reflect appropriately the activities of the TRA. An aide- mémoire for a TQM is at Table 5, and should include: Scope of MTS, including the details of, and justification for, any exclusions. Training Quality Policy. Training targets. Quality Records (and their control). Evaluation Strategy"
  },
  {
    "id": "1d6b6766-d455-4c1e-b7ba-842b49c2dc87",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Quality Policy",
    "content": "This should set out the rules regarding the establishment and maintenance of the QMS to ensure that the Training System delivers training that meets Defence mandated training requirements. Therefore the Training Quality Policy should: be appropriate to the purpose; include a commitment to comply with requirements and Continuously Improve (CI)12 the effectiveness of the MTS; ensure that training targets are established and provide a framework for establishing and reviewing them; 12 Continuous improvement should be embedded in the routine business of delivering training and underpinned by a culture that empowers staff and generates trust so that individuals feel able to step forward with new ideas. In the context of the DTC, the role of the DTM and DTS, in particular, is critical in creating and maintaining this culture of continuous improvement, by promoting the adoption of good practice, the exploitation of learning technologies and the provision of CPD at all levels. That said, all training staff should be made aware of their role in the continuous improvement process. be communicated and understood within the organisation as to the importance of meeting TRA as well as statutory and regulatory requirements; be regularly reviewed for continuing suitability; articulate how reviews and evaluations of the MTS will be conducted; ensure the availability of resources to support the MTS."
  },
  {
    "id": "a722cd71-eef5-4ed6-b181-1071915887c1",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Targets",
    "content": "These ensure that the Training System remains effective, efficient and appropriate to the training need. They should be designed to ensure that the Training System meets the requirements for the trained output. They should also be measurable and consistent with the Training Quality Policy."
  },
  {
    "id": "ee10d38f-c787-4840-980a-a3d00a2daa77",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Quality Records (and their control)",
    "content": "Records should be established and maintained to provide evidence of conformity to requirements and of the effective operation of the MTS. Records should remain legible, readily identifiable and retrievable. A documented procedure should be established to define the controls needed for the identification, storage, protection, retrieval, retention time and disposal of records. In addition, documents required by the MTS will need to be controlled. A documented procedure should therefore be established to define the controls, as required: to approve documents for adequacy prior to issue. to review and update, as necessary, and re-approve documents. to ensure that the current revision status of documents are identified. to ensure that relevant versions of applicable documents are available at points of use. to ensure that documents remain legible and readily identifiable. to ensure that documents of external origin are identified and their distribution controlled. to prevent the unintended use of obsolete documents and to ensure they are identifiable as obsolete should they need to be retained. procedures established for the MTS, or reference to them (including analysis, design, delivery and assurance of training). a description of the interaction between the processes of the MTS (such as the DSAT process itself) including the documents needed to ensure the effective planning, operation and control of the Training System processes. Table 5: Aide-mémoire for a TQM"
  },
  {
    "id": "87cfcdc1-b938-4f92-8b5d-111f3d26c65f",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "Assessment is an essential aspect of any training which must be properly understood and applied. Assessment requires the trainer to determine whether learning has occurred which requires making a judgement on trainee Performance and progress, then to decide whether the trainee is sufficiently competent in a particular Role or Task to be qualified for employment and/or work with or without supervision. The proper conduct of assessment in training can have a major impact on training time and resources, but ultimately will contribute directly to Defence outputs. Trainers should be able to administer assessments in training in a fair, valid and reliable manner, this is achieved through standardisation of conduct and moderation of marking: Standardisation. Standardisation is achieved by adhering to the direction given in the Assessment Strategy (AStrat), and the detail provided in the Assessment Specification (ASpec) . If an assessment is conducted using the same instructions every time, all trainees should receive exactly the same assessment, regardless of when, where and by whom the assessment is conducted. Moderation. Moderation of marking can also help to ensure that the marking of assessments by different trainers is equitable and fair. In this case, a random sample of marked assessments is marked again by another trainer without first seeing the original score or grades awarded. The resulting scores are then compared to see if they agree. Where scores do not agree, trainers should consult with other trainers, and as a team, identify where the marking system is flawed and adjust scores/grades accordingly. Any problems with the marking criteria should be highlighted to the DTS, DTM or Chain of Command. Although it takes many forms, Assessment serves one of two purposes: formative assessment that allows judgement or measurement of progress towards a goal or summative assessment that judges or measures whether that goal has been reached. Both measures can be norm referenced – making comparison with others (performance orientation) or criterion referenced – making comparison to a standard (mastery orientation). Assessment, then, is the primary measure available to the learner regarding their achievement. It is also the evidence base of that achievement. As with other learning activities the principles of motivation, goal orientation, believability, relevance (both to the operational requirement but also to that stage of development and learning) and trust are applicable. Assessment needs to be sufficiently challenging to be credible and to test deep learning should use higher levels of Blooms Taxonomy. Assessment, to be more than a process that just gathers data, must be meaningful to the organisation (actually constitute proof of competence) and be meaningful to the learner through a process of feedback."
  },
  {
    "id": "7f3ca819-835b-4e51-9e75-227341ba230c",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Strategy",
    "content": "The AStrat is useful as it ensures that the assessments are reliable, valid and administered correctly. An AStrat will give clear direction on: summative assessment of each TO. formative assessment of trainee progress. how grades should be assigned and interpreted. action to be taken upon trainee failure of a (valid) assessment. a policy for determining pass or failure. a policy for the maintenance of assessment records."
  },
  {
    "id": "c9f17a21-dc0b-49f7-8203-01693e5638a5",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment Specification",
    "content": "While the AStrat gives an overview of the training assessment, the detail of how the assessment is to be conducted is contained in the Assessment Specification (ASpec). It contains all the information needed to conduct a valid assessment including the type of test, marking details, pass/fail criteria for the assessment of TOs and the consequences of failure. Trainers should always use an up to date ASpec when planning an assessment. The main purpose of the ASpec is to control what is assessed and how. It is important Trainers assess all of the EOs and KLPs as specified in the ASpec and not make any changes that alter these. The manner in which the assessment is conducted is determined by the ASpec. Designers strive to provide as much realism as possible, sometimes by using simulation, instrumented or scenario-based activities and so unauthorised changes to the realism of a practical assessment may make it invalid. If limited resources make it difficult to deliver the assessment in the recommended way or the ASpec appears too restrictive, the DTS, DTM or Chain of Command should be informed."
  },
  {
    "id": "a9d8f3d0-0d79-46af-9635-c1d491249dfb",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Assessment of Learning in the Workplace Environment",
    "content": "Whilst the generic guidance on assessment of learning is relevant for all training, there are some special considerations for the workplace training environment. The proper conduct of assessments in the workplace is critical to the assurance of Defence outputs, since it requires making a judgement on trainee performance and progress and to decide on whether they are sufficiently competent in a particular task to be qualified to work without supervision. Trainers should be able to administer assessments in a fair, valid and reliable manner according to the specifications provided. This is particularly important because workplace assessments may not be conducted under the same conditions that would usually be expected in more structured training environment. Workplace assessments are generally practical in nature and are used to test individuals or teams in the achievement of a Skill, or Skills, both mental and physical. They can assess either the product of the Skill or the process involved in employing the Skills and should have an associated checklist to ensure both reliability and objectivity in assessment. The WTS will often require the trainees to be assessed on a Skill that has already been practised and assessed in a simulated environment but which now needs to be confirmed in a live environment. It is important that workplace assessments are conducted in a context that properly reflects the real challenges of the Role. Workplace assessments can be either formative or summative. The detail of what should be assessed and how it should be assessed is contained within the following training documentation: AStrat ASpecs. A workbook or other document containing a description of the Performance, Conditions and Standards to be achieved. It is important to ensure that the required Performance is assessed under all the Conditions stipulated (such as, field conditions, without support) and to the Standards specified. This may involve reference to a particular Service manual or handbook which is to be detailed in the training documentation. Any uncertainty as to how the assessment should be conducted and/or recorded should be referred to the DTS, DTM or Chain of Command."
  },
  {
    "id": "4efa6e5a-9751-4970-8b63-59a79d9d672b",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Recording Assessment",
    "content": "Recording assessments is an essential activity for all training environments to provide: A record for each trainee which includes a summary of all test results (both formative and summative), as well as a record of action taken, such as counselling notes or copies of written warnings. This record is then used to guide the trainee’s report. A table consolidating all the summative test results for all trainees. This record, accumulated over several repetitions of a training activity, provides valuable information for InVal of training in general, and evaluation of tests in particular. Supporting information for the assurance (audit, evaluation and inspection) and accreditation of training."
  },
  {
    "id": "61e5c44a-425b-45df-8256-7de6906730d6",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Malpractice and Maladministration in Assessment of Learning",
    "content": "Further guidance will appear in the next edition."
  },
  {
    "id": "02985cd1-1757-43ea-8a58-dafc8c09fa1a",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer",
    "content": "Defence Trainers inspire, motivate and challenge trainees in order to get the very best from them. To be fully effective, trainers fulfil the Roles of the specialist trainer and that of leader, including: understanding the key attributes of a trainer; effective delivery techniques; the realities of training; coaching; and the use of technology. The DTC will deliver trainers that are fit for purpose and whose training and development are linked to the DTCF. Trainers must, of course, also be fully SQEP in the subject matter they are delivering. If training delivery is outsourced, any trainer requirements must be specified in the contract. Defence Trainers are responsible for the planning, preparation, delivery and assessment of group learning as well as planning and supporting learning with individual trainees. Dependent on your specific work context, this may include the management of trainee attitudes and behaviour, and the administration of trainee records and reports. The Defence Trainer plays a central role in ensuring that trainees succeed in training. You are not only the focus for teaching knowledge and skills, but also for inspiring, encouraging, supporting and challenging your trainees, through strong leadership, role modelling and coaching. You want your trainees to become independent learners, who can continue to regulate their learning throughout their careers. Whatever their ability level, they will need regular feedback and support to help them assess their knowledge and skills, so that they can learn to identify and set their own goals for further professional development. PROFESSIONAL DEVELOPMENT All training for Defence Trainers is based on the competencies set out in the DTCF. These competencies are graded according to 3 different stages of professional development: Foundation, Practitioner and Advanced Practitioner. On successful completion of Stages 113 and 214 of the Defence Trainer course, you are awarded the JPA competence Defence Trainer Level 1 (Foundation). Completing Stage 315 of the Defence Trainer Course gains you a further JPA competence award of Defence Trainer Level 2 (Practitioner). You then have the opportunity to progress to JPA competence Defence Trainer Level 3 (Advanced Practitioner). This is achieved through a programme of CPD and, where appropriate, additional training. Advanced Practitioner level is awarded by your Chain of Command. In order to achieve Defence Trainer Level 3 (Advanced Practitioner), you will need to work with your DTS to identify ways in which you can provide the appropriate evidence of your advanced knowledge and skills, which should relate directly to the Advanced Practitioner behaviours listed in the DTCF. 13 Defence Trainer Course Stage 1 covers underpinning knowledge and concepts and will normally be delivered through the DLE. 14 Defence Trainer Course Stage 2 focuses on skills development and early application. 15 Defence Trainer Course Stage 3 focuses authentic application and contextualisation in the workplace. It comprises completion of the L3 AET Portfolio and observation of TPs 4, 5, and 6. PERSONNEL EMPLOYED AS DEFENCE TRAINERS The types of personnel employed as Defence Trainers include: Military Regulars. Military Reservists16. Civil Servants Includes all CS involved in delivering and managing training (e.g., DTS) Specialist Instructional Officers. CS lecturers of all occupational groups, e.g., Burnham Lecturers. Contractors17 Defence Contractors Lecturer Contractors, e.g., at DefAc, RTS (Halton) and RAFOTA (Cranwell)18. Other Trainers as directed by FLCs, e.g., University Air Squadrons, Officers’ Training Corps. DEFENCE TRAINER ATTRIBUTES Defence Trainers need to be able to inspire, motivate and challenge trainees, understand their learning needs and expectations, and be able to draw on the right tools and techniques to get the very best from them. To be fully effective, trainers should therefore understand and fulfil both the Roles of the specialist trainer and that of leader, which include: Role modelling. Through the adoption and promotion of the Service core values, trainers lay the foundations for the behaviours that build team cohesion and underpin operational effectiveness. Role modelling is therefore a core responsibility. Facilitating inclusive learning. Trainers should create an inclusive learning environment where all trainees have the opportunity to learn and reach their full potential. Trainees are trained to function as part of a team, but they also need to be regarded as individuals in order to unlock and maximise their potential. Only by 16 All types of Reservists including UTCs are in scope less Cadet Instructors. 17 Contractors employed locally in Educations Centres teaching GCSEs and A’ Levels, for example, are not classified as Defence Trainers. Best practice dictates that they should be qualified at one level higher than the subject they are teaching. The local CRA must address Care and Welfare issues relating to their employment. 18 Currently deemed to be working in ‘HE’ not FE. DefAc do DHET and RTS/RAFOTA do Fellowship of the Higher Education Academy within 12 months of taking up employment. This is a condition of the contract of employment. They must undertake CoT. treating them as individuals, based on their talents and knowledge, will they reach higher levels of achievement. Good trainers are able to facilitate learning in the most appropriate way to suit the needs of the trainees. Trainers will need a sound understanding of learning theory and a broad range of skills including the use of modern teaching techniques, learning technologies and coaching. Assessment of learning. Assessment is an essential part of training delivery and trainers are often asked to make critical decisions regarding trainees’ progress through training and subsequent qualification for employment. The proper conduct of assessment has implications for training time, resources and effective capability. Good trainers are able to administer assessments in training in a fair, valid and reliable manner in accordance with the AStrat and ASpecs provided. Care and Welfare. Trainee welfare has a big impact on how successful trainees are in training. Trainers need to create an environment of mutual support and respect where trainees feel safe and know that their contributions are recognised and valued. Commanders have specific responsibilities relating to Care and Welfare; these are detailed in Volume 4 JSP 822. DELIVERING EFFECTIVE TRAINING The Defence Trainer course provides new trainers with an understanding of how trainees learn and a range of tools and techniques to employ. Trainers should also be aware of the unique nature of the training environment and the codes and boundaries which must be applied to ensure that training remains safe and effective for all. REALITIES OF TRAINING Trainers will be required to deal with a whole range of issues that might affect the length of time available to teach a lesson (e.g. if trainees finish a previous lesson later than planned). KLPs may need to be covered again if, for example, some trainees have missed a previous lesson/event. In all cases, trainers should understand the following when adapting training delivery to meet the realities of training: All KLPs should be delivered in accordance with the LSpec. Where it has been necessary to adapt or miss out KLPs, trainers must inform their Defence Training Supervisor (DTS), Defence Training Manager (DTM) or Chain of Command, preferably with suggestions as to how these can be made up at a later date. If the KLPs cannot be delivered, then a deficiency report should be raised. Assessments should be delivered in accordance with the ASpec. If the assessment cannot be delivered in the time available, then the DTS, DTM or Chain of Command should be informed, and the assessment rescheduled for a later date. EVIDENCE-BASED APPROACH Evidence-based teaching (EBT) has been firmly embedded into the Defence training environment. It has proved to be highly effective in improving direct learning outcomes (achieving TOs) and indirect outcomes (e.g. encouraging independent learning, developing social skills, promoting the desire to learn). Detailed guidance on a range of EBT methods is given to trainers during the Defence Trainer course and is available on the Defence Trainer DLE. COACHING The purpose of using coaching techniques is to unlock a trainee’s potential in order to improve and maximise performance. It is about helping trainees learn for themselves rather than delivering training to them. Coaching techniques form an integral part of the trainer’s toolbox. Everything should be geared towards ensuring that trainees are successful. Often that simply means responding positively and constructively to their efforts and setting new challenges for them. There will also be times when a more focused individual approach is needed (e.g. to develop a trainee who is struggling, or to motivate a trainee who is finding training too easy). Coaching techniques form the basis of the Defence trainer course, and of learner-centric training, in order to ensure the effectiveness and efficiency of training are maximised. There is no single definition of Mentoring in Defence as the word has different meanings depending on the context. For example, Informal Workplace Training includes mentoring schemes where a trusted colleague shares knowledge and experience over a period of time to assist a new colleague; there are mentoring schemes to assist foreign forces to manage their own security. Each has different aims. Where mentoring is mentioned in this JSP, it is referring primarily to the Role of the Defence Trainer Supervisor (DTS) who acts as a mentor for Trainers. In the DTS context the definition of Mentoring is: ‘where a trusted colleague shares knowledge and experience over a period of time to assist a new colleague’. Trainers should be introduced to the learning technologies available in their unit during the unit induction programme. Trainers should never discount the use of a learning technology because they do not know how to use it, but instead they should watch and learn from other Defence Trainers or ask for training from their DTS and/or chain of command. TRAINING INTERVENTIONS FOR DEFENCE TRAINERS The DTc is delivered by the Defence College of Training Support (DCTS). Table 6: Defence Trainer Course Overview Franchises19 of the DTc course are also delivered by additional Training Providers within Defence. Franchisee for the training year 2023/24 can be found in 2023DIN07-060 (Annex A). The DTc includes the Advanced Care of Trainees (CoT) course, however, whilst the DTc only needs to be completed once, the Advanced CoT is only valid for 3 years. JSP 822 directs that all personnel in direct/regular contact with Phase 1 and 2 trainees must complete the Advanced CoT course. If you are still in a trainer position after 3 years of completing the Advanced CoT course, or, you have returned to a trainer position after 3 years of completing the Advanced CoT course, you will have to complete the course again. Table 2 has an overview of the Advanced Care of Trainee course. Table 7: Advanced Care of Trainee (CoT) Course Overview As with the Advanced CoT course, the Basic CoT course is only valid for 3 years. All staff within the Training Establishment MUST complete Basic CoT through the e- learning package on DLE. The Basic CoT course must be completed prior to competing the Advanced CoT course. Table 2 has an overview of the Basic Care of Trainee course. Table 8: Basic Care of Trainee (CoT) Course Overview 19 Additional application restrictions may apply to franchised courses. 20 Safeguarding level 1 within a MOD training environment. LEGACY DEFENCE TRAINER TRAINING COURSES JSP 822 states that Defence must recognise those with previous experience and qualifications and provide the necessary up-skilling to refresh and professionalise trainers. Assessment of personnel identified for the delivery or supervision of Defence training is key. It is the responsibility of DTSs or nominated TMS to carry out such assessments and to ensure the completion of any necessary training interventions. Para 16 below contains 3 legacy Defence Train the Trainer courses that were replaced by the DTc. The DTTT V1 and DTTT V2 courses are no longer delivered, whilst DTTT Ph3 is still still delivered, by the Army, however, it is not endorsed by the 1* TSLD Policy and Assurance Group (PAG). Defence recognises that these courses, with the additional training / actions listed, are deemed to be equivalents, and therefore, an acceptable alternatives, to the DTc. Table 9: DTc mapping requirements - DTTT V1 legacy course Table 10: DTc mapping requirements - DTTT V2 legacy course. Table 11: DTc mapping requirements - DTTT Ph3 legacy course. EXTERNAL QUALIFICATIONS Defence Trainers holding a recognised external equivalent or higher qualification are to be assessed on arrival in post22 to ensure that they are competent. The DTS or nominated TMS will carry out the assessment. If the individual’s skill set is below the standard required for the type of training they will be delivering, they are to complete the necessary training interventions. Table 12 lists the additional training and actions required, by the holders of the qualifications listed. Table 12: DTc mapping requirements - External qualifications 21 Through Defence, L3 AET can only be obtained by completing the whole DTc from the beginning. 22 Or prior if there is an opportunity for a familiarisation visit prior to arriving in post."
  },
  {
    "id": "ffba91ae-bc3d-45cc-b983-14a1be9767d9",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer (Flying)",
    "content": "The Defence Train the Trainer (Flying) course (DTTT (Fg)) is mandated for all Aircrew Instructors (AI) delivering Ph 2 or 3 flying training conducted in a ground school, synthetic or airborne environment23. On successful completion of DTTT(Fg), personnel will be awarded the JPA competence ‘Defence Trainer (Flying) Level 1 Foundation’. On successful completion of platform specific AI training and the award of B2 category24, individuals are awarded the JPA competence ‘Defence Trainer (Flying) Level 2 Practitioner’. DTTT(Fg) does not qualify AI to deliver group learning unless to members of a multi-person crew in preparation for an airborne sortie or trg ex, but does allow delivery of group briefings which facilitate flying training delivery. AIs delivering flying training within 22 Gp, RAF are mandated to complete the Aircrew Instructor Course (AIC) which, in addition to DTTT(Fg), contains Human Performance, Airmanship and Care of the Trainee modules. On completion of AIC, the Enhanced Instructional Techniques course and award of CFS B1 Cat, AI will be awarded Defence Trainer (Flying) Level 3 ‘Advanced Practitioner.’ AI Professional Recognition. Central Flying School (CFS) has an arrangement with Staffordshire University to enable B1+ CFS Category AI to gain higher education qualifications which recognise their prior military flying training and experience. To gain the qualification AI will undertake additional requirements to become an A2 instructor, as well as simultaneously completing distance learning modules set by the university. On completion of the required modules, individuals will be awarded a Post-Graduate Certificate in Higher and Professional Education (PGCHPE). Those completing the PGCHPE will then have the option of completing further top-up modules to obtain an MA in Education."
  },
  {
    "id": "4f7fed97-06a2-4fa9-92ff-5c22b05bb0c4",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Contractors as Defence Trainers",
    "content": "Contractor staff delivering, supervising or managing DTC Training Interventions must be qualified, monitored and developed to the standards detailed in this Direction25. The majority of DTC training is not available outside MOD, therefore contractual arrangements must be put in place to ensure contractors are trained to the required standards. The minimum external qualification for contractor staff who are Defence Trainers is the Level 3 Award in E&T. In addition, COs must satisfy themselves that the contractor is qualified, at the appropriate level of competence, and has undertaken the required supervisory care training, i.e., Basic or Advanced CoT iaw Volume 4. Contractors who are Defence Trainers who are qualified by virtue of a higher civilian qualification must also be inducted and socialised appropriately into the military environment and must complete TPs 4, 5 and 6 associated with Stage 3 of the DTc. Guidance on contractors attending DTC Training Interventions, contractual agreements and processes can be found in . 23 DTc (or legacy equivalent) is considered an acceptable equivalent for DTTT (Fg) when supplemented by the BMD and Airmanship modules produced by the Central Flying School (CFS). 24 The full regulatory structure for CFS qualified AIs, including category definitions, can be found in the 25 Existing contracts are not required to be amended to reflect the changes to this DTC Direction. New contracts, or those undergoing significant contract amend, must reflect the current Direction. DTC training links directly to the Defence Objective that requires the generation of sufficient and capable personnel; accordingly, where a contract exists to train MOD military or civilian personnel, Defence resource can be used to allow contractors to attend DTC training, either at DCTS or within a franchise, without charge, if this has been agreed in the original terms of the contract. In this case, each SC is to articulate their contractor requirement for DCTS and franchises in their annual SOTR. Agreements relating to the accreditation requirements and, where appropriate, the additional cost of accreditation, also need to be reached. In cases where contracts do not include a contractor training requirement or an individual contractor needs ‘one off’ training at either DCTS or within a franchise, the training must be applied for through the SC TRAs and IDT (A) 26 so that spare capacity can be confirmed, and appropriate charging can be made. As the majority of DTC training is not available outside MOD, in accordance with JSP 462, full costs are to be applied. Where training is available outside MOD, then market rates are to be applied. The Lead TDA, DefAc, in its Income Generation role, is responsible for publishing the costs to be applied for all DTC training interventions and associated accreditation. SCs, when setting up contracts, and IDT (A), when charging for places offered through spare capacity, will require this information. Agreements relating to the accreditation requirements and, where appropriate, the additional cost of accreditation, also need to be reached. Where contractors wish to run their own franchises to deliver DTC training to MOD military or civilian personnel, DCTS will mandate the same Franchise Trainer training requirements as for all other franchises and costs for training will be recovered iaw the costings published by DefAc. Agreements relating to the accreditation requirements and, where appropriate, the additional cost of accreditation, also need to be reached. DCTS, as the only source of licensed DTC training, will assure the contractor franchise iaw this JSP."
  },
  {
    "id": "e6f72a53-82c5-40a4-ba36-71c72ce6557e",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer Supervisor",
    "content": "Defence Trainer Supervisor (DTS). The DTS is responsible for the assessment and development of Defence Trainers (Phase 1, 2 or 3). A key role is the supervision of the completion of the Workplace Portfolio for Defence Trainers. DTS may also be responsible for the assessment and development of those delivering training which relates to any WTS. As a DTS you will be responsible for the supervision and development of Defence Trainers, and potentially new DTS, allocated to you. This will typically include the following: manage/deliver the induction and workplace training for newly trained Defence Trainers. mentor and coach Defence Trainers and/or new DTS. maintain\ttraining\tdelivery\tstandards\tthrough\troutine\tobservation\tand monitoring of Defence Trainers. 26 IDT (A) undertakes the role of the booking and charging of DTC training for all SCs. POC:   . support CPD opportunities for yourself and others. carry out legacy assessment. manage/deliver the induction and workplace training for newly trained DTS. The DTS is central to the success of the development of Defence Trainers. New trainers need to feel confident, particularly in the first few months of their new job that they can try out their newly learned skills, make mistakes and learn from them. Defence Trainers, whilst they will have successfully completed pre-employment training, they will still need your guidance and support so that they can achieve the Defence Trainer (Practitioner) competence through completion of the Workplace Training Statement (WTS)- Stage 3 of the Defence Trainer course. Once this is achieved, they will need regular feedback and support to identify and set goals for further professional development. You will be awarded DTS Level 1 (Foundation) on successful completion of the residential training. You will need to complete complete the DTS Workplace Portfolio so that you can achieve the DTS Level 2 (Practitioner). Defence Trainers are mandated to complete Stage 3 of the Defence Trainer course to become a Practitioner, which you will be responsible for overseeing. You may also be required to act as a mentor and supervisor to other newly trained DTS. The same principles apply to the supervision of DTS as to Defence Trainer; learning from mistakes is often the best way to learn, but individuals will still need the support and guidance of a qualified and experienced DTS to help them reflect on their actions and identify areas for improvement. PROFESSIONAL DEVELOPMENT DTS competencies are graded according to 3 different levels of professional development: Foundation, Practitioner and Advanced Practitioner. On successful completion of the DTS course, you are awarded the JPA competence DTS Level 1 (Foundation). Completing the WTS and the Defence Trainer Supervisor Portfolio (DTSP) gains you a further JPA competence award of DTS Level 2 (Practitioner). DTS Level 2 Practitioner is only mandated for those supervising Defence Trainers (Phase 1 or 2). You then have the opportunity to progress to JPA competence DTS Level 3 (Advanced Practitioner). Progressing to DTS Level 3 (Advanced Practitioner) is not mandated by the DTC Direction. In order to achieve Defence Trainer Supervisor Level 3 (Advanced Practitioner), you will need to identify ways in which you can provide the appropriate evidence of your advanced knowledge and skills27. WORKING PRACTICES 27 Each training unit should identify what an Advanced Practitioner looks like for their own development and business needs. It is recognised that there is still work to be done to develop guidance for SCs to understand what CPD could be undertaken to prove that an individual has reached the level of DTS AP. The DTC Direction mandates an assessment of Defence Trainers’ competence. For a new Defence Trainer at Level 1 (Foundation), this is to be carried out by the DTS through observations of TPs 4, 5 and 6. You are to conduct observations iaw the DTC Direction. The first formal observation should be conducted at an early stage and signed off by the DTS. You may also be required to arrange an assessment of level of competence for: individuals who are returning to a training delivery role having previously qualified, e.g. legacy trained military personnel or civilian staff with equivalent or higher teaching qualifications. individuals who have been absent from the training environment for a period of 6 months or more, e.g. on detachment or operational tour. If you deem that the individual’s skill set is below the required standard set by the Defence Trainer course then you should advise the DTM that the individual should complete the Defence Trainer course. If they are assessed as competent/acceptable, they may only need to complete refresher training and then engage in ongoing CPD. SUPERVISING THE COMPLETION OF STAGE 3 OF THE DEFENCE TRAINER COURSE Following, completion of Stage 1 and 2 of the Defence Trainer course, defence Trainers are awarded the JPA Defence Trainer Level 1 (Foundation) competence for their role. In order to reach Defence Trainer Level 2 (Practitioner), they must successfully complete Stage 3 of the Defence Trainer course (workplace learning) iaw the DTC Direction. This is an important part of the training and development process because it makes sure that individuals can relate what was learned in the classroom to the realities of the training environment. It therefore builds on the pre-employment training, allowing individuals to master newly learned skills and to gain experience with real trainees, whilst still enjoying the support and guidance of an experienced DTS. Successful completion of Stage 3 means that the individual has reached a sufficient level of competence to work without supervision. Stage 3 is divided into two specific areas: L3 AET Portfolio. Unit DTSs are responsible for monitoring progress and ensuring new Defence Trainers are provided with the necessary time and support to complete the L3 AET portfolio in unit. TPs 4, 5 and 6. DTS or a nominated TMS are responsible for developing Defence trainers in the workplace. In transitioning from foundation to practitioner competence levels DTS are conduct 3 formal lesson observations (TPs 4, 5 and 6), which is to be part of a structured induction programme. Detailed guidance on the supervising the completion of Stage 3 of the Defence Trainer Course is in this Annex O. SUPERVISING DEFENCE TRAINERS Defence Trainers in all Phases of training are to be routinely monitored to ensure that they are complying with Defence and single Service policy. You should conduct a formal observation every six months for each Defence Trainer allocated to you, providing coaching and developmental feedback in order to complement the appraisal process and support trainer development. You should ensure that Defence Trainers are: complying with the relevant course documentation, i.e. adhering to the requirements in the Learning Specification (LSpec), Assessment Specification (ASpec) and the Assessment Strategy (AStrat). using an appropriate range of active teaching methods and media to ensure a learner-centred, inclusive training environment. conducting assessments in a valid, fair and reliable manner. These formal observations are to be recorded as they may be used to support first, second- and third-party audit activities, including Ofsted inspections. Trainers should also be encouraged to learn from each other, through informal peer to peer observation and feedback. Defence Trainers should expect their peers to routinely visit their lessons to learn from their observations and to provide constructive feedback. This will promote the sharing of good practice and will also foster the development of supervisory skills for the future. Monitoring and observation should be seen by Defence Trainers as a positive, developmental activity rather than a judgemental assessment. You should therefore apply the following guidelines: Occasion of visit. Make sure that the individual knows in advance when and how the observations will take place. If an unannounced visit is made no formal assessment would normally take place other than verbal feedback (unless unprofessional conduct has been witnessed). Feedback. Facilitation of a reflective feedback session is encouraged, including when the reason for the observation may be for the observer’s own education and professional development, e.g. in the case of peer-to-peer observation. Trainee management. Observers should respect that the Trainer is in charge and will therefore abide by their management of the trainees and will not interfere in the process of teaching. The observer may need to leave the lesson part way through, and this will be done discreetly. DEFENCE TRAINER SUPERVISOR COURSES Table 13: DTS course overview Franchises28 of the DTS course are also delivered by additional Training Providers within Defence. Frranchisee for the training year 2023/24 can be found in 2023DIN07-060."
  },
  {
    "id": "1a769004-5538-4d18-935b-703bee0dd336",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer Manager (DTM)",
    "content": "As a DTM, you will need to be familiar with all aspects of DTC Direction, the DTCF and any single Service policies that apply within your unit. As the focus for DTC, you will typically be responsible to the chain of command for the implementation of DTC Direction, the functional management of the DTS and coordination of trainer specific CPD29. You will also be the establishment lead for the continuing improvement of the unit’s system for managing  and DTS. An understanding of DSAT is essential. Your role is critical in creating and maintaining a culture of continuous improvement in the unit. Training delivery duties should be seen as a privilege and career enhancing, and so the status of the trainer should be overtly valued and emphasised. There should be an expectation that trainers will perform to the highest standards and there should be incentive for high performance. CPD opportunities should be provided at all levels, and these should promote the adoption of good practice from across the Defence and FE sectors, and the exploitation of modern techniques and learning technologies. MANAGEMENT OF TRAINING DELIVERY STAFF Commanding officers of training establishments are responsible for ensuring that all personnel, military and civilian, are trained, qualified and managed in accordance with Defence and single Service policies. As the DTM, you may have partial, or full, responsibility for providing a holistic approach to the management of training delivery staff. STAFF SELECTION 28 Additional application restrictions may apply to franchised courses. 29 This is a coordinating rather than a supervisory role - the DTM is not expected to duplicate the role of the DTS. Attracting high calibre training staff. Training provision needs to be seen as an attractive and career enhancing opportunity to encourage high-calibre volunteers to apply. While potential trainers will normally be identified by their chain of command through appraisal30 and reporting processes, it is in the interests of the training establishment if trainers are volunteers rather than ‘pressed’. You should therefore aim to highlight and promote the benefits and incentives linked to specialist training provision both within the unit and externally wherever possible. As an example, some training provision posts offer significant elective accreditation possibilities, with the opportunity to achieve national teaching qualifications and professional recognition in the FE sector; this could be widely promoted on orders but also on career courses, with signposts in place to direct interested parties to further information. Identifying potential DTS. The DTS role is not necessarily a full-time employment role and may be carried out in addition to other training duties. You may therefore need to identify potential DTS from within your existing staff in order to maintain a suitable complement of supervisory staff. Potential DTS should be qualified Defence Trainers who have ideally achieved the Advanced Practitioner level. Selecting Defence Trainers. Some training establishments may require the DTM to organise or provide support to centralised selection cadres to explicitly test individuals’ aptitude as a potential trainer within that specific training context. Equally, you may be required to assist in the selection process for civilian or contracted training staff. Strong leadership and role modelling are critical attributes for a Defence Trainer in any phase of training; the selection process should also take into account the likely needs and expectations of the trainees in that environment. Additional considerations should include: Operational experience. Individuals returning from an operational tour may be identified for full time training provision duties in order to ensure currency and credibility in training; however, they should not assume these duties until they have had a suitable period of time to re-adjust to the non-operational environment. Civilian Defence Trainers. Selection of civilian Defence Trainers will take place through the normal employment interview process, in which they should be assessed for their suitability to deliver training within specific environments, with particular emphasis on training delivery competence. The minimum qualifications and training for a civilian Defence Trainer are the same as for Service personnel. Contracted staff. Contracted or agency staff employed in training provision are required by the DTC Direction to meet the same level of competence and to hold the same requisite qualifications, or their civilian equivalent, as Defence personnel. The chain of command must satisfy itself that the contractor is qualified, at the appropriate level of competence, and has undertaken any required training. STAFF DEVELOPMENT Staff development is based on principles which recognise the crucial links between centralised training, workplace learning and continuing professional development (CPD). Following assignment, Defence Trainers should develop professional competence through 30 See section on Selecting Personnel for Trainer Duties in JSP 757. a pipeline of appropriate pre-employment training, induction, workplace learning and CPD. DTM are responsible to the chain of command for ensuring that there are clear and comprehensive systems in place to manage training delivery staff development, which will typically include the following: Ensuring that pre-employment training is completed in accordance with the DTC Direction. Delivery of an induction programme to all training staff immediately upon employment. Completion of the Workplace Training Statement (WTS) iaw the DTC Direction. Regular monitoring and support for Defence Trainers by qualified DTS throughout their employment. Planning and provision of regular CPD for all training staff. Maintenance of staff development records for the purpose of performance management, appraisal, audit and inspection. Pre-employment training. All individuals are required to achieve the appropriate pre-employment standards prior to joining training organisations. Details of the minimum pre-employment training requirement for each role are provided in the DTC Direction. Where training delivery staff already in post do not meet the requirements of Defence Direction, action plans must be agreed to bring these staff to the necessary level. Other training delivery skills or related competences may also be required, in which case the Chain of Command or Heads of Profession may set professional requirements in excess of this minimum. Induction. Induction training forms a vital link in the process of orientation to a new environment and is the responsibility of the employing unit. Induction for Defence Trainers is particularly important as it may be the individual’s first experience of a training establishment. Induction should therefore provide the opportunity for individuals to gain insight into the organisational climate and training culture and to align their expectations with that of the organisation. Induction should, where possible, be tailored to the individual and should typically cover the following areas: Pre-arrival. Engaging with new staff prior to joining can aid the process of induction in terms of managing expectations and setting the tone of the relationship between the individual and organisation. New Defence Trainers complete a pre- residential online training package which provides an introduction to the Defence training community, but unit contact pre-arrival will also assist in setting the specific context, determining their previous experience and establishing any training needs in advance. A DTS should be allocated and an induction pack with welcoming letter should be dispatched. On arrival. An arrival interview and briefing should be conducted to include the organisation’s vision and purpose, support networks, the demands of the role, the individual’s terms of reference (TOR) and quality management procedures.  For newly qualified Defence Trainers and DTSs, some elements of the WTS which are designated as Unit Induction (UI) may be covered by the standard unit induction package e.g. introduction to welfare support networks, unit discipline policies. Where this is the case, there is no need to repeat the training, but you should ensure that all elements designated as UI in the Defence Trainer and DTS WTS are either covered by the standard unit induction package or are provided as an additional module of induction. Assessment of competence. As part of the training establishment induction process, an initial assessment of level of continuing competence is to be undertaken (within 3 months of completion of pre-employment training including any supervisory care training). This is to be conducted by an appropriately qualified DTS or equivalent. For newly qualified Defence Trainers and DTSs, this is included within the requirements of the WTS. For, previously qualified staff arriving in post, or those returning from an extended period of absence, detachment or operational tour, separate arrangements must be made to observe and assess their competence in the workplace at the earliest opportunity. Workplace Training Statement (WTS). For those who complete a WTS, responsibility for its completion lies with the employing unit and the individual. It is critical in ensuring the initial transfer of learning from the pre-employment training course into the workplace context. Pre-employment training provides trainers with an introduction to the learning theories and techniques so that they can start to use their trainer skills under supervision, but these skills must then be monitored and developed in the context of the relevant training establishment if the individual is to develop as an effective trainer. New trainers must feel confident, particularly in the first few months of their new employment, that they have the support of their superiors, so that they can try newly learned skills and learn from their mistakes, using a blend of pre-determined tasks and/or problem solving as well as learning from on-the-job experience and coach/mentor feedback. Completion of the WTS ensures that individuals move from the Foundation level to the Practitioner level. The WTS is achieved through the completion of Stage 3 of the Defence Trainer Course, i.e. the L3 AET and TPs 4, 5, and 6. The observations for TPs 4, 5 and 6 must be conducted and recorded by a qualified DTS, who will provide developmental feedback and assist the individual in achieving the JPA Defence Trainer Level 2 (Practitioner) competence. Observations conducted as part of Stage 3 of the Defence Trainer course should be conducted at least 1 month apart. Conducting observations too close reduces the reflective learning opportunities that the WT portfolios were designed to create. Supervisor guidance for aiding the completion of the DTP is contained in this Annex O. Newly trained DTSs are also required to complete a WTS using the Defence Trainer Supervisor Portfolio (DTSP) which gains them the JPA DTS Level 2 (Practitioner) competence. MONITORING AND SUPPORT Defence Direction requires that appropriately qualified personnel monitor the continuing competence of their training delivery staff and that an individual record of monitoring is maintained. You must therefore ensure that performance of your Defence Trainers is monitored at regular intervals by DTS or equivalent qualified staff. This should be conducted at least twice a year in line with the relevant MPD and/or unit performance appraisal and reporting procedures. Functional management of DTS is important in order to ensure that routine supervision, monitoring and support takes place in accordance with the DTC Direction requirements. The ratio of Defence Trainers to each DTS will be set locally31 and will be based on unit structures and the capacity of DTS to carry out supervisory duties in addition to other primary duties. You will need to be aware of staff workloads and ensure that sufficient time is allocated for DTS to carry out their supervisory duties, which should be clearly articulated as part of the individual’s job description and annual objectives. CPD The coordination of CPD activity is a critical element of your role as DTM. Defence Direction mandates annual CPD as part of the DTC. Where practicable, you should provide CPD opportunities for legacy trained staff to complete the elements of the Defence Trainer or DTS development pathways. This provides both with the pre-requisite to achieving Level 3 (Advanced Practitioner), which should ultimately be the goal of all training delivery and supervisory staff. CAREER MANAGEMENT In order to maintain the valued status of the training delivery role there must be suitable reward for Defence Trainers and DTS who demonstrate strong performance. Training delivery assignments should be career enhancing and, while you may not be involved in the appraisal and overall career management of all delivery staff, you should be in a position as DTM to provide opportunities for further professional development. Incentive and reward will clearly only be effective if it is relevant to the individual’s personal goals, but where individuals are performing to a high standard in training delivery, the provision of funding and/or study time for a higher level qualification may be a suitable option, which will benefit both the individual and the organisation. Those most suited to the training delivery role should be encouraged to return, at a suitable career point, to supervisory and management levels, which in turn provides maximum return on investment in training and professional development. MAINTAINING RECORDS Defence policy requires training establishments to have a formal process where auditable records of assessments for training delivery staff are maintained. This will include the recording of unit induction, WTS completion and annual monitoring. Records are required to: provide the individual and line management with a means of monitoring progress from Foundation to Practitioner and Advanced Practitioner. support the appraisal process and identify areas for further development. provide supporting evidence of professional development activity during audit and inspection. 31 For example, in Unit Standing Orders or Training Quality Manual. Defence Trainers and DTSs are to complete a portfolio as part of their workplace training but this should not be retained as a unit record, as it is designed to be a resource for the individual. A separate copy of the final page of the portfolio should be kept, which lists the date of WTS completion and the signature of the supervising DTS."
  },
  {
    "id": "b2fa8123-412c-4df7-b21c-39a3f8c09338",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Commanding Officers / Heads of Training Establishments",
    "content": "Commanding Officers (COs)32 / Heads of Training Establishments33. COs and Heads of Training Establishments will be held to account for ensuring that: the Training Quality Manual (TQM) reflects the structure of the organisation and the monitoring and development procedures for Defence Trainers. people under their command who are engaged in training delivery or have contact with trainees are appropriately trained and qualified in accordance with this Direction and also have any additional necessary competences. there are sufficient Defence Trainers, DTSs and DTMs and the command structure within which they operate is configured to ensure that the requirements of this policy direction are achieved. their FLC TRA is informed via the TDA of any risks and/or issues relating to the DTC so that these can be raised at the appropriate governance meeting."
  },
  {
    "id": "c5069af3-7599-4417-8ec9-3a35d7bae341",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Delivery Authority",
    "content": "The Training Delivery Authority (TDA) is the organisation responsible for training delivery, but not always for the conduct of the actual training itself. If a SC so wishes, the TDA role can be a nominated post. Examples of the types of Roles associated with the TDA are: Designer, 2nd party auditor or inspector, and Training Line of Development (TLoD) Owner in the case of projects, programmes or capabilities. The responsibilities34 of a TDA are: The delivery of effective, efficient and safe training, but not always for the conduct of the actual training itself. Generating and completing the SOTT by taking the agreed output-based requirement articulated in the SOTR and developing it into a deliverable training plan for the following TY. 32 ‘Commanders’ covers those commanding / in-charge of any Unit or organisation where formal Phase 1, 2 or 3 training takes place. (including Operational Units, Training or Education Establishments, Defence Colleges, Training Schools and Training Units). 33 See JSP 822, Volume 4 – Care and Welfare in Training. 34 TDA responsibilities can be delegated if agreed at the CEB, and recorded on the TrAD. Deriving (from the RPS) and maintaining the FTS (where agreed with the TRA). Chairing the CEB. TDA ROLE IN JOINT/DEFENCE TRAINING REQUIREMENTS In many cases, if there is a Lead TRA, it may also be appropriate to nominate a Lead TDA to ensure coherency and that the totality of the Joint and/or Defence training requirements are met."
  },
  {
    "id": "b500cb60-ebe4-4bd7-9d20-fe98a9db495e",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "What is CPD? CPD stands for Continuing Professional Development. It is any activity that updates your knowledge or develops your skills in your job role. Why do CPD? CPD updates your knowledge and skills, keeping you current and preparing you for the future. It benefits you, the individuals you are training and the operational effectiveness of your organisation. Evidence of your CPD can also count towards gaining JPA Level 3 (Advanced Practitioner) and recognised civilian qualifications. How much CPD should I be doing? Defence Direction mandates that those working in a Defence training delivery role should complete a minimum of 5 hours’ CPD per year. The focus of CPD is firmly on you as an individual, so one size doesn’t fit all. You will need to decide what type and how much CPD is best for you at a particular stage in your career, but you can get help from your supervisor or line manager, or by sharing and comparing ideas with colleagues. What counts as CPD? The answer is a lot of what you are doing already without perhaps realising it. The Plan, Develop, Support, Share (PDSS) model at Figure 2 summarises the main areas that constitute CPD for an individual working in a training delivery role. Figure 3: CPD PDSS Model Table 13 has some examples of CPD activities: Table 14: Examples of CPD activities"
  },
  {
    "id": "021d71e8-646a-46d2-b67b-76ac6c606641",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Choosing CPD Activities",
    "content": "Some CPD activities, such as workshops, seminars and team meetings, will be directed and organised by your unit. Other activities will be your individual choice and these should focus on personal abilities, goals and opportunities. It is important to plan these individual activities to make sure that you get the most from the time spent on CPD, by focusing on areas that will benefit you in your job role and your career. Your CPD plan should map out what you personally need to achieve in order to reach your development goals. The plan is specific to you and so there is no set format, but a Defence planning template is available from DCTS if you wish to use it. To create the plan, you need to do the following: Step 1: Identify your goals. One of the problems that people face when trying to improve their performance is defining what they want to achieve and how they need to develop. It will help to discuss your goals with someone else, e.g. a DTS, your line manager, or you may wish to seek advice from a professional body that you are a member of. You may also find that it helps to create a performance profile when setting goals. DCTS has a proforma to help with this. Step 2: Identify your learning and development needs. Having identified your goals, the next step is to break them down into the skills and knowledge you need to develop in order to achieve them. Ask yourself the following questions in relation to each of your goals: What skills do I need to be able to do, or what do I need to be able to do better? What new knowledge do I need? Step 3: Identify specific CPD activities. Once you have identified your goals and defined your needs, your next step is to decide what activities will meet those needs. When defining your activities, try to make them clear and explicit. If others are involved, identify who they are and state when things are going to happen. It is important that you identify a timescale for each activity to help yourself prioritise events and be realistic about what you can achieve. If you are considering a course of study, check how much time and resources are available to you – remember, if you have a clearly defined and logical CPD plan, you are more likely to be successful in gaining support from your Chain of Command."
  },
  {
    "id": "32caf1ad-4564-49f6-8fe6-aeafac5a551f",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Keeping a Record of CPD Activities",
    "content": "It is very important for you to record your CPD in order to: Show that you have completed the mandatory 5 hours per year – your unit will be expected to provide this evidence to audit/inspection teams, including Ofsted. Provide evidence for gaining other civilian qualifications. Demonstrate your commitment to professional development to any professional bodies that you are a member of. Your CPD record should be a summary of all the major CPD activity you engage in, together with your reflection on the outcomes, i.e. what you have learned and how you are applying this. You should fill the record in regularly as you undertake key CPD activities, or soon after. There is no set format for recording your CPD, but as a minimum, your record should include: dates of development activities. number of hours spent on development activities. description of development activities. what you have learned. how you are applying or will apply what you have learned."
  },
  {
    "id": "a3cac9fd-c5b9-407d-8ca6-39304dac1547",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "The Armed Forces have a unique training ethos. It is a combination of firm discipline, high quality rigorous training, maintenance of high standards, a sense of fair play, treating the trainee as an individual and encouraging people to achieve tasks and skills far beyond those that they first thought themselves capable of. Training is successful if it results in a high level of skill, self-discipline, initiative and obedience to orders in the moment of crisis. Successful training also delivers independent learners, who are motivated to continue to learn through life and thus are able to deal with the complex, the uncertain and the unexpected. Defence training is characterised by a strong sense of purpose, relevance to the operational environment and the will to develop the core Values and Standards of the Armed Forces in the individual. Skill, strength and forbearance are admired and encouraged; there is no place for cruelty, callousness or meanness. A strong sense of appropriate humour pervades the way in which this training is delivered. This defines the challenge to those who deliver Defence training, each of whom will be held as a role model to the trainee in all that they do. The Defence Code of Practice for Trainers applies to all Service and civilian trainers employed by the Ministry of Defence. Underpinned by the core Values and Standards of the Armed Forces, it serves to unify and complement the various training courses provided for the different trainer roles, by setting out common standards of practice which are central to the delivery of Defence training. All trainers are expected to adhere to the Code’s ethos and meet the standards set out within it."
  },
  {
    "id": "e2caf38e-06db-4bed-abbd-0f19d40ade90",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Standards for the Delivery of Training",
    "content": "Standards in Training. All trainees should be given the same opportunity to learn and achieve. The trainer promotes an inclusive learning culture by helping trainees to avoid or deal with different barriers to learning. This can present a challenge, particularly in Phase 1 and 2 training, to get the right balance between encouraging and supporting a trainee whose true potential may only be faintly visible, and warning, perhaps even helping to discharge, those who are never going to achieve the required standard. Each case must be treated on its own merits and you should make every effort to motivate and support your trainees, but this should not be at the expense of the standards required to maintain operational effectiveness. In all cases, you should focus first on 'training in' rather than 'selecting out'. Respect in Training. It is important that a relationship exists between the trainer and trainee based on mutual respect. Respect from a trainee cannot be demanded or expected; you must never abuse your position of authority. Good trainers will continually seek to develop the trainee's self-belief with constructive criticism and encouragement, and will naturally be afforded respect as a result. Physically striking or humiliating a trainee or the use of threatening, rude or abusive language is counterproductive and is not tolerated within the Armed Services. Sensible and Achievable Training. Training must be progressive, safe and sensibly achievable. Safe training does not mean being over-cautious, unadventurous or dull but you must not push trainees faster than they can learn and they must be allowed time to learn from their mistakes. Consider your audience carefully when planning training, and make sure that your expectations take into account the background, military knowledge and experience of your trainees. Challenging Training. Phase 1 training by its very nature presents a considerable challenge to a young person but care should be taken to ensure that subsequent and further training also challenges every trainee mentally, physically and intellectually. If not, they may feel patronised and quickly become demotivated. This applies particularly to Phase 3 training, where trainees will have greater breadth of maturity and military experience. You should always acknowledge trainees’ previous experience and aim to provide sufficient challenge for all levels of background and ability. Safety in Training. If training is to be effective, it must include exposure to the conditions (real or simulated) that will be present in operations. This will often incorporate some level of risk. Whilst risk management is the duty of the chain of command, responsibility will also rest with the trainer in direct control of the activity. You must therefore manage risk in order to deliver training as safely as possible. Where you believe, in a particular situation, that the training benefits are outweighed by real risks to life and limb, you have a duty to step in and modify the training. Training safety will be enhanced by application of the following principles: Risk Assessment. Prior to conducting training, a risk assessment must be completed by a competent (qualified, experienced and current) individual. Nevertheless, you must always conduct your own assessment prior to the start of training and, if applicable, record any deviations from the lesson plan. You should continue to review that assessment during training in order to adapt to changing conditions (equipment, weather, tiredness, etc). If appropriate, trainees should be briefed on any changes in the plan resulting from a revised risk assessment. Safety Instructions. Before any training commences an appropriate set of safety orders/instructions are to be published and a safety briefing must always be given based on those orders/instructions. Repetitive training may be covered by standing orders, provided that these are briefed at regular intervals. Orders and instructions should include any actions to be taken in the event of an emergency. Trainer/Trainee Ratios. For many training activities, including adventurous training, weapons training and physical training, there will be a recommended ratio of trainers to trainees. You must be aware of the guidelines and plan the training accordingly. Competition in Training. Competition between individuals or teams involving mental or physical endeavour can be an excellent tool for improving performance, developing robustness and the desire to win. You should strive to encourage healthy competition in your training but, balance and care are always required to ensure that trainees are encouraged and motivated but not demoralised. Humour in Training. Humour is a powerful tool in the provision of effective training. You should, where possible, aim to make training fun so that a trainee will find it memorable and will be looking forward to the next session; however, care must be taken to avoid misdirected humour. Knowing where to draw the line can be difficult, particularly with trainees who you do not know you as well as you know your colleagues. Anything that belittles trainees is definitely NOT appropriate and is almost certain to create a barrier to learning which will then have to be dealt with later. If in doubt about a remark, don’t use it. Accountability in training. A trainer is accountable for both the training and well- being of all trainees. This demands total commitment and a sense of responsibility. The successful trainer will be prepared to spend extra time coaching or providing informal tuition to assist trainees in overcoming barriers to learning. You should also be prepared to provide a sympathetic ear when trainees need to discuss issues outside of training, particularly (but not exclusively) in training environments where they are living away from home. You need to be able to signpost and refer trainees to specialist support as required. Relaxation for Trainees. All trainees need breaks if they are to get the most from training and time must be programmed in when they can rest, relax and recover. Strenuous training (both physical and mental) over a long period of time may lead to fatigue and therefore proper time for meals, rest and free time must be given to trainees."
  },
  {
    "id": "9d409699-b419-41d1-907d-3fdc41c0985c",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Standards for Professional Conduct in Training",
    "content": "Leadership. Trainers are expected to set the highest standards of motivational and inspirational leadership at all times, and to demonstrate, by example, the same leadership expected on operations. A good trainer uses motivational feedback to develop trust and inspire confidence and self-belief in trainees. You should communicate enthusiasm, encourage perseverance and always be optimistic of trainee success. You must also have the moral courage to demonstrate sound principles, high personal standards, values and a strong code of ethics at all times; but particularly when making decisions under stress. Good leadership is vital in this respect and you should participate fully in the rigors and hardship of training and inspire your trainees through commitment and example. Equality in Training. All trainees must be accorded fair and equal treatment, whatever their rank, gender, sexual orientation, religion, social background, race or ethnic origin. No harassment, intimidation, abuse, humiliation or unlawful discrimination of any kind will be tolerated anywhere within the Armed Forces. You must lead by example: you should make it absolutely clear that you disapprove of any form of discrimination and you should foster an environment where a complaint can be made without fear of retribution. Discipline in training You must clearly understand your disciplinary powers as published in the orders and regulations of your organisation. Unofficial disciplinary procedures can be interpreted as bullying or as an abuse of authority and, for these reasons, all disciplinary action must be clearly recorded and open for inspection. Nevertheless, you should not defer giving reasonable but firm orders or taking appropriate action for fear that they will be challenged by a trainee on the grounds of, for example, harassment. Moral courage must be exercised at all times and any inappropriate behaviour or poor attitude/effort towards training must be challenged. Personal relationships in training. The relationship between a trainer and a trainee is inevitably often a close one. Some trainees, particularly young recruits, can develop a sense of awe and hero worship that goes beyond professional respect and admiration. You must recognise this and not allow a situation to develop that might lead to an unhealthy abuse of your authority or give a trainee the opportunity to take advantage. Maintain a professional distance at all times and take care to ensure that you do not become over involved with any trainee. Failure to do so can lead to unacceptable personal relationships, accusations of favouritism or even allegations of misconduct. Prohibited practices. Trainers working with trainees must not: pursue any personal or financial gain in dealing with trainees. accept gifts of any form, or value, from trainees for themselves or for others, to include charitable organisations, except when specifically authorised by the Commanding Officer. borrow money from or loan money to trainees. provide transport for hire to trainees. as part of their position of authority, sell any items, whether personal property or commercially obtained, to trainees; this does not apply to sales personnel of the PRI or NAAFI and its authorised concessionaires. deal with trainees on behalf of, or as an agent or sponsor for, any commercial enterprise. This includes encouraging trainees to do business with any commercial enterprise and/or referral to any commercial enterprises, as well as actual sales. This does not apply to the PRI or sales personnel of the NAAFI or its authorised concessionaires nor shall it be a violation to advise trainees of the service available through the NAAFI. collect or take money from trainees for any reason, including cleaning funds, party funds, charitable contributions, etc (other than those authorised by the Commanding Officer). cause trainees to perform any personal service. enter into any public or private relationship with trainees, which are not required to accomplish the training mission. This includes, but is not limited to, gambling. consume alcoholic beverages or in any way socially mix with trainees on or off camp other than at approved unit activities. Off-camp these activities should be avoided where possible. engage in any action or relationship which involves or gives the appearance of partiality, preferential treatment or improper use of rank or position for personal gain. engage in any intimate or sexual relationship to include, but not limited to, dating, handholding, kissing, embracing or caressing."
  },
  {
    "id": "b7075b5b-ed03-47a3-9f70-bd8fc9ea7eb7",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "F - Defence Trainer Manager - Terms of Reference",
    "content": "ANNEX A TO DTSM 4"
  },
  {
    "id": "3fc9e2c6-ea96-4f07-b5b2-6309afa89819",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Role purpose",
    "content": "The role of the Defence Trainer (Phase 1, 2 or 3) is to deliver or facilitate the delivery of formal training objectives in formal training environments."
  },
  {
    "id": "47cca76e-28c6-49f2-98bf-f9d07ef604e4",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Outputs/tasks",
    "content": "The main outputs and tasks for a typical Defence Trainer are listed below. Dependent on the training environment in which the Defence Trainer is employed, the emphasis may shift from one tasking area to another or there may be additional specialist requirements within a particular tasking area. Managing the attitudes and behaviour of trainees, including: Promoting core Values and Standards and military ethos. Maintaining and restoring discipline. Supporting trainee welfare. Planning, preparing and delivering group learning in accordance with the relevant Learning Specifications. Planning and supporting individual learning using: Coaching and mentoring techniques. Learning support strategies. Conducting\ttraining\tadministration\tin\taccordance\twith\tlocal\tunit requirements. Supporting continuous improvement of training through: Assisting in the internal validation of training courses35. Engaging in Continuing Professional Development (CPD) activities for both trade and trainer roles"
  },
  {
    "id": "ede766c1-7a72-40bd-ba02-060745d9b53d",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Training and competence.",
    "content": "The JPA Defence Trainer Level 1 (Foundation) competence is achieved by successfully completing Stage 1 and 2 of the Defence Trainer course. The JPA Defence Trainer Level 2 (Practitioner) competence is achieved by completing Stage 3 of the Defence Trainer course (in the workplace). Stage 3 comprises the L3 AET and TPS 4, 5 and 6."
  },
  {
    "id": "1042bad7-a45a-44bf-9235-7acfe91afafa",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Competencies36",
    "content": "The following competencies, at Level 2 (Practitioner)37, are to be achieved after successful completion of all 3 stages of the Defence Trainer course: pre-residential learning on the DLE (Stage 1), the one-week residential course (Stage 2) and workplace learning (Stage 3). Group 1: Understanding the role of the trainer. Group 2: Planning and preparing learning and development (L&D) for the training environment. Group 3: Planning and preparing learning and development (L&D) for the work environment. Group 4: Facilitating learning and development (L&D) in the training environment. Group 5: Facilitating individual learning and development (L&D) in the work environment. Group 7: Maintaining and improving quality standards. 35 During the InVal process trainers or trainees may highlight issues with the training content, e.g. pertaining to currency or relevance. In this case it is essential that any are highlighted shortcomings to the Chain of Command, so that the DSAT process can be used to make the necessary changes. Alterations to any part of the training documentation can only be achieved by following the appropriate formal change processes which must be authorised by the Training Requirements Authority (TRA) and carried out by the Training Delivery Authority (TDA). Trainers must be absolutely clear on their boundaries when adjusting training content. 36 In accordance with Defence Trainer Competency Framework 37 Displays knowledge and understanding to support competencies, providing evidence and guidance to others. Demonstrates practical application in a range of work situations. Level expected after experience and completion of work-based learning. Group 9: Employing functional skills."
  },
  {
    "id": "31ec8312-5318-44f2-b55d-3496e3da53a0",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Legacy Assessment of Defence Trainers (Flowchart)",
    "content": "This flowchart is currently being reviewed and will appear in a future edition / version. ANNEX B TO DTSM 4"
  },
  {
    "id": "ef04c9cf-d95d-4ceb-b004-1fe705fbb55a",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 EDITION, V1.0",
    "content": "ANNEX C TO DTSM 4"
  },
  {
    "id": "2d7363f9-4f60-411e-b7da-5728747c244b",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Legacy Assessment of Defence Trainers (Table)",
    "content": "38 Eligibility for Defence Trainer (Practitioner): Candidate to already hold Defence Training (Foundation) level competence. ANNEX D TO DTSM 4"
  },
  {
    "id": "d0be6f61-c68f-435f-93a6-fb71ec36aed4",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer Supervisor - Terms of Reference",
    "content": "Role purpose. The DTS is a key enabler to the Defence Trainer Capability (DTC) model and central to the success of the development of the Defence Trainer, providing the supervision and guidance needed to monitor performance and support mandatory work- based learning and Continuing Professional Development (CPD). Outputs /tasks. The DTS is likely to have other diverse roles and responsibilities within the unit, including instructional duties of their own. The Chain of Command should be aware of the additional workload imposed when carrying out Defence Trainer Supervisor functions and ensure that sufficient time is allocated for DTS to carry out their supervisory duties. Supervision of Defence Trainers will typically include the following tasks and responsibilities: Supporting the Defence Trainer Manager (DTM) in the implementation of DTC Direction. Overseeing the completion of Stage 3 of the Defence Trainer course for Defence Trainers. In practice this includes mentoring newly qualified Defence Trainers and conducting observations for TPs 4, 5 and 6. The assessment of the L3 AET portfolio is the responsibility of the Trainers from the unit that delivered Stage 2 (the residential element) of the Defence Trainer course. Carrying out legacy assessments of Defence Trainers and DTS to establish requirement for further training. Supporting the professional development of Defence Trainers through: Delivery and facilitation of induction. Provision of developmental feedback based on trainer performance. Identification and promotion of trainer-related Continuing Professional Development (CPD). Supporting the professional development of DTS through: Delivery and facilitation of induction. Provision of developmental feedback based on DTS performance when conducting Defence Trainer feedback sessions. Identification and promotion of DTS-related CPD. Application of coaching techniques. Quality assurance and maintenance of trainer standards through observation and monitoring. Overseeing newly qualified DTS completion of the DTS WTS. Mentoring other Defence Trainer Supervisors. Training and competence. The JPA DTS competence is achieved through passing the Defence Trainer Supervisor Course and, for DTSs, completion of the DTS WTS in accordance with the DTS Formal Training Statement (FTS). The JPA competences DTS Level 1 (Foundation) and DTS Level 2 (Practitioner) are awarded. Competencies. DTSs should display the following DTCF competencies as a result of their prior training and experience and should also demonstrate these competencies within the context of the DTS role: Group 1: Understanding the role of the trainer. Group 2: Planning and preparing learning and development (L&D) for the training. Group 3: Planning and preparing learning and development (L&D) for the work environment. Group\t4:\tFacilitating\tlearning\tand\tdevelopment\t(L&D)\tin\tthe\ttraining environment. Group 5: facilitating individual L&D in the work environment. Group 7: Maintaining and improving quality standards. Group 8: Leading learning and instruction in the training environment. ANNEX E TO DTSM 4"
  },
  {
    "id": "61d6ad38-f158-4f85-bbd6-738a39e527b0",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Legacy Assessment of Defence Training Supervisor (Table)",
    "content": "39 Eligibility for Defence Trainer Supervisor (Practitioner): Candidate to already hold Defence Trainer Supervisor (Foundation) level competence. ANNEX F TO DTSM 4"
  },
  {
    "id": "fc2fd3d7-0cd8-4533-ba22-002e52ea23fe",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Defence Trainer Manager - Terms of Reference",
    "content": "Role and purpose. The DTM is responsible for the management of staff delivering training and plays a critical role in creating and maintaining a culture of continuous improvement in the unit. Outputs/tasks. The DTM appointment is likely to be held in addition to other primary management roles and responsibilities within the unit. The Chain of Command (CoC) should therefore be aware of the additional workload imposed when carrying out trainer management functions and ensure that sufficient time is allocated for DTM to carry out these duties. The DTM role will typically include the following tasks and responsibilities: Advising the CoC on and ensuring the implementation of DTC Direction. Functional management of DTS. Supporting the professional development of training delivery staff through: Management of mandatory workplace training for Defence Trainers and DTS. Coordination of trainer-specific Continuing Professional Development (CPD). Quality assurance and maintenance of training delivery standards through: Implementation of unit self-assessment relating to the unit’s system for managing Defence Trainers and DTS. Promotion of good practice. Training and competence. The JPA Defence Trainer Manager competence is achieved through successful completion of the DSAT (Managers) course. Competencies. The following DTCF competencies are linked to the DTM role and are covered in DTM training: Group 1: Understanding the role of the trainer. Group 2: Planning and preparing learning and development (L&D) for the training environment . Group\t4:\tFacilitating\tlearning\tand\tdevelopment\t(L&D)\tin\tthe\ttraining environment. Group 7: Maintaining and improving quality standards."
  },
  {
    "id": "a3cae268-eb2c-4dc3-ade5-314faed22c79",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Coverage",
    "content": "This DTSM supersedes all previous DTSMs on Governance of Individual Training The totality of DTSMs included in the DTSMs Suite, of which this document is a part, are listed on the DTSMs SharePoint site."
  },
  {
    "id": "86308426-1866-4cc4-a293-c08cd6950648",
    "document": "DTSM 4 Delivery of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Editions / Versions",
    "content": "Annual editions of this DTSM will be published every December in time for upcoming year relevant to the DTSM. Throughout the year, different versions of the current edition may also be published. When every new edition is published, the versions will reset to 1."
  },
  {
    "id": "aa5fed0e-0df8-4203-8df6-874ddc917d46",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Uncategorised",
    "content": "Defence Training Support Manual 5 Evaluation of Individual Training"
  },
  {
    "id": "781edfcc-1d81-41f3-b5b9-eb11a1f51500",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "2023 Edition",
    "content": "Version: 1.0 Contents"
  },
  {
    "id": "5d5b9956-8b25-498e-bc8f-340978598587",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "How to use this Manual",
    "content": "Defence Training Support Manuals (DTSM) have been developed to support the understanding and implementation of the policy contained in JSP 822. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. DTSMs will be published every December, following the publication of the latest version of JSP 822. Throughout the year, different versions of the latest DTSM edition may also be published. When every new edition is published, the versions will reset to 1. Using the DTSMs is entirely optional, and users may find there are alternative resources available to help them understand and implement the policy contained in JSP 822. Throughout this document there are references to other DTSMs, these references contains hyperlinks that will take you to the DTSMs that are held on the   SharePoint site. The DTSMs currently available are:"
  },
  {
    "id": "1ee0486c-e028-4a59-9813-5f5fc4893bc1",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Introduction",
    "content": "This DTSMs provides Guidance on the processes and outputs associated with the evaluation of individual training. Evaluation activities do not focus solely on the provision of training (although this is a key activity) but also on the DSAT process and the Training System as a whole, including the Management Training System (MTS). In addition to evaluation, Element 4 activities includes Training Needs Evaluation (TNE) which is Stage 3 of the Training Needs Analysis (TNA). Evaluation activities are detailed in the Training Quality Manual (TQM) which is endorsed at the Customer Executive Board (CEB). The DSAT Quaity Management System (QMS) is key to assisting those involved in the evaluation of Defence training. The DSAT QMS is the standard that is met when the outputs of the DSAT Elements and the MTS activities are delivered correctly. The evaluation activities covered by this DTSM are: TNA, Stage 3 – TNE - This assesses and reports on the effectiveness of the TNA process as well as the ability of the implemented training solution to meet the Defence requirement. The TNE is conducted in 2 parts: evaluation of the process and evaluation of the training solution. The key output is an assessment of how well the TNA outputs contributed to the provision of a training solution that meets the Defence requirement. This completes the TNA process. Evaluation Strategy (EStrat). The EStrat is a long-term action plan for achieving successful training, which details what training will be evaluated and how. Internal Validation (InVal) and External Validation (ExVal). A specific sub-set of evaluation is Validation which is further split into InVal and ExVal. InVal examines whether the Training Objectives (TOs) are being met and ExVal uses both qualitative and quantitative data to determine the degree to which training prepares individuals for the specified Role and whether the Role remains valid. Responsibilities. The following are most likely to fulfil these roles/activities1:"
  },
  {
    "id": "ec2989f7-deae-4272-aa23-f147c43da3c3",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Requirements Authority (TRA):",
    "content": "TNE. EStrat. ExVal of the training activity. 1 Any deviation from the recommended delineation of responsibilities detailed on the DSAT Hierarchy of Activities should be recorded on the TrAD."
  },
  {
    "id": "19c8dd4e-c6fb-42a9-ac72-7d119f6cb8e4",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Training Provider (TP):",
    "content": "InVal based upon the EStrat written by the TRA."
  },
  {
    "id": "87eca584-e4de-4cdd-9e13-5c0973095424",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Evaluation Strategy",
    "content": "Writing an Evaluation Strategy is a key activity that is the responsibility of the TRA. Evaluation is defined as ‘the process of making a judgement as to the worth of training to Defence. It allows Defence to monitor the impact of training and assess what has been achieved, whether it was effective, efficient (i.e. represents VfM) and how it contributed to the achievement of Defence outputs’. Evaluation processes and procedures should ensure that training is: Efficient and effective. The input effort to deliver the training should be the minimum required to meet the output standard which should meet Defence’s requirements. Focused. The training should be focused on operational/business goals. The trained output should be able to perform their job competently. Necessary. A requirement for training must be identified. Flexible. The training must be responsive to a change in circumstances. Appropriate. The training product should match the employment need. The Evaluation Strategy is likely to include these individual elements, which collectively make up the whole approach to evaluation: InVal. Conducted by the Training Provider. ExVal. Conducted by the TRA. Kirkpatrick’s evaluation model 2 is a goal-based evaluation model that divides evaluation into 4 levels of measurement: Reaction, Learning, Behaviour and Results. In a Defence context, it would be useful to ask the following questions: Level 1 - Reaction. Did the trainee perceive the training as useful when compared to their expectations? This question is answered through InVal. Level 2 - Learning. Were new Skills and Knowledge acquired and Attitudes developed? This question is answered through InVal. Level 3 - Behaviour. Has Behaviour changed as a consequence of training and can this be measured when the individual is carrying out the Role? This question is answered through ExVal. Level 4 - Results. Was there a measurable impact on business performance and was Value for Money (VfM) achieved? This question can be answered partially through ExVal if agreed training costs are available. 2 Kirkpatrick, D.L. (1967), Evaluation of Training in, ‘Training and Development Handbook,’ edited by Craig, R.L. and Bittel, L.R. London: McGraw Hill. In devising an Evaluation Strategy the TRA develops a long-term action plan for achieving successful training. This requires the development of a strategy which aims to assess the total worth of a training activity. An Evaluation Strategy should therefore articulate the training to be evaluated, the types of evaluation to be applied and the roles and responsibilities of the people involved in the process. The Strategy should cover the whole cycle of training, starting when a training need is first identified and continuing until the required Defence outputs are achieved. It is not always necessary, beneficial or possible to evaluate all activities. The TRA should define those areas to be targeted in their Evaluation Strategy and define the link to the requirement. For all types of training, the Evaluation Strategy is based upon the 4 Stages of Evaluation in Defence as outlined in Table 2. Table 2: The 4 Stages of Evaluation in Defence When planning evaluation activity the following factors should be considered: Importance/impact. The actual or perceived impact of the training activity on Defence performance. Cost. The cost of the evaluation compared to the realised or potential/perceived benefit of the training activity. Outputs. Utility of the outputs of evaluation (e.g. can the results of the evaluation be used to improve the effectiveness and efficiency of the training?). Frequency. The frequency of the training activity. Availability. The availability of evaluation data. Feedback. Feedback from InVal or ExVal that requires further investigation. The benefits of adopting and implementing an Evaluation Strategy are various. Examples are: Clear communication and strategic direction for the evaluation of training. A framework from which the TRA can readily ascertain and/or demonstrate whether training is effectively contributing to the achievement of Defence outputs. More specifically, it assists the TRA, TDA or Training Provider to: Ascertain whether training is meeting Defence’s needs. Ascertain whether training is being delivered efficiently and effectively. Ascertain whether the refresher training strategies were successful. Quantify the learning transfer achieved by the training activity. Identify a consistent baseline against which to measure benefits. Responsibilities. The production of the Evaluation Strategy is the responsibility of the TRA and should be set out in the TQM (Element 3, 5.13). Developing an Evaluation Strategy. An Evaluation Strategy will involve the systematic collection and interpretation of evidence leading, as part of the process, to a judgement of value with a view to action. The term ‘systematic’ implies that the required information is defined at the outset; ‘interpretation of evidence’ and ‘judgement of value’ introduce a critical consideration; and ‘with a view to action’ highlights that evaluations are intended to provide recommendations for the modification and improvement of training. Any Evaluation Strategy, therefore, should: be systematic. ensure provision of a critical analysis of current training. be linked to risk management to enable review of mitigation strategies. give a clear indication of improvements to training. Ultimately, the Evaluation Strategy should be appropriate, proportionate, responsive and targeted on the needs of the Defence to help ensure that the costs of the evaluation activities do not outweigh the benefits. It should state: The evaluation stages to be applied to each training activity. The frequency with which each evaluation stage should be applied. The responsibilities of the various stakeholders at each stage of evaluation. The sources from which information will be obtained. The methods of data recording and analysis. The reports that will be raised. The staffing chain for addressing report recommendations."
  },
  {
    "id": "e7d55672-4b90-4ea5-ade4-03d0ea22e902",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Internal Validation",
    "content": "InVal – 4.1.1. InVal is a process used by the Training Provider to determine the efficiency and effectiveness of training delivery. To achieve this, InVal measures: The immediate reaction of a trainee to a training activity (Evaluation Stage 1; see Table 2). The learning transfer achieved by the training activity (Evaluation Stage 2; see Table 2). Responsibilities. The Training Provider is responsible for the conduct of the InVal process which involves personnel from a range of backgrounds including trainers and trainees: Trainer. Trainers have responsibility for day-to-day management of the InVal process including management of the AStrat and feedback mechanisms used during the training activity. Trainers also inform the InVal process through the provision of post-training feedback. Trainee. Trainees provide the primary source of feedback, through both test results and feedback, for the InVal process. The information is usually gathered through the completion of a questionnaire or through response to questions posed during a post training discussion or individual interview. In addition, the assessment of trainee Performance will provide data which can be used to measure the transfer of learning. InVal team. At large training establishments InVal teams may be tasked to conduct the InVal process. InVal teams offer the advantage of impartiality and can provide a ‘big picture’ overview of training effectiveness. Sources of data. There are numerous sources of InVal data: Training documentation. Training documentation should be checked to ascertain that all Standards from the TOs have been transferred to the LSpecs, that the AStrat includes the testing of all TOs and that any lesson plans (or equivalent) comply with the LSpecs. Formative3 and summative4 tests. Tests may be practical, written or oral in nature and can be used to ascertain that the trainees have assimilated the KSA 3 Formative assessments are conducted during training to identify any weakness in learning or training and to aid the retention of successful learning. 4 Summative assessments are designed to measure achievement at the end of a period of training. required to achieve the Standard as specified in the TOs. They can also be used to diagnose the strengths and weaknesses of trainees and test potential success, progress and achievement. An unusually high number of failures may indicate faults with the Training System rather than trainee performance. Trainer performance monitoring. Trainer performance monitoring can be used to ensure that training is being delivered in accordance with the LSpecs. Trainee logs. Trainees can be requested to complete logs on either a daily or weekly basis and should be required to submit written feedback regarding the training they have received. Observations. The observation of procedures is especially important in Skills training and relates particularly to the areas of speed, sequencing, manual dexterity and safety. Observations can take either a structured form, requiring the use of coded schedules, or can be unstructured, where the trainer uses their judgement about which events are considered important. Feedback questionnaires. Questionnaires can be used to capture trainee opinion on any aspect of training. They can be used to collect both qualitative and quantitative data. Timing needs to be considered to reduce the chance of trainees forgetting information. Questionnaires can also be used to gather information from trainers. Post training discussions. A discussion, or focus group, at the end of training enables trainees to air their views, to amplify comments made on questionnaires and for the trainers to gauge the initial reaction to training. It is considered appropriate to use staff who have not been involved with the delivery of the training activity to manage and conduct the discussion process. If ‘external’ staff are used in this way it may not be possible for these staff to answer questions or criticisms and this must therefore be done by the Training Provider. Irrespective of who conducts the discussion, the content of the discussion should be planned as for any interview, producing an aid or schedule to follow. Information from other sources will suggest the areas needing more/less attention or none at all and can include: The collated responses to the questionnaire. Reports from preceding training. Past problem areas. Issues raised by unsolicited or informal feedback. Analysis of assessment results. Interviews. Interviews can be conducted in order to collect trainees’ reactions to training. They have the advantage of being flexible and allow subjects to be explored in depth. However, interviews can be time consuming and are normally only used to obtain opinions from small numbers of trainees and trainers. Interviews can take both structured and unstructured forms. Unsolicited feedback. Unsolicited feedback may come from trainees, trainers and training support staff through involvement in informal discussions. Data gathered through this means can be used to usefully inform the InVal process and should not be treated in isolation. Other tools. In addition to the tools listed, activities such as audits of the Training System and management reports can provide useful additional data to inform an InVal. Timing. The data required to inform the InVal process can be collected before, during, or at the end of, the training process: Before training starts. When specifying the content of a training activity, it may be necessary to establish what the trainees already know, or what trainees can do, by means of pre-course diagnostic testing. Failure to recognise that trainees can perform certain tasks or possess certain Knowledge can result in training that is inefficient or irrelevant. It is also important to gauge trainee expectations. These tasks can be achieved through completion of a pre-course questionnaire or a pre- course discussion with the information gained used by trainers to enhance the relevance of the training."
  },
  {
    "id": "81505f67-d29d-4f3c-8056-0316fe296f39",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "During training.",
    "content": "Measuring learning transfer. Formative assessments are conducted during training and can be used to measure the learning transfer. Assessing trainee performance during training enables training problems to be identified and dealt with as they arise and allows the Training Provider the opportunity to measure trainee progression towards the achievement of TOs. Trainee reaction. Trainee reaction to the training that has been received can be captured during, as well as after, training. Questionnaires, logbooks and unsolicited feedback are methods through which trainee reactions can be captured."
  },
  {
    "id": "34cea601-3bff-48aa-9e5a-d5bec7382da2",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "At the end of training.",
    "content": "Measuring learning transfer. The testing and assessment of trainees at the end of training provides a vital indicator of overall training effectiveness. The results of summative assessment can be used to help the Training Provider identify which areas of an activity caused trainees difficulties; they can also be used for assessing the effectiveness of the Training System as a whole. An essential element of the InVal process is the analysis of test results in order to assess the effectiveness of the tests themselves. Trainee reaction. Feedback mechanisms, such as questionnaire- based critiques, and post training discussions, can provide information against which trainee reactions to training can be gauged. Trainee assessment results, coupled with reaction to training, will allow trainers to evaluate trainee performance and will facilitate the formulation of judgements regarding overall training effectiveness. Analysis of data. The InVal process can generate considerable qualitative and quantitative feedback, some of which may be contradictory. In order to ensure that any changes made to training are positive, it is essential that a robust analysis of feedback data is implemented. When analysing data it is important that an analyst is familiar with the concepts of validity, reliability and triangulation: Validity. A measuring instrument is valid if it measures what it is intended to measure. For example, in training the most valid measuring instrument for a practical Skill is a practical test. A written test may well test whether the trainee knows what to do in a practical task but not if they can actually do it. Reliability. A measuring instrument is reliable if it gives consistent results. For example, a test or questionnaire, when administered to two very similar groups, would not be reliable unless it gave similar results. If it is a reliable measuring instrument it should also give similar results when it is administered twice to the same group at different times. Triangulation. The term triangulation is used to describe the use of 2 or more data gathering techniques to investigate the same phenomenon. Confidence in the findings is enhanced when the techniques yield similar results. For example, if the outcomes of a questionnaire-based survey correspond to the findings of an observational study of the same phenomena, the more the analyst will be confident of the findings. In addition to the use of 2 or more data collection tools, triangulation can also be achieved using 2 or more analysts using the same research instrument. Factors that influence trainees’ reaction to training. Despite the evaluators' best efforts to design feedback mechanisms which are both reliable and valid, it is important to realise that there is a range of external factors that may influence the content of InVal feedback. Every attempt should be made to take these into consideration when conducting an analysis. For example, trainees' reactions to training can be influenced by many factors, including: Their relationship with their trainer. Their attitude towards attending the training. The influence of peers. How hard or easy they found the training. The perceived relevance of the training. The quality of the delivery of the training. Presentation of findings. Once data has been gathered and analysed, it becomes evidence to support the conclusions and recommendations of the InVal. It should, therefore, be summarised and incorporated into a report, although it may be appropriate to hold a meeting of stakeholders and record the findings in minutes. For a training activity to be deemed internally valid it must be proven, by triangulation of data, that all training and testing meets the requirements of the TOs as contained in the FTS. For the InVal teams to be able to identify a course as being internally valid they must be able to positively state that: All Standards have been transferred from the TOs in the FTS to the LSpecs. The trainers are training to the LSpecs. Training is being delivered to the correct Standards and Conditions. The TOs are being tested to the correct Standards and Conditions as per the ASpec. The trainees have assimilated the Knowledge and Skills to achieve the required Performance. The InVal report is primarily an internal document but it can also be distributed to those responsible for conducting ExVal where appropriate. The InVal report should be used as a management document to identify where, or indeed if, changes to training should take place. It may also form useful evidence for any major changes to the Training System which would be discussed at the appropriate governance body (such as the CEB). InVals also form part of the MTS and contribute to ensuring that the Training System meets the Defence mandated QMS."
  },
  {
    "id": "a2bfbfac-c247-4583-9cf0-fef8ea3eaeb8",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "External Validation",
    "content": "ExVal uses both qualitative and quantitative data to determine whether the training remains relevant to the workplace or role. ExVal should also measure business improvements. ExVal is applied after trainees have completed a training activity and have had the opportunity to apply what they have learnt in the workplace. ExVal measures: The changes in Behaviour of trainees as a result of the training and how well the KSA have prepared trainees for their Role; and whether the requirement is still valid (Evaluation Stage 3; see Table 2). The contribution of training to the achievement of business/operational goals (Evaluation Stage 4; see Table 2). Aims. The first aim of ExVal (Stage 3) is to determine the success of training in preparing individuals for their Role and whether the requirement is still valid. The following must be considered: Timing. Initially, after training, an individual’s motivation will be increased. Performance, however, frequently suffers as people try to ‘unlearn’ old behaviours and practise new skills. Therefore, the timing of ExVal should be determined by both the length and complexity of the training activity that is being validated. Usually, an ExVal would be implemented between 6-18 months after the completion of training. On the other hand, if too long a period is left between the training event and the ExVal, it will be difficult to ascertain which KSA have been acquired as a result of training and which have been learnt subsequently. Methodology. Some measurement of Behavioural change may have already been made during the assessment of trainee performance during training. However, in order to ascertain the full impact of training on individual performance in the workplace, further analysis must be undertaken. The process through which data is collected and analysed in order to inform ExVal should be planned. This is typically via questionnaire-based feedback mechanisms5. Questionnaires will normally be distributed to both ex-trainees and their respective line managers at least 6 months after the completion of training. The questionnaire should examine the degree to which the TOs relating to a particular training activity remain relevant to the employment area they were designed to support. The questionnaire should also serve as a mechanism through which data can be gathered on wider aspects of the training process, and must be responsive to the needs of all stakeholders. The questionnaire should also give Training Providers a common method of determining 5 Although questionnaires will be the main method of gathering data, the user should not rule out the other tools available, such as minutes of meetings, visit reports and data relating to Role performance that is obtained through observation of the trained individual in the working environment and through interview. how applicable and effective the training was in affecting the trainees' Role Performance. Data should also be gathered from trainers. Activities such as audits of the training process, trainer monitoring, management reports and other data gathered through the InVal process can all be used to inform ExVal. The aim of Stage 4 Evaluation is to assess overall benefits to the organisation of a particular training activity and whether it offered VfM. This Stage of evaluation is challenging in an organisation the size of the MOD. Defence Performance and Risk reporting mechanisms mean it is possible to measure whether training has directly contributed to Defence outputs by measuring performance against the Defence Board Defence Tasks which are, essentially, Defence’s organisational goals. To evaluate business benefits to the organisation, training should be linked to the Defence Tasks and their subordinate SC objectives. Those conducting Stage 4 Evaluation should bear in mind that there are many other factors external to training which may impact business performance (such as redundancy programmes, leadership in the workplace etc). JSP 507 provides guidance on the evaluation of projects including the assessment of whether VfM was achieved. Responsibilities. It is the responsibility of TRA to conduct ExVal. The TRA may employ an ExVal team for the planning, coordination and implementation of the ExVal and for the dissemination of the results. In doing so the team will need to draw on the experiences of many of those involved in the training process who should be encouraged to take individual responsibility for the conduct of ExVal. Wherever such a responsibility is accepted then CI of the training is more likely. The main contributors include: Ex-trainees. Provide information, by questionnaire and/or interview, that informs the ExVal process of their opinions as to how well the training prepared them for their in-Role tasks. Line managers. Ranging from the ex-trainees’ immediate supervisor to their CO (or equivalent), such personnel usually prove to be more objective sources of information as to how the training has prepared the ex-trainee for their Role. Subject Matter Experts (SMEs). Recognised experts in the subject matter for which the training was designed should be identified and consulted. An SME working within a Training Provider should not, however, be disqualified from making a contribution purely on the grounds of their current employment. The methods of gathering and analysing data used in ExVal will vary according to the object, scope and Stage of the ExVal itself. The final ExVal report should be used to identify where, or indeed if, changes to training should take place. It may also form useful evidence for any major changes to the Training System which would be discussed at the appropriate governance body (such as the CEB). ExVals also form part of the MTS and contribute to ensuring that the Training System meets the Defence mandated QMS."
  },
  {
    "id": "62de52d7-407a-4b11-be26-21a297a17147",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Data Gathering and Analysis",
    "content": "There are a variety of data gathering tools and analysis techniques that are available to assist with Assurance, particularly InVal and ExVal. This Guidance aims to present the tools and techniques available along, the advantages and disadvantages each brings and some considerations for the analysis of data."
  },
  {
    "id": "fcfec379-89e3-4a8e-a9d8-2e33f2e99868",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Characteristics of data gathering tools",
    "content": "The characteristics that all measuring instruments should possess are: Validity. A measuring instrument is valid; that is, relevant and appropriate, if it measures what it is intended to measure. In training, the most valid measuring instrument for a practical skill is a practical test. A written test may well test whether the trainee knows what to do in a practical task, but will not test whether the trainee can actually do it. The written test is not valid because it is measuring the wrong thing. If a measuring instrument is not valid it should not be used however effective its other characteristics. Reliability. A measuring instrument is reliable if it gives consistent results when the same entities are measured under the same conditions. If it is a reliable measuring instrument it should also give similar results when it is administered twice to the same group at different times (i.e. test/re-test reliability). If a test, questionnaire, report form or interview is not reliable it should not be used. Standardised Conditions. The conditions under which a measuring instrument is used should be standardised. If the administration of the same test on two separate occasions is likely to bias responses, due to a learning effect, then it is possible to develop an alternate form of the test. Alternate form reliability, however, would need to be demonstrated. Discrimination. A measuring instrument should be sensitive enough to record differences between individuals in what is being measured. Similarly, the inability to discriminate between satisfactory and unsatisfactory training is of no use. Practicability. Any assessment of training must be administratively practicable. A theoretically superb assessment system is of no use if practical limitations, such as time, cost or workforce considerations prevent it from being used."
  },
  {
    "id": "0dfd93fa-0632-4a1f-9e00-8f2cf8bb4077",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Factors influencing the choice of data gathering tools",
    "content": "The choice of data gathering tools is crucial in determining the effectiveness of the study. Influencing factors can be: The reason(s) for directing data gathering to be conducted. The resources allocated to the task (such as, timescale, workforce, funding). Level of expertise of the analysts. The size of the Target Population: Numbers of Role holders6 and supervisors/managers. Rank/experience. Trades/skill levels. Availability of target population/geographical influences. For example, questionnaires may be preferable to face to face interviews for a widely dispersed population in distant locations. The data gathering plan should be produced at an early stage, highlighting the tools, sources of data and resources that will be used. The relative advantages and disadvantages of the main data gathering process are discussed later in Chapter 5."
  },
  {
    "id": "f15d350f-d9b3-4479-b860-765b47fcf884",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Ethical considerations when gathering data",
    "content": "There are several ethical considerations that need to be adhered to throughout the data collection process7. The respondents’ right to privacy and the right to refuse to answer certain questions, or to be interviewed at all, should always be respected, and no undue pressure should be brought to bear. The reason for this caution whilst undertaking data collection is not only for the interviewee’s benefit but also for the interviewer’s. If an interviewee believes that answering questions honestly will harm them then they are more likely to give bland, misleading and uninformative answers. Any evaluation based on such data is invalid. When conducting interviews a manner conducive to following sound ethical considerations should be followed. Examples are: Honesty. The interviewer should portray a non-threatening manner and remain truthful and faithful to the purpose of the interview. This ensures that the interviewee also gives honest answers to any questions. Impartiality. Regardless of the analyst’s own particular viewpoint, an interview or questionnaire analysis should remain objective, valid, reliable and accurate. No attempt should be made to persuade a respondent to agree with the analyst’s perspective. For example, an interviewer must be careful not to ask leading questions. Relevance. The reason for the data collection and the target population is to be made clear. The data collection tool must be objective and economic with the respondent’s time. For example, an interview should be concise and focused. Rushed interviews with irrelevant questions reduce the credibility of the interviewer and the reliability of the data gathered. Confidentiality. If the data collected is to remain confidential, and the analyst has stated this, then confidentiality must be observed. If the respondent wishes to remain anonymous and if the analyst agrees then this agreement must also be observed. It may also be important that it is explained who will see the data collected and the analysis of the collected data. Such openness on the part of the analyst leads to respondents being equally open. 6 For the purpose of this Guidance the terms ‘role holder’ and ‘ex-trainee’ are synonymous. 7 The  provides further guidance. Anonymity. Consideration needs to be given when anonymity is to be used. If follow up interviews are to be undertaken as a result of the data gathered from questionnaires then it is important to have those details of individuals filling in the questionnaire. Consequently, the reason for the lack of anonymity should be stated as part of the instruction to the questionnaire. Additionally, individuals are more likely to complete questionnaires if they know what is going to happen with the data collected. If there is no requirement to know who has completed a questionnaire or interview then anonymity is recommended. Control of data. Data should be utilised in accordance with the Data Protection Act (DPA) 2018. The DPA sets standards for protecting general data, in accordance with the GDPR, giving people more control over the use of their data, and providing them with new rights to move or delete personal data. Further information about the DPA and GDPR is available at  ."
  },
  {
    "id": "60ba140e-ac8a-4639-8a56-6788e07aef83",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Data gathering methods",
    "content": "Quantitative data gathering. Quantitative data are gathered using closed questions (yes/no or scored answers). A relatively simple easy way of processing quantitative data is through some form of frequency statement which requires the use of standardised measures so that the varying perspectives and experiences of respondents can be identified by a number of predetermined response categories. A numerical value is then assigned to each category. Qualitative data gathering. Qualitative data can be defined as data gathered on individuals’, feelings, opinions, beliefs etc using open ended questioning. Qualitative methods allow the study of selective issues in depth and detail. Qualitative data consist of detailed textual information rather than numerical information generated by quantitative techniques. Qualitative data can be generated from 3 main types of data collections: Questionnaires/written documents. Document analysis in qualitative terms includes excerpts, quotations or passages from organisational records and open- ended written responses to questionnaires and surveys. Direct observation. The data from observations consist of detailed descriptions of operators’ activities, behaviours, actions that are part of observable human experience. Interviews. The data from interviews consist of quotations from respondents about their experiences, opinions, feelings and knowledge. These aspects are elicited using open-ended questioning and can be used to confirm/clarify data obtained as referenced above."
  },
  {
    "id": "1346d9d5-2b65-4dea-a4e0-c7624ad3cb51",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Piloting",
    "content": "The aims of piloting are to allow: The systematic gathering of information to confirm validity of data gathering tools. The identification of technical inaccuracies and faults. Testing the questions. When piloting (testing) the questions these points should be borne in mind: The question should involve only one idea. The question should be worded as simply as possible in light of the ability of the target group. The question should be as brief as possible. The question should be as direct as possible. The question should allow the respondent to admit lack of knowledge without loss of face. The question should be positively phrased - not looking for negative response. The question should not influence the response. Piloting process. For questionnaires, when the initial construction is complete, in addition to testing the questions, the questionnaire must be piloted as follows: The questionnaire is completed by an individual under the close supervision and with the assistance of the designer. Any difficulties found or comments made by the person completing it should be noted. The individual chosen should be either a member of the group for whom the questionnaire is intended, or as much like the members of this group as possible. Ideally, this procedure should be carried out a number of times with different people. The questionnaire is amended to solve problems and ambiguities found in the first stage. The amended questionnaire is then completed under the same conditions that will prevail when it is eventually administered. Again, members of the group used should be as near as possible to those for whom the questionnaire is intended. The respondents should be asked for comments or criticisms after they have completed the questionnaire. The questionnaire is amended to eliminate any difficulties or ambiguities remaining. Analysis of the answers given should assist in indicating any inconsistencies in answers that may be the fault of the questionnaire. Outcomes. Only after effective piloting can the questionnaire be considered ready for use. Even then the questionnaire will not be perfect. Answers given and comments made by those completing the questionnaire will indicate, in some cases, that further amendments are required: If the structure of the design does not need any alteration following the pilot, then information obtained from the pilot can be used as part of the population data. However, where the population is to be analysed by sampling in order to prevent any misrepresentation or confusion, the data-gathering pilot should be conducted on a separate sample of the population. Once the objective(s) of the study has/have clearly been stated, including sample/population size and the quality and type of information to be received (qualitative and quantitative), the process of establishing the data gathering techniques can begin. Sources of information. When conducting a pilot careful consideration should be given as to who would be the best source of information for particular areas: Subject Matter Experts (SME) and trainers can provide useful feedback in respect of the technical content included in the interview/questionnaire and the language used. Representative operators can be used to review the responses already obtained from SME input. In addition they can also provide information on: Operator reaction. Ease of completion. Sequence of activities. Time taken to complete questionnaire. Depth of response required. Piloting pre-requisites. There are certain pre-requisites for piloting when carrying out a study: High cost. Large target population. Complex subject matter. Tasks of a critical nature."
  },
  {
    "id": "b0475835-4cfb-4ca6-a49b-97afb080ffd3",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Choice of data gathering techniques",
    "content": "Once the objective(s) of the research have been clearly stated, including the sample/population size and the quality and type of information to be received (either qualitative or quantitative data), then the process of establishing the technique to be employed to gather the data can begin. The choice of data gathering technique(s) will depend on the sample size, resource implications and many other factors. In all cases the data gathering method should be fit for purpose and developed by suitably qualified and experienced personnel. Questionnaire. A questionnaire can be used to cover a large number of people at relatively low cost and the data it provides is generally easy to analyse. However, questionnaires are difficult to design, are resource intensive and require piloting and pre- testing to ensure that they are collecting the right types of information. Questionnaires do not always allow great flexibility, may not be completed by the recipient, and response rates are not always as high as the team doing the analysis would wish. Interview. Data can be gathered from Role holders and their employers by interview. While the interview allows the personal touch to be brought to the analysis process, and its inherent flexibility, care needs to be taken to avoid bias. The process is time-consuming and data analysis can be difficult. Observation. Observation of personnel carrying out their tasks can also provide useful information but it is a very labour-intensive means of acquiring data. It is usually limited by the range of tasks being undertaken and can be misleading if the observer is unfamiliar with the task. Document research. When conducting a study it may be necessary to consult documents such as interim reports from on-going related studies, exercise reports, operational reports, current training documentation, doctrine and policy documents and manufacturer’s manuals. A conference of experts. This is sometimes known as a Technical Conference or Focus Group and is held when it is necessary to discuss the nature of the Role with others who are experts in that particular field. In some cases this may be the only data gathering method available or needed. It produces quick results, but the problem with experts is that they tend to overlook routine aspects of a Role that could present problems to the non- expert. This method can also be used to analyse findings (e.g. from questionnaires). Critical incident technique. The critical incident technique is the procedure for collecting observed incidents that have proven very important or critical to performance. It has been used extensively in civilian flight safety investigations and can be used to provide data on the relevance of training to performance of the Role or task. However, this technique can be very lengthy and labour intensive when used to identify the whole spectrum of tasks that make up a particular Role."
  },
  {
    "id": "bdefdffc-f3c0-4300-9398-b355e2d5fea0",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Questionnaires",
    "content": "Questionnaires can gather qualitative and quantitative information and are very useful in both InVal and ExVal. Questionnaires sent to ex-trainees sometime after their course can provide useful information about the relevance of training. Questionnaires should be sent out on a routine basis to ex-trainees and their supervisors at an appropriate period on completion of training (normally 6-9 months). This type of questionnaire looks all the tasks conducted, addressing: Do the operators carry out the tasks for which they were trained? How well were the operators trained for these tasks? Do the operators carry out any other tasks for which they were not trained? Constructing a questionnaire. When producing a questionnaire these points should be borne in mind: Introduction/rapport. The introduction, or covering letter, to the questionnaire is very important, because unless the full co-operation of the respondent is obtained the results are useless. To ensure willing co-operation, the questionnaire should create and maintain rapport with the respondent. The purpose of the questionnaire should be explained whether in a written introduction or by the person administering the questionnaire. It should be made clear that respondents’ opinions are valued and could make a difference to the results of the project. Presentation. The questionnaire should look well prepared and be easy to complete. Instructions. Instructions on how to complete the questions should be simple, clear and concise. Language. The language used in questions asking for criticisms should be impersonal and permit the expression of frank replies. Questions. Questions should be: As short as comprehensive coverage allows and must be relevant to the information required. In a logical sequence. Questions relating to a specific subject should be placed together. Precise and specific. Vague questions will lead to vague responses due to different interpretation. If a group of questions does not apply to everyone it must be made apparent who is to answer them. Filtering of questions is recommended. Capable of being answered. Respondents must be capable of answering the questions and have adequate knowledge/experience to provide meaningful responses. Confidentiality. Respondents must be reassured that the questionnaire will be treated in strict confidence and that completed questionnaires will only be seen by the analysis team and destroyed once analysis is completed. Clarification. Provide a contact name and telephone number for any queries. Include a date for completion and return of the questionnaire. Details. One part of the questionnaire from which the analyst can obtain useful data is the element on personal details. In deciding what personal details are required, the analyst will be guided by the requirement of the analysis. The analyst must ensure that the questionnaire asks for all the details that will provide meaningful data for the analysis, while at the same time not asking for details that are clearly irrelevant to the analysis, as by doing so this may tend to alienate some respondents. If the analyst requires some particular detail, but considers that the respondent may not realise why it is required, the analyst must explain the reason behind asking for the information. Increasing the degree of openness of the potential response received can be achieved by offering anonymity (discussed earlier) by not including clearly attributable details in the personal details. However, if anonymity is quoted it must be honoured. Questions over confidentiality cannot only taint the study but may also negate the chance for further open and honest dialogue. Dangerous questions. There are certain types of questions which should be regarded as ‘dangerous’, producing inaccurate and immeasurable answers, or, at best, vague responses which can easily be misinterpreted: Multiple questions. These have a variety of responses ‘Yes/Yes’ ‘Yes/No’ ‘No/Yes’ ‘No/No’. For example ‘Are you supervised at work and do you rely on manuals? Negative questions. These are difficult to understand and it is unclear what the response means. For example to answer ‘No’ to the question ‘Would you prefer not to have to account for this equipment?’ is confusing. Questions are more readily understood if phrased in the positive. For example ‘Do you think you should account for this equipment?’ Leading questions. Beginning the question with words such as ‘It’s obvious that...’ can influence the respondent’s reply. In the closed question format, limiting the fields of response to ‘Very Interesting’ ‘Interesting’ and ‘of some interest’ steers the respondent away from the response ‘Tedious’. Loaded questions. These are similar to leading questions but tend to have an emotional overtone, for example ‘Have you stopped cheating in tests?’ and ‘Which aspects of your training were irrelevant?’ Prestige bias questions. Some questions may tempt the respondents to reply in a way that will present them in the strongest light, hence there might be a reluctance to admit that certain tasks are difficult or never carried out. Anonymous questionnaires. Making the questionnaire anonymous (not adding clearly identifiable details which can be traced) has the advantage of encouraging more candid responses, increasing the degree of openness. However, its main drawback is that it is not possible to analyse the responses further, through follow up interviews. If anonymity is promised it must be honoured. Questions over confidentiality not only taint the study, but also negate the opportunity for further open and objective dialogue. Advantages and disadvantages of questionnaires. When gathering data using written questionnaires analysts must be aware of the respective advantages and disadvantages:"
  },
  {
    "id": "b52e79a1-5f2e-405b-b81e-593cd7a2146a",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Advantages:",
    "content": "Relatively cheap way of data collection. Large target population. Largely objective although there could be bias in analysis of qualitative responses. Potential to automate data entry and analysis. Can be anonymous. Questions can be asked in a consistent manner."
  },
  {
    "id": "c9087d9e-d2d9-4fc2-8b20-62c0ca4e3671",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Disadvantages:",
    "content": "No guarantee of respondent identity. Response rate may be low. Impersonal - difficult to establish a rapport with respondent. May be limited by length. Investment needed to develop and pilot the questionnaire."
  },
  {
    "id": "38ebfb68-fbd3-421f-9e79-55e7ccfce524",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Interviews",
    "content": "Purpose. An interview is not an aimless chat but a method of obtaining specific information. An interviewer must work out beforehand what information is required; otherwise, the interview will be ineffective and a waste of time. The questions should be incorporated into an interview schedule, which will: Remind the interviewer of the areas that must be covered. Provide a framework for the interview and ensure that data are collected in a systematic and standardised way. Interviews can be structured, semi-structured or unstructured (open ended); this refers to the degree to which the interviewer follows prescribed questions or deviates using prompts to gain further information from the interviewee. Generally, the more structured the interview, the more comparisons can be drawn between responses. However, unstructured interviews can provide richer data and may be useful if the interviewer has only a limited knowledge about the subject matter of the interview. Interviews involve going outside the immediate training organisation to interview employing officers and ex-trainees at all levels in field units. Gaining entry to these units and access to those who are required for interview needs careful planning and proper authority. The question of the appropriate ranks of interviewer and interviewee should also be considered. The interview schedule. The interview schedule can be regarded as a verbal questionnaire but differs from the written questionnaire in that the instructions are for the interviewer not the respondent (interviewee). The instructions should indicate: The amount/level of background information to be provided. The amount of prompting allowed. The method(s) of recording and interpreting responses. The instructions should assist the interviewer in conducting the interview allowing them to place a mark against one of the responses already included on the sheet. However, there should be sufficient space to record open responses. General techniques of interviewing. An interview is not an interrogation but a relaxed, two way exchange with the interviewer maintaining an open and understanding attitude. The interviewer must not, however, allow the interview to pass from their control. The structure of the interview must be decided beforehand on the basis of the information required. While the interviewer must be flexible and allow the subjects to express themselves, the interviewer must be firm and maintain control. Role of the interviewer. The effective interviewer listens, adapts their approach to what is being said and avoids interpreting what is said to fit in with their own ideas. Interviewing is a skill that must be learned and practised. Although there is no one correct way of conducting an interview, the following guidelines may be of assistance: Rapport. In order to establish good contact with the interviewee, the interviewer needs to: Decide the purpose of the interview and what is to be gained from it. Decide the questions to be asked during the interview. Ensure that any information, reports or data required to back-up the interview are readily available. Decide when the interview is to take place. Arrange a convenient time for both interviewer and interviewee so that there is no need to rush the interview. Arrange a suitable location for the interview. Avoid discomfort or distractions. A comfortable room without a telephone is ideal. Telephone interruptions can destroy the relationship built up between the interviewer and interviewee. One of the most irritating distractions is that of people ‘barging in’ during the interview. Prevent this from happening by placing an ‘Interview In Progress - Please Do Not Enter’ notice on the door. A friendly, sympathetic, but emotionally detached relationship should be established to put the respondent at ease. This should gain their confidence and thus persuade them to talk freely and frankly about themselves. Whenever a candidate has to wait in another room before the interview, the interviewer should always escort them into the interview room. In this way contact is made in less formal surroundings than the interview room; the rapport thus established can help to smooth the way into the interview itself. The interviewer(s) should introduce themselves fully. The interviewee should be told the reason for the interview. Difficult or controversial topics at the beginning of an interview should be avoided. Allow the interviewee to get used to talking. This can be achieved by starting with an ‘easy to talk about topic’. Content. The interviewer can elicit facts efficiently only if they ask the right sort of questions and pose them in an appropriate manner. The main points to note are: Do not read out facts. Repeating information that is already available in forms or publications wastes time and can antagonise the interviewee. Use appropriate language level. The interviewer should make sure the interviewee understands the questions using the most appropriate vocabulary for the interview. Ask one question at a time. Rambling, multiple questions confuse the interviewee and are difficult to answer. Keep questions simple, unambiguous and to the point. Avoid leading questions. Avoid questions that hint at the answer expected; some interviewees will tend to give the answer they think is wanted. Avoid trick questions. Trick questions that attempt to ‘catch out’ the interviewee provide little information and can endanger the contact that has been built up. Use comparative questions. It is easier for an interviewee to say which of two things does the indiviudal find more difficult than it is for the individual to state how difficult something is in absolute terms. Use open questions. The interviewer should try to use questions beginning with words such as “tell me about...”, “how ...”, “when ...”, “why...”, rather than those which demand a simple “yes” or “no” answer. Control. To ensure that the interview flows smoothly from topic to topic and control is retained, the interviewer should attempt to: Avoid interruptions. Interruptions can cut off the interviewee’s train of thought. The interviewer should interrupt only when necessary in order to avoid digression, or to regain control. Use pauses wisely. Do not rush to fill any pauses that may occur in an interview with another question. Pauses give both interviewer and interviewee a chance to consider what has been said and the interviewee may spontaneously continue with further information. Handle delicate issues carefully. On occasion it may be necessary to ask questions about topics which are emotionally charged or which may cause distress or embarrassment. These topics should be left until effective rapport has been established, introduced when a natural opportunity occurs and discussed in an open, objective, but tactful way. Summarise. It is useful occasionally to summarise what has been covered. This helps ensure that all the relevant points are covered and that the interviewee’s statements have been understood. Be flexible. The main advantage of the interview is its flexibility in that points can be followed up as and when they arise. This advantage will be lost if the interviewer follows a preconceived plan rigidly and without reference to what has been said. The interviewer must: Be prepared to adapt themselves to the natural flow of the interview. Follow up leads as necessary. Ensure that, in the end, all the information required has been obtained that is needed. Recording Responses. It is impossible to remember everything that was said in an interview. To avoid later distortion, interviewers must try to record responses during the interview, without breaking contact with the interviewer. Beware of bias. The purpose of the interview is to collect information as accurately and objectively as possible. The interviewer should guard against introducing bias by interpreting the replies to fit in with their preconceived ideas. It is also important to avoid biasing the replies by expressing approval/censure. The interviewer must suppress their own opinions and feelings and help the flow of conversation with neutral phrases such as “good”, “I see” or “go on”. Interviewee questions. After answering a series of questions it is reasonable to allow the interviewee to ask some of their own. These should be answered before ending the interview. Thank interviewees. Finally, end the interview on the right note and thank the interviewee for their help and information. Remember that it may be necessary to interview them again at a later date. Interviewing techniques checklist.\tThe following list is a summary of points to consider when conducting an interview as part of the data gathering process."
  },
  {
    "id": "e1a87b22-5bdc-4a64-a653-1420a2b68432",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Contact:",
    "content": "Be prepared: ‘read in and ready’. Ensure a suitable environment. In time and enough time. Introduce yourself (if necessary). Be pleasant but not too amiable. Make sure the interviewee knows the object of the interview. Reduce tension. Start with an ‘easy to talk about’ topic."
  },
  {
    "id": "6353b106-ab79-4484-b954-e9d7963e8d15",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Content:",
    "content": "Do not read out facts from forms. Use the appropriate language level and adjust as necessary. Ask one question at a time. Avoid leading questions. Avoid trick questions. Make use of comparative questions. Use indirect open questions. Distinguish between skill and enthusiasm. Explore the reasons for statements."
  },
  {
    "id": "5e794187-88ee-4671-975c-a2e84b108441",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Control:",
    "content": "Avoid interrupting the interviewee. Use pauses widely. Handle delicate issues carefully and as opportunity occurs. Summarise from time to time. Be flexible rather than rigid. Use open, probing then linked questions. Follow leads given by the interviewee. Keep a balance between the points of your plan. Make notes. Beware of bias. Avoid ridicule. Give the interviewee chance to add points at the end. Answer interviewees’ questions and thank them. Recording responses. It is rarely possible to record all that a respondent says during an interview and it would be of little value in any case since all the answers would then appear to be different. What is necessary is the grouping of answers under suitable headings, so that the completed schedule will indicate clearly and concisely what the interviewee may have taken a quarter of an hour to say. It is then appropriate for the interviewer to indicate how the answer has been recorded (e.g. “Am I right in putting you down as saying?”). This gives the respondent time to think again and for the interviewer to check that what has been said has really been understood. If the answer does not fit under an already accepted heading then it must be inserted under a new heading, which will in turn be available for all subsequent interviews. A pocket-dictating machine may be useful but permission must be gained to use one. Recording interviews can also inhibit interviewees. Attempt to transcribe a recording is prohibitive due to the amount of time required. It may be worth considering the use of a second team member to record responses. This will leave the interviewer free to concentrate and develop the interview. A successful interview is dependent upon: Careful planning. Good questioning technique. Establishing an effective good rapport with the interviewee(s). Advantages and disadvantages of interviews. Interviews have the advantage of being flexible, allowing subjects not previously considered by the interviewer to be raised and explored. They can be extremely time-consuming, hence they may be used to clarify issues raised from questionnaires for relatively small numbers. A structure must be developed (see Interview Schedule below) to record the strength of opinions given. Interviewers and those analysing the data need to be trained if similar opinions are to be rated by different individuals. Once achieved, information obtained from different interviewers can be compared:"
  },
  {
    "id": "42c81956-0124-40a3-a41d-5de283bc7831",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Advantages:",
    "content": "Easier to tailor to the audience. The interviewer can select only those questions that are relevant to a particular situation. This is particularly important when the Role in question is unusual and it would be time- consuming, costly and unacceptably bulky to produce a detailed questionnaire to cover all possibilities. The interview can be conducted with reasonable speed (depending on circumstances). Wide range of topics can be covered to required depth. Entirely new points of interest can arise. The interviewer can deal with these immediately and add them to the list of questions to be put to all remaining respondents. Personal contact can reinforce commitment to study and raise response rate. The interviewer can check that the respondent has understood technical expressions and terms which have been used in the questionnaire. For example, a term like ‘Defence Writing’ is open to numerous interpretations. To one person it may mean the mechanics of writing, i.e. layout, conventions etc, while to another it concerns matters of style and content."
  },
  {
    "id": "638b8795-baa9-475d-b46a-7681eda40feb",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Disadvantages:",
    "content": "Time intensive - not only the interview itself, but the analysis of data it produces. Data may be of complex nature requiring structured/thematic analysis. Requires experienced personnel to conduct the interview. Lack of objectivity, further to which the relationship between interviewer and respondent can become confrontational limiting transmission of objective information. Can be influenced by perception - there may be bias for, as well as against, a particular topic."
  },
  {
    "id": "89e54163-8544-4c4c-94bc-e2ce3d5d54cb",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Observations",
    "content": "Requirements. Observation involves watching, recording and analysing. Observing a particular activity is influenced by the fact that human perception is highly subjective. The fact that an individual is equipped with functioning senses does not make that person a skilled observer. Different people looking at the same design or object will see different things, due in part to their interests, biases and backgrounds. Coding. The observation may be unstructured, with the person who is observing being as open-minded as possible and using his or her judgement about which events are considered important. Alternatively, it may be highly structured by the use of coded schedules that guide attention to specific types of event. The categories that are selected will be those where changes are expected as a result of training, or those that are thought to be particularly important to the success of the Role. Unstructured observations should be avoided. Use pre-determined criteria to increase the reliability and validity of the data collected. Advantages and disadvantages of observations. Observation of procedure is important in the areas of skills training and relates particularly to the areas of speed, sequencing, manual dexterity and safety. As with questionnaires and interviews, to be effective, observations require formal structure in the form of an observation schedule. The advantages and disadvantages of gathering data by observation are highlighted as follows:"
  },
  {
    "id": "9b9794c4-3156-4804-b6f8-13668ec5a275",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Advantages:",
    "content": "Direct experience can be utilised. Real time analysis. Can be done without co-operation of operator. Whole situation of activity is included. Activity is placed in context - aids understanding."
  },
  {
    "id": "8e0c24d3-829c-44f2-8f91-31dcec50e18a",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Disadvantages:",
    "content": "May lack objectivity - influenced by perception. Potential blizzard of information. May concentrate on unrepresentative individual(s). False performance - operators aware of being observed. Time intensive."
  },
  {
    "id": "31c3e663-04a2-4e8f-9b60-a369134bc5ce",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Reports/logs",
    "content": "Training reports. These should cover an ex-trainee’s Role performance and should be completed by the employing officer/line manager. Reports should be structured if they are to be of value. Examples of training reports are: RN: Form S3018. Army: Training Deficiency Reports. RAF: Training Improvement Form (TIF). Open-ended reports. Open-ended report forms may be administratively feasible, but may suffer from lack of relevance, as the type of comment(s) required may not be clear to a reporting officer. In addition to which they may lack comprehensiveness, due to limitations of space and time. They are usually fragmentary and often misguided. Report forms using rating scales are designed to direct the reporting officer’s attention to specific behaviours. This enables reports of different supervisors to be accurately quantified. The main disadvantage of this method is the restriction it places on reporting officers’ freedom of expression, although this can be mitigated by provision of room for open-ended comments. Equipment reports. These can be used to identify equipment malfunctions which may have training implications. Post Exercise Reports (PXRs). These can be used to highlight the application of skills acquired during training in a realistic environment Work records. A study of the tasks carried out can give a reasonably accurate picture of the performance and the standards involved in a Role. Additional records containing details of time taken, lack of skills, incidence of accidents etc can sometimes complement these, which can be pointers towards areas of training deficiency. Log books. The log book can be a valuable source of information. Its main value lies in that it allows a direct comparison to be made between what the ex-trainee is able to do as a result of training and what they are required to do when employed on an operational task."
  },
  {
    "id": "aa974a9b-998e-47be-bf69-bd71bca01cfd",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Analysing Collected Data",
    "content": "Quantitative and qualitative data analysis. Quantitative data by their very nature lend themselves to statistical analysis. However, with qualitative data there may be trends (patterns, themes) present, which could go unnoticed. One of the problems of dealing with qualitative data is the ‘blizzard of information’ that can be reproduced. This can often be unstructured in content and resource intensive in terms of workforce and time to analyse. Such considerations need to be included during initial project management planning. In analysing qualitative data the quality of the analyst must be taken into consideration, as unlike quantitative data analysis where the issues are more readily identifiable, qualitative analysis requires greater degree(s) of interpretation. Analysts must be conscious of the possibility of knee jerk reactions when confronting data for the first time Qualitative data allow a vast amount of (potentially wide-ranging) information to be considered, allowing the respondent to provide depth of feeling over complex issues which may be difficult to elicit by purely quantitative terms alone. That said, in order to obtain a full picture, qualitative data should not be treated in isolation, but should be compared with quantitative data. Triangulation of data. Triangulation is the combination of different data gathering techniques to investigate the same issue and will usually combine both quantitative and qualitative data methods. For example, rather than simply completing a questionnaire in respect of how an individual performs a task, they might also be interviewed and observed conducting the task. The use of questionnaires together with observation, or qualitative with quantitative data gathering techniques, for example, can reduce the chance of distorting the results or introducing bias within the methodology. To that end triangulation allows greater confidence in the research results regardless of the data gathering methodologies applied. Information sources. Collecting data can be gained from a number of different points of view: the Role holders (ex-trainees), the Role holders’ supervisors/line managers and the participant observer. The Role holders can reflect on the adequacy of the training they received; the line managers can comment on their performance when carrying out their Role. The observer can collect first-hand data of the Role holders conducting the Role tasks. Comparing these sources of information enables a more accurate and unbiased method of data gathering. Data combination. The combination of different data gathering techniques to investigate a particular issue usually is a combination of both qualitative and quantitative methods: Triangulation of analysts. This uses 3 or more analysts to look at the same set of data independently. If similar findings come from all analysts then it is likely that objectivity is being applied. Triangulation of data. This involves 3 or more types or sets of data and subject them to the same analytical procedures. For example, if interview notes, questionnaire responses and observation notes produce similar findings it is likely that the analytical process is being applied objectively. Triangulation of target population. This concerns 3 or more types of target population. For example, the ex-trainees, their immediate line managers/supervisors, commanding officers and trainers. If similar findings are produced it is highly likely that an objective picture has been achieved."
  },
  {
    "id": "8eef6cc1-9470-4d54-b2cc-2d606b2fbd7f",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Data Coding",
    "content": "Requirement. Some form of coding (grouping, classification) is required before analysis can begin identifying themes: All information needs to be read thoroughly to obtain a clear picture of the main issues. Themes/patterns/trends need to be identified and clearly highlighted. Repeated instances of these themes need to be recorded in the form of ‘tallys’. These ‘tallys’ can then be recorded as numerical responses allowing follow-on statistical analysis to take place."
  },
  {
    "id": "09abc25e-0ae8-4593-b2c1-4e80f3a648e6",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Coverage",
    "content": "This DTSM supersedes all previous DTSMs on Governance of Individual Training The totality of DTSMs included in the DTSMs Suite, of which this document is a part, are listed on the DTSMs SharePoint site."
  },
  {
    "id": "2b8902bb-5637-46ae-a361-539c94fc3b8e",
    "document": "DTSM 5 Evaluation of Individual Training 2023 Edition V1.0.docx",
    "section": "Document Editions / Versions",
    "content": "Annual editions of this DTSM will be published every December in time for upcoming year relevant to the DTSM. Throughout the year, different versions of the current edition may also be published. When every new edition is published, the versions will reset to 1."
  },
  {
    "id": "a8019e36-f9f6-4cb7-959e-8cd3b7ddf93c",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Uncategorised",
    "content": "HS 1.004 Skill Fade Competence Retention Analysis Handbook THE INVESTIGATION WHICH IS THE SUBJECT OF THIS REPORT WAS INITIATED BY THE PROGRAMME AND DELIVERY DIRECTORATE DSTLAND WAS CARRIED OUT UNDER TERMS OF CONTRACT NO. DSTL/AGR/01035/01. Reference\tO-HSSRC-1.004-029 Version\t3 Date\t07 April 2022 © BAE SYSTEMS (2022) This document is supplied in confidence to MOD in accordance with Contract No . DSTL/AGR/01035/01. The document comprises information proprietary to BAE SYSTEMS and CRANFIELD UNIVERSITY and whose unauthorised disclosure would cause damage to the interests of BAE SYSTEMS and CRANFIELD UNIVERSITY. The document is supplied to MOD as a FULL RIGHTS VERSION under the terms of DEFCON 705 (Edn 11/02) and, except with the prior written permission of BAE SYSTEMS, MOD’s rights of use and dissemination in the document are limited to UK government departments and to service providers as set out in Clause 12 of DEFCON 705 (Edn 11/02) for the use of FULL Rights Versions of Technical Deliverables. Requests for permission for wider use or dissemination should be made to BAE SYSTEMS. OFFICIAL ALL RECIPIENTS OF THIS REPORT ARE ADVISED THAT IT MUST NOT BE COPIED IN WHOLE OR IN PART OR BE GIVEN FURTHER DISTRIBUTION OUTSIDE THE AUTHORITY WITHOUT THE WRITTEN APPROVAL OF THE DSTL HSSRC PROJECT MANAGER, DSTL, PORTON DOWN, SALISBURY WILTS SP4 OJQ. Contents List of Figures Figure 1 – Updated CRA-T process steps\t3 Figure 2 – Indication of your current location within the process of CRA\t3 Figure 3 – Retention Levels for each of the nine psychological domains\t12 Figure 4 – Example of a simple task – ‘Ironing a shirt’\t32 Figure 5 – Mental model for the complex task, ‘Manage own bathroom renovation’\t34 Figure 6 – Mental model for the task, ‘Carry out actions on arriving at an emergency incident involving Aircraft’ as an example of a fully integrated complex cognitive task\t35 Figure 7 – UDA retention curves for different psychological domains\t37 Figure 8 – Indicative retention bandings\t38 Figure 9 – Revised Taxonomy of Psychological Knowledge and Skills Domains\t40 Figure 10 – Psychological domains underpinning RAF Firefighter role: ‘Incident Commander – Respond to an incident’. (Note: D-M = Decision-Making)\t42 Figure 11 – UAS Pilot Task: ‘Control the payload’. (Note: D-M = Decision-Making)\t43 Figure 12 – RAF Firefighter Task: ‘Incident Commander – Respond to an incident’. (Note D-M = Decision-Making)\t44 List of Tables Table 1 – Example Learning Scalar\t6 Table 2 – Psychological Knowledge Domains with descriptions and task examples\t7 Table 3 – Psychological Skill Domains with descriptions and task examples\t8 Table 4 – Example of matching a subtask/EO to a psychological domain when the same psychological domain is matched to all task elements/KLPs\t13 Table 5 – Example of matching a subtask/EO to a psychological domain where a combination of psychological domains are matched to task elements/KLPs that are performed separately. (Note D-M = Decision-making)\t13 Table 6 – Example of matching a subtask/EO to the Integrative domain where a combination of coordinated psychological skill domains are matched to task elements/KLPs that are performed concurrently. (Note D-M = Decision-making)\t14 Table 7 – Complete Learning Scalar with subtasks/EOs and task elements/KLPs matched to the psychological domains. (Note D-M = Decision-making)\t14 Table 8 – Mapping generic psychological knowledge and skill domains to indicated retention levels after considering frequency of application\t17 Table 9 – Learning Scalar example with subtasks/EOs matched to psychological domains and frequency, with indicated retention levels\t19 Table 10 – Three levels of criticality\t20 Table 11 – Learning Scalar example with output from Step 1 to Step 4\t21 Table 12 – General factors influencing retention of knowledge and skills in all psychological domains\t22 Table 13 – Additional factors influencing physical and simple cognitive skills retention\t24 Table 14 – Factors which influence implicit knowledge and complex cognitive skills retention\t28 Table 15 – Key with symbols for dimensions of complexity\t33 Table 16 – Example of a complete Learning Scalar with output from Step1 to Step 5\t37 Table 17 – Template for recording CRA-T Output\t36 Table 18 – Definition of retention levels\t38 Acronyms & Abbreviations Definitions Introduction"
  },
  {
    "id": "9e6a302b-4057-4733-80e8-a393e5ba23c1",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "1\tCompetence Retention Analysis",
    "content": "For the purpose of this handbook, competence retention is defined as “the knowledge, skills and underpinning attitudinal dispositions that must be acquired and maintained by individuals in order to effectively perform tasks to a pre-defined standard of proficiency”. Competence Retention Analysis (CRA) is a scientific methodology developed as a practical approach to predicting the retention of different knowledge and skills that underpin military tasks at the workforce level. CRA is intended to assist Defence to reduce the impact of skill fade and enhance competence retention. It is relevant to two audiences as follows: Training analysts can use the outputs of CRA during the Training Needs Analysis (TNA) process to justify training solutions and the training budget; and Training designers can use the outputs of CRA during the design phase to inform the scheduling of refresher training or practice intervals, and during the development of training to mitigate knowledge and skills fade. CRA can also be used retrospectively to improve training design and to inform decision- making about the specification of training priorities (initial and refresher), where issues are identified during the TNA evaluation process. This CRA handbook replaces the Defence Human Capability Science and Technology Centre (DHCSTC) Task Identification Number (TIN) 2.057 CRA User Guide (Cahillane, MacLean & Webb, 2015) to incorporate new insights into the retention of different types of current and future knowledge and skills over time. These insights were established during a programme of research commissioned by the Defence Science and Technology Laboratory (Dstl), through the Human and Social Sciences Research Capability (HSSRC) framework (Cahillane et al., 2020). A summary of what has changed within the Competence Retention Analysis Technique (CRA-T) and why, is presented in Section 1.2. Gaps in the science related to the CRA-T are covered in Section 1.3."
  },
  {
    "id": "07afc43f-7115-484f-9fce-db43755292cf",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Section 2 provides step-by-step guidance on how to conduct CRA, along with an overview of influencing factors that can be considered in training design to improve knowledge and skills retention.",
    "content": "Further detail on competence retention key concepts, including new insights is provided in Section 1."
  },
  {
    "id": "0d6719bd-19d9-4e39-9d34-ab7424c8d1e6",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "What Has Changed and Why?",
    "content": "This section summarises the updates made to the CRA-T and the rationale for these changes. The terms ‘skill’ and ‘task’ that were introduced in the original CRA User Guide, often caused confusion because they were considered interchangeable. In order to avoid this confusion, the terms, as used in this handbook, are defined as follows: Task refers to what needs to be done, i.e., performed, or executed mentally or physically; and Skill refers to the psychological capability that supports performance or execution of the task. These psychological capabilities are organised into domains. The taxonomy of psychological knowledge and skill domains has been updated to include complex cognitive skills and implicit knowledge. The original taxonomy in the User Guide only considered simple cognitive skills and explicit knowledge. Simple cognitive skills are known to decay more rapidly, whilst the science to date indicates complex cognitive skills are better retained. The updated taxonomy of psychological knowledge and skill domains in this handbook aligns with advances in the science and reflects the knowledge and skills considered important by Defence, today and in the future, given emerging roles. Understanding the retention of knowledge and skills is important to Defence because knowledge and skills are retained at different rates over time. These insights can inform training design and delivery and the setting of refresher training intervals. The CRA-T approach has been updated to allow combinations and integrations of knowledge and skills to be considered. The original approach involved decomposing a task into subtasks and identifying the ‘predominant psychological domain’ for each subtask. This approach failed to acknowledge that the predominant domain is not always that which is most susceptible to skill fade. It also prevented identification of where combinations of two or more domains underpin subtasks or where skills are integrated. In this handbook, CRA now requires decomposition of a task/Training Objective (TO) into subtasks/Enabling Objectives (EOs) and task elements/Key Learning Points (KLPs). Decomposing tasks down to the task element/KLP level enables a detailed identification of the knowledge and skills needed for an adequate understanding of the task. By doing so, it becomes possible to identify the psychological domain most susceptible to decay and map that to the subtask/EO, rather than the predominant domain. The CRA-T considers other factors, including task frequency, which may affect the retention of the knowledge and skills that underpin task performance. These additional factors have been updated to include those known to moderate the acquisition and retention of complex cognitive skills and implicit knowledge. Guidance for training designers and trainers on competence acquisition and retention have been updated to include those relevant to complex cognitive skills and implicit knowledge. Guidance on factors known to influence the acquisition and retention of complex cognitive skills and implicit knowledge is included, along with relevant training strategies that improve their acquisition and retention. This will enable more efficient and effective training to be developed for complex tasks."
  },
  {
    "id": "5e4b1b59-9e91-4503-920f-406b0992566d",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "What is Not Known?",
    "content": "While complex cognitive skills and implicit knowledge are now included in the updated taxonomy of psychological knowledge and skills domains, their retention levels cannot be included in this handbook due to insufficient scientific evidence being available. However, guidance is provided in a Top Tips document for the Planning, Conduct and Analysis of Future Skill Fade research (Cahillane & Anderson, 2021), to support the collection of longitudinal empirical evidence if required."
  },
  {
    "id": "42aaf335-2df0-4314-aa25-8b24f3eb5b4a",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Guidance – What is the Competence Retention Analysis Technique For?",
    "content": "The CRA-T provides an indicative model of knowledge and skill retention, which may be exploited to give practical, usable advice and quick wins to optimise competence retention. It also provides training design and delivery options for competence acquisition and retention. The early development of the CRA-T was underpinned by best practice from the scientific literature and an existing predictive model of skills retention known as the User Decision Aid (UDA) (Rose, Radtke et al., 1985; see Appendix B for background on competence retention key concepts). The CRA-T process has since been updated with reference to new insights from the science and from Defence and Security case studies (Cahillane et al., 2020). The CRA-T can be used to indicate the percentage of a workforce (e.g., a unit) which will remain competent after a specified period of non-practice or application, based on the types of skills and knowledge that are characteristic of their job or task. This allows the operational readiness of a workforce to be estimated. The CRA-T is flexible in that it can be applied as part of the Defence Systems Approach to Training (DSAT) TNA (JSP 822, 2021) and/or training design stages, or independently. It also complements Difficulty, Importance and Frequency (DIF) analysis. Steps 1 to 4 of the CRA-T are required if individuals wish to know more about the retention of knowledge and skills within subtasks/EOs and wish to specify evidence-based refresher training intervals and priorities. Step 5 is relevant if individuals wish to apply the CRA-T output to identify relevant training design and delivery options to improve competence acquisition and retention. This step is most appropriate for those responsible for the design of a training pipeline, or in the delivery of training, for those with an interest in understanding training design and delivery approaches for optimal acquisition and retention of knowledge and skills. Using the output of Step 2, Step 3 and Step 4, it is possible to consider training design and delivery options for optimising both the acquisition and retention of the knowledge and skills required."
  },
  {
    "id": "99cd069e-fa84-4fe9-80f4-0b959f26a93f",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Guidance – What the Competence Retention Analysis Technique Does Not Do",
    "content": "The CRA-T provides a method to identify how long knowledge and skills will be retained if they are not applied or practised, but it does not consider attitudes because these do not decay over time. The CRA-T does not indicate retention beyond 12 months of non-practice or application. The CRA-T can be applied to individual tasks at the workforce level but cannot indicate retention for individual tasks at an individual level. Therefore, the CRA-T cannot be used to identify the point at which an individual’s task performance would fall below a set level. ‘The Predictive Performance Equation (PPE)’, is a potential alternative to CRA (Peebles, 2020). The PPE can predict individual performance over periods ranging from days to months and can therefore support training designers in tailoring refresher training to an individual’s particular requirements. Application of the PPE is likely to be most suitable for specialised training courses, where an understanding of individual requirements for refresher training is needed. See Peebles (2020) for information on the type of training or performance data that is required to make use of the PPE. The CRA-T cannot indicate retention for collective tasks since it does not consider the full range of factors that moderate the retention of collective skills."
  },
  {
    "id": "a2c96213-0b36-41cc-8d7b-295427738bbe",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Revised Competence Retention Analysis Technique Process",
    "content": "This section summarises the structure of the updated CRA-T process, which comprises five steps as depicted by the presence of arrows shown in Figure 1. Figure 1 – Updated CRA-T process steps Each step in the updated CRA-T process is briefly described below: Step 1: Develop a clear understanding of the task. The level of analysis is at the whole task level, starting with the task/ TO and decomposing it into the subtasks/ EOs and task elements/ KLPs; Step 2: Match task elements/KLPs and subtasks/EOs to psychological domains. This step looks at the task elements/KLP psychological domain mapping first and then maps the subtask/EO to a psychological domain; Step 3: Consider frequency of application and assign retention level at the subtask/EO level of analysis; Step 4: Consider subtask/EO criticality; and Step 5: Use the CRA-T output in training design and delivery. This step considers additional influencing factors that can affect acquisition and retention. It supports the identification of training design and delivery options for very critical and/or moderately critical subtasks/EOs. A dark blue arrow, similar to the example in Figure 2, is used in this handbook to indicate your location within the CRA-T process. Figure 2 – Indication of your current location within the process of CRA There is stand-alone guidance in Section 1 on ‘Competence Retention Key Concepts’ which the reader may choose to refer to at any point during the CRA-T process. This section provides background information on how the indicative competence retention model, which is used in the CRA-T process, works. It also summarises background information on the new insights from the science that led to the revised CRA-T process. The output of each step of the CRA-T can be recorded using the template provided at Appendix A."
  },
  {
    "id": "0484f1a1-2a2c-4c83-ba24-13dc79b2ade3",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 1 – Establish a Clear Understanding of the Task",
    "content": "Step 1 of the CRA-T involves establishing a clear understanding of the task. The term ‘Task’ refers to what needs to be completed (i.e., performed, or executed), to meet the operational requirement. This understanding can be achieved when the available training documentation presents a clear description of the task, and the requisite knowledge and skills can be identified."
  },
  {
    "id": "de340087-819d-4187-8902-9841680a458f",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 1 Guidance – How Do I Know If I Have Enough Information of the Right Quality?",
    "content": "The type of training documentation available will depend on the current stage of the DSAT process. Training analysts will have access to, or will develop, the Task Scalar, Role Performance Statement (RPS), and early Knowledge, Skills, and Attitudes (KSA) analysis outputs, generated as part of the Training Gap Analysis (TGA). These provide training analysts with a suitable input to CRA. The Task Scalar provides an understanding of the skills and decomposes high-level tasks into subtasks and task elements. The KSA analysis, which is updated during the design phase of the DSAT process, provides an understanding of the knowledge and skills required to perform the task/job. For the training designer, in addition to the Task Scalar, RPS and early KSA analysis outputs, other relevant training documentation could include the Training Performance Statement (TPS), a Competence Framework (CF), and the Learning Scalar. A DSAT-compliant Learning Scalar decomposes the TO into EOs and KLPs. As more than one type of knowledge and/or skill can underpin an EO, the KLPs will provide the granularity needed to perform CRA and articulate the knowledge and skills required to complete the EOs. Now proceed to perform Step 1."
  },
  {
    "id": "830581c2-2c2e-4f5c-ae58-c798b4a14416",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Perform Step 1 – Establish a Clear Understanding of the Task",
    "content": "The template in Appendix A can be used to record the output of Step 1 of the CRA-T. Step 1 involves establishing a clear understanding of the task. The level of granularity required is determined by that information which provides the clearest understanding of the task or job, in terms of the requisite knowledge and skills. In order to demonstrate the CRA-T process, an illustrative example of a DSAT-compliant Learning Scalar is used throughout this handbook. A clear understanding of the task is achieved by reviewing the scalar, which enables identification of the supporting knowledge and skills needed for the task. Table 1 shows an example of a DSAT-compliant Learning Scalar for the pseudo military task – ‘Plan an Uncrewed Air System (UAS) Mission’. It decomposes the task/TO (presented in brown text) into subtasks/EOs (shown in green text) and task element/KLPs descriptions (displayed in blue text). This type of scalar is sufficient to proceed to Step 2. For training analysts, a Task Scalar with subtasks and task elements would also be sufficient to proceed to Step 2. Table 1 – Example Learning Scalar"
  },
  {
    "id": "2d768089-3170-47cb-b814-dc3f62a15eda",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 2 – Match Task Elements/KLPs and Subtasks/EOs to Psychological Domains",
    "content": "This step involves matching the task elements/KLPs and subtasks/EOs to the psychological domain that best represents the knowledge or type of skill required to perform the task component."
  },
  {
    "id": "ea5e4bb4-a4a2-462f-8e4a-443cd9622b10",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 2 Guidance – What Are Psychological Domains and How Do I Match Them to Task Elements/KLPs and Subtasks/EOs?",
    "content": "A skill refers to the psychological capability that supports performance or execution of the task. These psychological capabilities, along with knowledge, are organised into domains. The psychological domains are higher-level categories against which Joint Service Publication 822 (JSP 822, 2021) job-related KSA analysis can be mapped. They reflect the human psychological processes known to underpin the acquisition and retention of job/task-related knowledge and skills. There are differences in retention between these psychological domains and consequently they influence the extent to which skilled performance of tasks is retained over time. The psychological knowledge domains are Explicit Knowledge and Implicit Knowledge (see Table 2 for definitions and examples). Table 2 – Psychological Knowledge Domains with descriptions and task examples Physical skills fall within the Continuous Psychomotor and Discrete Psychomotor domains. Simple cognitive skills fall within the Procedural and Simple Decision-making domains, whilst complex cognitive skills fall within the Complex Decision-making, Adaptive Cognition, and Integrative domains. The Integrative domain is a meta-skill involving the integration of two or more coordinated psychological skill domains that are performed concurrently rather than separately, along with underpinning explicit and/or implicit knowledge (see Table 3 for definitions and examples). Table 3 – Psychological Skill Domains with descriptions and task examples The mapping of knowledge and skills, represented by the task elements/KLPs and subtasks/EOs, to one of these psychological domains is important because the ability to retain these types of knowledge and skills varies. Figure 3 presents the levels of retention for the different psychological domains, which are underpinned by the science (see Appendix B for more detail). The retention levels are categorised into a practical traffic light system of three retention levels: GREEN (High Retention: 12 months), AMBER (Moderate Retention: 5 months) and RED (Low Retention: 2 months). GREY (Not Known) is used for implicit knowledge and the complex cognitive psychological skill domains, as a retention level cannot yet be assigned due to insufficient scientific evidence. Although insufficient, the available evidence suggests implicit knowledge and complex cognitive skills are retained for 6 months. Figure 3 – Retention Levels for each of the nine psychological domains In order to match each task element/KLP and subtask/EO to the psychological domain whic h best represents the knowledge or type of skill required to perform it, it is important to read and understand the psychological knowledge domain definitions in Table 2 and the psychological skill domain definitions in Table 3. Note that for complex tasks, all or some of the subtasks/EOs may involve two or more psychological skill domains at the task element/KLP level that are activated at the same time. That is, the task elements/KLPs are performed concurrently, rather than separately, and must therefore be coordinated and integrated. Where this is the case, these subtasks/EOs should be mapped to the Integrative domain."
  },
  {
    "id": "b714b976-1e6e-493d-a1f9-81c7c57381c5",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Perform Step 2 – Match Subtask/EOs to Psychological Domains",
    "content": "The output of CRA-T Step 2 should be recorded using the template in Appendix A. When performing Step 2, look at the scalar and the psychological knowledge and skill domain definitions (see Table 2 and Table 3) and match the task elements/KLPs and the subtasks/EOs to the psychological domains. Considering the action verb used to describe the task elements/KLPs and subtask/EOs will help in mapping to the correct psychological domains. For example, the action verb ‘Describe’ indicates the Explicit Knowledge domain underpins performance. However, the action verb may not always provide a clear and practical indication of the psychological knowledge or skill domain being applied in the conduct of the task element/KLP or subtask/EO. For example, ‘Manage’ could indicate the Procedural skills or Simple Decision-making skills domain. Therefore, Subject Matter Expert (SME) knowledge of the task/job role is needed in order to best match task elements/KLPs and subtasks/EOs to the psychological domains. In some cases, it may also be necessary to look at the steps (i.e., the next level of granularity below the task element/KLP) to better inform understanding of the domains required at the task element/KLP level. Mapping should start with the task elements/KLPs, as this provides the necessary granularity to inform the subsequent mapping of the subtasks/EOs and, where appropriate, tasks/TOs. Table 4 – Table 6 provide examples of how this mapping should be conducted. Where all task elements/KLPs (i.e., the blue text) are mapped to the same psychological domain, then this domain should also be mapped to the subtask/EO (i.e., the green text) (see Table 4). Table 4 – Example of matching a subtask/EOto a psychological domain when the same psychological domain is matched to all task elements/KLPs Where task elements/KLPs are mapped to a combination of psychological domains, but they are performed separately, then the psychological domain that is most susceptible to decay should be mapped to the subtask/EO. For example, although Explicit Knowledge is the predominant domain in the example at Table 5, it is the Procedural skills domain required for the 1.2.3 and 1.2.6 tasks elements/KLPs that is the most susceptible to skill fade. As can be seen in Figure 3, procedural skills have a low (RED) level of retention. Therefore, the subtask/EO is mapped to the Procedural skills domain. Table 5 – Example of matching a subtask/EO to a psychological domain where a combination of psychological domains are matched to task elements/KLPs that are performed separately. (Note D-M = Decision-making) Where task elements/KLPs match a combination of two or more different psychological skill domains (note that this does not include the Knowledge domains) that are performed concurrently (i.e., integrated), the Integrative domain is matched to the subtask/EO as illustrated in Table 61. Here, the Integrative domain is responsible for managing attention to effectively coordinate the other psychological skill domains that underpin performance of this subtask/EO. As can be seen in the example at Table 6, this includes the Procedural skills, Simple Decision- making and Complex Decision-making domains. For this subtask/EO, procedural skills are essential and fully 1 Not all psychological skill domains have to be concurrent. A minimum of two concurrent psychological skill domains are required for the integrative domain to be involved. integrated (i.e. performed concurrently) with simple and complex decision-making to form a functioning and unified whole, hence they are integrated. Table 6 – Example of matching a subtask/EOto the Integrative domain where a combination of coordinated psychological skill domains are matched to task elements/KLPs that are performed concurrently. (Note D-M = Decision-making) Table 7 illustrates the full DSAT-compliant Learning Scalar for the pseudo military UAS Mission Planning task, with subtasks/EOs and task elements/KLPs matched to the psychological domains. This will be used as the exemplar in Step 3 of the CRA-T process onwards. Table 7 – Complete Learning Scalar with subtasks/EOs and task elements/KLPs matched to the psychological domains. (Note D-M = Decision-making) In Table 7, only one of the subtasks/EOs (1.3) is mapped to the Integrative domain, where the management of attention is required to effectively integrate and coordinate Procedural skills with Simple and Complex Decision- making. The remaining subtasks/EOs are mapped to the Procedural domain. In Table 7, the psychological domains are mapped to the task elements/KLPs and then to the subtasks/EOs but not to the task level. Where all subtasks are not mapped to the same psychological domain, the Task/TO cannot be mapped to a psychological domain because a combination of psychological domains is involved in performance of the Task/TO. In such cases only the task elements/KLPs and then the subtasks/EOs can be mapped to a psychological domain. In cases where all subtasks/EOs are mapped to the same psychological domain, thenthe Task/TO (i.e., the brown text level) should also be mapped to that domain. This single domain, as opposed to a combination, determines retention at the task level. For example, in cases where all subtasks/EOs are mapped to the Integrative domain, then the Task/TO (i.e., the brown text level) should also be mapped to the Integrative domain. Where this is the case, the Integrative domain acts as a psychological ‘meta-skill’ and is responsible for managing attention to effectively integrate and coordinate the other psychological skill domains that underpin performance of each subtask/EO, along with any underlying explicit knowledge."
  },
  {
    "id": "df35fd8d-d6e5-4576-ad00-f457c5dc0f73",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 3 – Assign Retention Level to Subtasks/EOs",
    "content": "The output of Step 3 can inform decisions on refresher training interval specification or priorities. This output can also support training designers in the refinement of DIF analysis training categories."
  },
  {
    "id": "0b144a9c-93df-4316-b4ca-b9c1c596bc13",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 3 Guidance – How Does Frequency of Application of Subtasks/EOs Affect Retention? What Are Retention Levels?",
    "content": "The purpose of Step 3 is to consider the impact of how often subtasks/EOs are performed on the retention of knowledge and skills. This is because the frequency with which knowledge and skills are practised can moderate the rate at which they fade over time. As an example, a subtask/EO mapped to the Procedural skills domain would be expected to have a low level of retention in comparison to other psychological domains (refer to Figure 3). However, Table 8 demonstrates how frequency of application moderates the alignment of psychological domains to a particular retention level. It uses the same traffic light system as Figure 3: GREEN meaning high retention (greater than 50% of workforce competent after 12 months non-practice); AMBER meaning moderate retention (50% of workforce competent after 5 months non-practice); and RED meaning low retention (50% of the workforce competent after 2 months non-practice). Therefore, if the same subtask/EO mapped to the Procedural skills domain was performed very frequently, the expected retention level would be moderate, rather than low. Information on the frequency with which subtasks/EOs are performed can be obtained from the DIF analysis, which is gathered during the TNA. If a TNA/DIF analysis is not available, then SME judgement should be used. Table 8 – Mapping generic psychological knowledge and skill domains to indicated retention levels after considering frequency of application *Very Frequent: More frequent than once every 2 months . *Moderately Frequent: Between once every 2 months and once every 5 months . *Infrequent: Once in a period greater than 5 months . *Not Known: Available evidence is insufficient but suggests 6 months . Given the current level of validation for the CRA-T, the retention levels in Table 8 are fixed at the 50% point and cannot be adjusted. Therefore, the low (RED), moderate (AMBER) and high (GREEN) retention levels and their respective definitions should be considered as indicative of when refresher training is required and not conclusive. For example, the final column of Table 8 indicates that procedural skills that are practised infrequently need to be refreshed after 2 months of no practice. For more information see Appendix B, Section B.3. Note that the GREY retention level is used for implicit knowledge and the three complex cognitive skills (i.e., the Complex Decision-making, Adaptive Cognition, and the Integrative Domains). A retention level cannot yet be assigned to these complex skill domains due to insufficient scientific evidence. Although insufficient, the available evidence suggests implicit knowledge and complex cognitive skills are retained for 6 months. Proceed to perform Step 3."
  },
  {
    "id": "aa0dcc25-734f-44ae-802a-2a9c5f084ae4",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Perform Step 3 – Consider Frequency of Application and Assign Retention Level",
    "content": "The output of Step 3 of the CRA-T should be recorded using the template in Appendix A. In order to address frequency as a moderator of retention, it is necessary to know the frequency at which each subtask/EO will be performed (see column 3 of Table 8). Note that task elements/KLPs are integral components of subtasks/EOs and therefore these should be at the same frequency as the subtasks/EOs. Consequently, frequency is considered at the subtask/EO level rather than the task element/KLP level. Having allocated a frequency to each subtask/EO, an indicative retention level for each subtask/EO can be identified by using the information in Column 4 (the CRA Retention Level) of Table 8. The outputs of the analysis conducted in Step 3 so far will look like Table 9. Table 9 – Learning Scalar example withsubtasks/EOs matchedto psychological domains and frequency, with indicated retention levels"
  },
  {
    "id": "620d643d-d66b-4d18-b82d-3cf9ea2533d7",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 4 – Consider Subtask/EO Criticality",
    "content": "The output of Step 4, criticality analysis, is an SME judgement about subtask/EO criticality. Criticality in this context refers to the impact of an inadequately performed subtask/EO on operational capability and safety. Subtask/EO criticality does not affect retention levels; however, subtask/EO criticality analysis should be completed to identify the risks carried with regards to the susceptibility of the subtasks/EOs to knowledge and skills fade. This can support training designers by informing the refinement of the initial training categorisation and the allocation of limited training resources."
  },
  {
    "id": "671b8a7a-eff1-482e-993b-7de4ac9a20fc",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 4 Guidance – What is Subtask/EO Criticality and How Should I Consider the Knowledge and Skills Fade Risk Held?",
    "content": "Criticality analysis is informed by the importance of the subtasks/EOs as identified by the DIF analysis. This analysis enables the consideration of the relative criticality of each subtask/EO to performance of the overall task/job. Although a subtask/EO may be matched to a low retention level, if it is deemed not critical then the risk to overall job performance is reduced. Table 10 presents the three criticality levels and their associated impact. Table 10 – Three levels of criticality"
  },
  {
    "id": "8db01b9b-86ad-4e90-8ad7-a01db20c3ac0",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Perform Step 4 – Match Subtasks/EOs to a Criticality Level",
    "content": "The output of Step 4 should be recorded using the template in Appendix A. Assign a criticality level to each subtask/EO. Considering the criticality of successful performance of subtasks/EOs enables the prioritisation of subtasks/EOs when making decisions regarding the allocation of resources to refresher training and/or the design and delivery of training. The output of the analysis conducted up to Step 4 so far will look like Table 11. Within this example, four out of the five subtasks/EOs are very critical in terms of their successful performance. Although the subtask/EO 1.5 is underpinned by the Procedural domain and has a low retention level, it is deemed not critical. Therefore, the risk of skill fade to overall job performance is reduced. This subtask/EO would be of a lower priority in terms of training design and the allocation of resources/ frequency of refresher training required to maintain subtask/EO proficiency. To perform a final check of the indicative retention intervals, proceed to Step 5 to consider other factors, in addition to frequency, which may affect knowledge and skills retention. Step 5 should only be performed on the subtasks/EOs identified as very critical and/or moderately critical. Table 11 – Learning Scalar example with output from Step 1 to Step 4"
  },
  {
    "id": "8fab5c27-450f-494f-8fcb-5ba49c874752",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 5 – Use of Competence Retention Analysis Technique Output in Training Design and Delivery",
    "content": "Step 5 is about considering other factors, in addition to task frequency, which may influence the retention of the knowledge and skills that underpin the very critical and/or moderately critical subtasks/EOs identified in Step 4. Considering how these influencing factors can be addressed within training design and/or delivery supports the management and retention of knowledge and skills."
  },
  {
    "id": "d6736377-22d1-46a1-b4e5-c0da8c22d83b",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Step 5 Guidance – What Additional Influencing Factors Should I Consider and How Do They Affect Retention?",
    "content": "It is necessary to have an understanding of the context in which a task is conducted in order to effectively consider the additional influencing factors. The Conditions and Standards associated with the list of Performance Objectives should be articulated within the RPS. This information can be used as a supporting input to Step 5."
  },
  {
    "id": "27b5f2ca-dcbe-4580-a623-22ea225d5538",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "General Factors Influencing Knowledge and Skills Retention.",
    "content": "Table 12 presents general factors that can influence the retention of knowledge and skills in all psychological domains. Table 12 – General factors influencing retention of knowledge and skills in all psychological domains In addition to general influencing factors listed above, there are specific influencing factors, included below, relevant to explicit knowledge, physical and simple cognitive skills and those which are applicable only to implicit knowledge and complex cognitive skills. If the very critical and/or moderately critical subtasks/EOs are limited to explicit knowledge, physical skills and/or simple cognitive skills, go to Section 2.5.3. This section covers additional influencing factors matched to the relevant psychological domain(s). If the very critical and/or moderately critical subtasks/EOs retention only involve implicit knowledge and complex cognitive skills, go to Section 2.5.4. Go to both Section 2.5.3 and Section 2.5.4 if the very critical and/or moderately critical subtasks/EOs involve a mix of physical and/or simple and complex cognitive skills."
  },
  {
    "id": "bb2fb653-6652-46a8-9a49-2f6b5b95f9ea",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Additional Factors Influencing Physical and Simple Cognitive Skills Retention",
    "content": "Table 13 presents additional factors known to influence the retention of explicit knowledge, physical and simple cognitive skills, with each factor matched to the relevant psychological domain(s). The effect on retention is also presented. The retention of these knowledge and skills relies heavily on job holders being able to hold a lot of information, procedures and/or stepped decisional processes in working memory. The effect of the factors on retention, matched to the psychological domain underpinning the very critical or moderately critical subtask/EO, should be considered. It is necessary to have an understanding of the context in which a subtask/EO is conducted in order to effectively consider where these influencing factors could be designed into training to maximise retention. For example, where a well-designed and mandated job aid exists for a subtask/EO that was originally matched to the Procedural or Simple Decision-making domain in Step 2, then the subtask/EO may now be remapped to another domain as appropriate. This is because memory for the procedures, or stepped decisional processes, which are now represented by the job aid is no longer required. For example, the subtask/EO mapped to the Procedural domain in Table 5 would now be remapped to the Explicit Knowledge domain. Subtasks/EOs matched to the Explicit Knowledge psychological domain have a high (GREEN) level of retention regardless of frequency (see Table 8). Table 13 – Additional factors influencing physical and simple cognitive skills retention 2 Scaffolding is an instructional approach, where learners complete manageable tasks which progress in difficulty. Trainers demonstrate the task at each stage and explain the steps. Learners are provided with the opportunity to practise at eachstage."
  },
  {
    "id": "5eafa7d0-9bc6-4991-a93f-bf76c5ca0cdf",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Factors Influencing Implicit Knowledge and Complex Cognitive Skills Retention",
    "content": "Advances in science have identified factors that can influence the retention of implicit knowledge and complex cognitive skills (e.g., the Complex Decision-making, Adaptive Cognition, and Integrative domains). These are presented in Table 14, including their effect on retention. It is necessary to have an understanding of the context in which a subtask/EO is conducted. Therefore, a panel of SMEs should consider how these factors can be integrated into training design and delivery. The Conditions and Standards associated with the list of Performance Objectives should be articulated within the RPS and this information can be used as a supporting input to Step 5. Implementation of these influencing factors will support the management of implicit knowledge and complex cognitive skills retention. Table 14 – Factors which influence implicit knowledge and complex cognitive skills retention"
  },
  {
    "id": "8cd7cf84-cfc7-4795-8dcd-f79b625261c4",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Developing Graphical Representations of Task Mental Models",
    "content": "The acquisition and retention of implicit knowledge and complex cognitive skills that underpin complex tasks is enhanced by the development of a strong mental model. A mental model is a mental representation of a task, which captures how it is understood or conceptualised and performed. It includes an understanding of the task components and the purpose(s) of the whole task and its subtasks/EOs, the conceptual relationships between subtasks/EOs, and how they work together during performance of the whole task. Developing a strong mental model is a key factor influencing the acquisition and retention of implicit knowledge and complex cognitive skills. This is because a strong mental model provides the conceptual ‘glue’ required to bind subtask/EO components (i.e., task elements/KLPs) in long-term memory. It also aids the encoding of task complexity. The positive effect on retention of the other influencing factors summarised in Table 14, is dependent on the acquisition of a strong mental model. Mental models enable trainees to mentally acquire, organise and retain a wide range of task types from the simple to the complex. The more complex the task, the more important it is for the mind to be able to develop, retain and update the mental model for the task. In general, individuals are not conscious of their task mental models and do not explicitly articulate them. However, mental models for any task can be explicitly articulated through analysis to identify what has to be learned. By analysing the mental model, the conceptual relationships between the subtasks/EOs can be identified. These can then be specified as additional KLPs and incorporated into the training design and delivery. It is important to note that these KLPs would not have been identified using traditional KSA analysis techniques. The external representation of a task’s mental model can be captured graphically to enable visualisation of complexity. The external representation enables visualisation of the conceptual relationships between the subtasks/EOs listed and detailed in the Task/Learning Scalar. These relationships represent the task concept and where, when, and how subtasks/EOs work together during whole task performance. The greater the number of relationships, the more complex the task. Having identified the complexity of the task, training can be designed to support acquisition and retention of complex tasks. If this is done successfully, the jobholder will have acquired the strong, subconscious, mental representation of the task required for proficient performance; however, job holders should not be expected to describe their mental model. Simple tasks are underpinned by physical and/or simple cognitive skills and involve discrete subtasks/EOs that are performed separately. Such discrete subtasks/EOs can be performed in isolation from each other and there are no conceptual relationships between them. For example, Figure 4 shows the simple task of ‘Ironing a shirt’. Here, there is a single relationship (i.e., link) radiating out from the whole task to each subtask/EO. To illustrate, setting up the ironing equipment can be conducted independently of thinking about the other subtasks/EOs. Mental models for simple tasks do not need to be made explicit during training. This is because the retention of simple tasks is determined by working memory capacity i.e., memory for procedurals and/or stepped decisional processes. Figure 4 – Example of a simple task –‘Ironing a shirt’ In contrast with simple tasks, complex tasks involve complex cognitive skills. They may also involve physical and/or simple cognitive skills. The subtasks/EOs of complex tasks can be performed separately or concurrently, but conceptual relationships will exist between two or more of the subtasks/EOs. Complex tasks require the acquisition of a strong and flexible (i.e., adaptable) mental model. To support acquisition and retention of a complex task, it is important for training designers to explicitly specify this task mental model. This can be done by developing an external representation, which illustrates the conceptual understanding that has to be developed in the learner through practice. This then allows the training designer to identify the conceptual learning points which will support subconscious acquisition of the task mental model. There are three dimensions to understanding task complexity; component, coordinative, and dynamic complexity: Component complexity of a task is determined by the number of subtasks/EOs and their underpinning task elements/KLPs; Coordinative complexity is determined by the nature of the conceptual relationships between subtasks/EOs. There are two types of conceptual relationship. The first type is coordinated but not integrated (i.e., not performed concurrently). The second type is integrated (i.e., performed concurrently); Dynamic complexity refers to expected input/output changes to one or more subtasks/EOs that may impact whole task performance. The set of symbols in Table 15 can be used to represent component, coordinative and dynamic complexity within a graphical mental model. Training should be designed so that it helps trainees to learn and understand the conceptual relationships between task components (i.e., subtasks/EOs). Doing so will bind the subtasks/EOs in memory, developing the conceptual glue that holds the complex task together. Table 15 – Key with symbols for dimensions of complexity Consider analysing the (non-military) example complex task, ‘Manage own bathroom renovation’. In Figure 5, the central circle represents the whole task, supported by complex cognitive and simple cognitive skills. The central circle is purple as opposed to blue because of the presence of complex cognitive skills, in this case required for three of the surrounding subtasks/EOs (also purple). The blue circles indicate subtasks/EOs that are only supported by simple cognitive skills. Together, the purple and blue circles represent the component complexity of the task. The subtasks/EOs are performed separately. Five coordinated but not integrated (i.e., not performed concurrently) conceptual relationships have been identified between some of the subtasks/EOs, as indicated by the five double-ended single arrows. Figure 5 – Mental model for the complex task, ‘Manage own bathroom renovation’ These coordinated relationships relate to aspects of sequencing, timing, frequency, dependency, or location between pairs of subtasks/EOs. For example, the subtask/EO of Conduct Project Planning is an essential part of a bathroom renovation and begins with the setting the budget (i.e., sequencing) and its ongoing management as the project evolves. Ongoing management requires coordination in terms of timing (budget usually comes first). Managing the Budget is dependent on ongoing adjustments to the project plan, resulting from changes in other subtasks/EO. For example, it may be necessary to cancel the purchase of previously selected materials due to unforeseen delays in the supply chain. Updating the budget as a result of changes to the plan is likely to be frequent, given the component complexity. The timing of the selection and purchase of materials is coordinated with the project plan. If selected materials become unavailable, project planning, and by extension the budget, will have to be updated accordingly. The selection of skilled tradespersons (e.g., plasterer, plumber, electrician, and tiler) relates to the project plan and the budget. This initially involves establishing communication and gathering quotations and estimates. The success of the project plan is dependent on the selection of tradespersons early in the project. Other coordinated subtasks/EOs, i.e., Quality Control and Manage Tradespersons, may highlight the need within the project plan to replace one or more of the initially selected tradespersons, thus reactivating the relationship with the Select Tradespersons subtask/EO. As consequence, the budget may need to be updated. Having selected the tradespersons, their individual tasks will have to be coordinated and managed within the project plan, in terms of sequencing, timing, frequency, dependencies and location. For example, some jobs will have to be done before others: The plumber will need to decommission the old bathroom and cap- off the water pipes before other work can commence and the plasterer will have to complete their work before tiling can begin. Even if there are no dependencies between some activities, the size of the workspace (i.e., location) may determine how many tradespersons can be working at any one time. In order to ensure that the renovation work is being carried out to the standards agreed at the time of selection, the ongoing subtask/EO of Quality Control is coordinated with the Management of Tradespersons. In Figure 5, the outer circle surrounding the task and subtasks/EOs comprises a dotted line with a single dotted line arrow pointing towards the task. With reference to the key to symbols for dimensions of complexity in Table 15, this type of circle and arrow indicates that dynamic complexity is low for this task. There are few expected input/output changes to one or more subtasks/EOs. Thus, the impact on whole task performance resulting from an increase in cognitive demand is correspondingly low. An example of an input change to the ‘Select Tradespersons’ subtask/EO would be where a tradesperson is no longer available. This would result in an adjustment (i.e., output change) to the ‘Conduct Project Planning’ subtask/EO. However, if more dynamic input/output changes to one or more subtasks/EOs were to be expected, the task mental model could be adjusted by using the symbol for high dynamic complexity (see Table 15). Figure 6 illustrates the mental model for the complex task, ‘Carry out actions on arriving at an emergency incident involving aircraft’. It is very different from managing the renovation of a bathroom. Here, the incident commander will be carrying out all of the subtasks/EOs concurrently. The central purple circle represents the whole task, underpinned by complex cognitive skills. The outer purple circles represent subtasks/EOs involving complex cognitive skill domains. In addition to lines radiating from the whole task to each subtask/EO, there are double ended arrows with two lines between all the subtasks/EOs. This illustrates that the subtasks/EOs are integrated (i.e., performed concurrently), thus representing a fully integrated complex cognitive task. [Note that five of the double ended arrows are partially obscured by the central circles representing the whole task]. Figure 6 – Mental model for the task, ‘Carry out actions on arriving at an emergency incident involving Aircraft’ as an example of a fully integratedcomplex cognitive task At the whole task level, the Integrative domain enables the integration of the subtasks/EOs and the coordinated psychological skill domains that underpin them. At the subtask/EO level, the Integrative domain enables the integration of the psychological skill domains that underpin the task elements/KLPs. As all the subtasks/EOs are integrated (i.e., performed concurrently), the task should be practised and assessed at the whole task level. That is, all subtasks/EOs should be brought together and practised as a whole task. This ensures the integrative conceptual ‘glue’, essential for the effective integration of the other psychological skills underpinning task elements/KLPs, is addressed in the design of the training. The mental model in Figure 6 illustrates how multiple, interdependent subtasks/EOs have to be integrated (i.e., performed concurrently) for successful performance of the whole task. The conceptual relationships between subtasks/EOs will become more or less activated during task performance, dependent upon task goals. Any new task inputs to the incident commander will require dynamic changes to the plan. In Figure 6, the outer circle surrounding the task and subtasks/EOs comprises a solid line with three arrows pointing towards the task. As can be seen from the key in Table 15, the dynamic complexity for this task is high. It is highly likely that there will be multiple input/output changes to one or more subtasks/EOs. An example of an input change to the ‘React to environmental impact’ subtask/EO would be where an unpredicted impact on the environment is identified by the incident commander (e.g., hazardous cargo exploding). This would result in an adjustment (i.e., output change) to the ‘Liaise with other agencies’ subtask/EO. Thus, the impact on whole task performance resulting from an increase in cognitive demand is correspondingly high. To enable acquisition of complex tasks, the level of dynamic complexity should be designed into task exercises. Where a task mental model indicates high dynamic complexity, training designers and deliverers should ensure that learners practise responding to multiple dynamic (i.e., unpredictable) input/output changes to one or more subtasks/EOs. Conversely, where low dynamic complexity is indicated, training designers and deliverers should build in some dynamic input/output changes to one or more subtasks/EOs. This will exercise the conceptual relationships between the subtasks/EOs. By building in authentic, meaningful, varied, and unpredictable task inputs/outputs, training designers and deliverers will ensure the conceptual relationships between the subtasks/EOs are strongly bound in memory. How well complex cognitive tasks are acquired and retained is inferred from whole task performance and not the ability of trainees to describe or repeat the structure of the task mental model. Acquisition of strong mental models will enable job holders to respond effectively to dynamic complexity (i.e., new task inputs). If job holders understand the conceptual relationships between subtasks/EOs, they can consider how dynamic input changes to one or more subtasks/EOs may impact whole task performance. In summary, the complete Task/Learning Scalar with subtasks/EOs and task elements/KLPs matched to the psychological domains (i.e., Step 2 output) should be considered by a panel of SMEs to inform the development of the graphical mental model for the complex task. CTA as a supplement to traditional task analysis can support the identification and specification of the conceptual relationships between subtasks/EOs. The conceptual relationships drawn between the subtasks/EOs can then be specified as additional KLPs. These KLPs will make explicit how subtasks/EOs are conceptually related and can be incorporated into initial training. This will promote task meaningfulness, thus inducing more elaborative processing which supports the acquisition and long-term retention of a strong mental model for complex tasks. Proceed to perform Step 5."
  },
  {
    "id": "bf5c8603-4ea8-413c-b303-71a576a5d954",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Perform Step 5 – Identify Relevant Influencing Factors",
    "content": "The output of Step 5 should be recorded using the template in Appendix A. Identify additional influencing factors aligned to the psychological domains matched to the very critical and/or moderately critical subtasks/EOs. The factors identified should be practical options for implementation in training design and delivery. The output of the analysis conducted up to Step 5 will look like Table 16. O-HSSRC-1.004-029 Version 3 / 07 April 2022 Table 16 – Example of a complete Learning Scalar with output from Step1 to Step 5 OFFICIAL Where subtasks/EOs involving complex cognitive skills have been identified, develop a graphical representation of the task mental model. This will provide a visual interpretation of the task’s complexity in terms of its components (i.e., subtasks/EOs) and the conceptual relationships that exist between them. Development of the graphical representation of the task mental model should be undertaken by a panel of SMEs, using: i) the complete Task/Learning Scalar with the subtasks/EOs and task elements/KLPs matched to psychological domains (i.e., Step 2 output); and ii) the symbols for dimensions of complexity (see Table 15). To further support the identification and specification of the conceptual relationships between subtasks/EOs, a CTA can be performed. The first step in developing a graphical representation of a task’s mental model is to draw the central circle representing the whole task, and then the outer circles representing the subtasks/EOs. These circles will illustrate the component complexity of the task. Next, links should be drawn between the subtasks/EOs to explicitly represent the task’s coordinative complexity and define the conceptual relationships, i.e., what conceptually ‘glues’ the sub-tasks/EOs together. The conceptual relationships will either be coordinated (but not integrated) or integrated (i.e., performed concurrently). An outer circle should then be drawn, with the line of the circle and arrows representative of the task’s dynamic complexity and thus the likely occurrence of dynamic input/output changes to one or more subtasks/EOs that may impact whole task performance. The greater the number of task components and conceptual relationships, and the higher the dynamic complexity, the more complex the task. Once the graphical representation of the mental model has been developed, the other factors known to improve retention of implicit knowledge and complex cognitive skills can be designed into training. For example, where integrated conceptual relationships have been identified between all subtasks/EOs because these are matched to the Integrative domain, then the complex task is fully integrated. Consequently, all subtasks/EOs should be brought together and practised and assessed as a whole task. This ensures the conceptual integrative ‘glue’, essential for the effective integration and coordination of the other psychological skills underpinning task elements/KLPs, is fully integrated into the training programme. However, if a complex task is only partially integrated, where some but not all subtasks/EOs are matched to the integrative domain, then it may be possible for some subtasks/EOs to be practised and assessed at the part task level. Having performed Step 5, the revised CRA-T process is now complete."
  },
  {
    "id": "98705096-b3d7-45d7-b02c-49e5a78fbf58",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Summary",
    "content": "As Defence tasks become more cognitively complex, now and in the future, the CRA process provides a simple mechanism for identifying the psychological domains that underpin task and subtask performance. This is important for training designers and deliverers as it helps to identify when different learning approaches must be adopted to ensure both the acquisition and retention of knowledge and skills. Further detail on competence retention key concepts, including new insights into competence retention is provided in Section 1."
  },
  {
    "id": "1af871dc-6a59-4b49-a80f-9cfe43d991bd",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "References",
    "content": "Cahillane, M.A., & Anderson, T. (2021) Top Tips for the Planning, Conduct and Analysis of Future Skill Fade Research. HS1.004 – Costed Option 1. Version 1.0. Cahillane, M.A., Launchbury, C., MacLean, P., & Webb, S. (2013). TIN 2.001 Competence Retention. Final report. DHCSTC_12_T_T2_001_1.1/005. Cahillane, M. A., MacLean, P., Smy, V; Anderson, T., & Caird-Daley, A. (2020). HS 1.004 Skill Fade. Phase 1 Technical Report. O-HSSRC-1.004-010. Cahillane, M., MacLean, P., & Smy, V. (2018). Novel application of a predictive skills retention model to technical VLE content production skills among Higher Education teachers: a case study. Interactive Learning Environments. Doi.org/10.1080/10494820.2018.1474231. Cahillane, M.A., MacLean, P., & Webb, S. (2015). DHCSTC TIN 2.057 Competence Retention Analysis - User Guide. O-DHCSTC_I2_T_T2_057/002a, v4 2015. Cahillane, M.A., & Morin, C. (2012). Skills Retention in a Complex Battlefield Management System: A Pilot Study. Journal of Battlefield Technology, 15 (1), 65-72. ISSN 1440-5113. Cianciolo, A. T., Crabb, B. T., Schaefer, P., Jackson, S., & Grover, J. (2010). Sustainment of individual and collective future combat skills: Modelling and research methods (ARI Research Report 1918). Arlington, VA: US Army Research Institute for the Behavioral & Social Sciences. Available at: https://apps.dtic.mil/sti/pdfs/ADA514991.pdf (Accessed: 18 January 2022). Green, C. S., & Bavelier, D. (2015). Action video game training for cognitive enhancement. Current Opinion in Behavioral Sciences, 4, 103–108. https://doi.org/10.1016/j.cobeha.2015.04.012 (Accessed: 21 January"
  },
  {
    "id": "ef218c84-212b-4868-ac1b-98af320ffd65",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "2022).",
    "content": "JSP 822. (2021). Defence direction and guidance for training and education. Part 2 guidance. V4.1. Klein, G. (1999). Sources of Power: How People Make Decisions (pp. 15-30). Massachusetts Institute of Technology: MIT Press. MacLean, P., Cahillane, M., and Smy, V. (2015). Extension of a knowledge and skills taxonomy to include a complex and integrated skills category. In Proceedings of the International Conference on information Communication Technologies in Education. (pp.246-256).  (Accessed: 04 February 2022). Peebles, D. (2020). HS1.008 Data-Driven Training and Learning for Defence – Innovative Concept Exploration (ICE) Personalised Training Using the Predictive Performance Equation. Theoretical Report . O-HSSRC-1.008- 1-003. Richards, H.J., & Deighton, C. (2019). Skills management and retention. Final report. DSTL/TR114370 1.0. Rose, A., Czarnolewski, M., Gragg, F., Austin, S., Ford, P., Doyle, J., & Hagman, J. D. (1985). Acquisition and retention of soldiering skills. Arlington, VA: (671) US Army Research Institute for Behavioral & Social Science. https://apps.dtic.mil/dtic/tr/fulltext/u2/a160336.pdf (Accessed: 21 January 2022). Rose, A.M., Radtke, P.H., Shettel, H.H, & Hagman, J.D. (1985). User Manual for Predicting Military Task Retention. (Report No. AIR FR 37800) U.S. Army Research Institute for Behavioral and Social Science: Alexandria, VA. https://apps.dtic.mil/sti/pdfs/ADA163710.pdf (Accessed: 06 December 2021). Sanli, E., & Carnahan, H. (2018). Long-term retention of skills in multi-day training contexts: A review of the literature. International Journal of Industrial Ergonomics, 66, 10-17. https://doi.org/10.1016/j.ergon.2018.02.001 (Accessed: 06 December 2021). Stasielowicz, L. (2019). Goal orientation and performance adaptation: A meta-analysis. Journal of Research in Personality, 82, 1-13. https://doi.org/10.1016/j.jrp.2019.103847 (Accessed: 08 December 2021). Villado, A., Day, E., Arthur, W., Boatman, P., Kowollik, V., Bhupatkar, A., & Bennett, W. (2013). Complex command-and-control simulation task performance following periods of non-use. In W. Arthur, E. A. Day, W. Bennett, & A. M. Portrey (Eds.), Individual and team skill decay: The science and implications for practice (pp. 53–67). New York, NY: Routledge. Wang, X., Day, E.A., Kowollik, V., Schuelke, M.J., & Hughes, M. G. (2013). Factors Influencing Knowledge and Skill Decay after Training. In W. Arthur, E. A. Day, W. Bennett, & A. M. Portrey (Eds.), Individual and team skill decay: The science and implications for practice (pp. 68–116). New York, NY: Routledge. O-HSSRC-1.004-029 Version 3 / 07 April 2022 OFFICIAL"
  },
  {
    "id": "7bd48b59-f180-4b94-8262-e9df9527547c",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Appendix A Template For Recording CRA-T Output",
    "content": "The table below shows the format for a template suitable for recording CRA-T output, which may then be used to inform training design and delivery. Table 17 – Template for recording CRA-T Output"
  },
  {
    "id": "a9200ce8-1f5f-42c8-9848-396bb6ffd4f7",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Appendix B Competence Retention Key Concepts and New",
    "content": "Insights This Appendix describes the science behind the development of the CRA-T’s ‘RED’, ‘AMBER’ and ‘GREEN’ retention levels for explicit knowledge, physical and simple cognitive skills. These retention levels are included in the original User Guide and this handbook. The key concepts on which CRA is based are also outlined."
  },
  {
    "id": "d85f69c8-ed6e-43e7-aacc-bd155abf5111",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Predicting Competence Retention",
    "content": "Two predictive models of individual skill retention that consider multiple factors known to affect the retention of knowledge and skills have been identified. The US Army Research Institute’s (ARI) UDA model (Rose, Radtke et al., 1985) predicts knowledge and skills retention by rating task-based characteristics of individual tasks, whereas its revised version, the Trainers’ Decision Aid (TDA) includes training-related factors in addition to those which are tasked-based (Cianciolo et al., 2010). The UDA was identified as the only fully developed predictive model that considers multiple factors known to be strong predictors of knowledge and skills retention. In developing the original CRA-T for the User Guide, the UDA was applied by SMEs to tasks representative of the following domains: Explicit Knowledge, Continuous Psychomotor, Discrete Psychomotor, Simple Decision-making, and Procedural skills (Cahillane et al., 2013). The set of tasks cases were defined in consultation with Defence stakeholders, with each representing the application of one of the psychological domains. Application of the UDA resulted in a series of indicative retention curves for the generic psychological knowledge and skill domains (see Figure 7). The UDA model assumes no practice has taken place in the generation of predicted retention curves. Figure 7 – UDA retention curves for different psychological domains The retention curves in Figure 7 were categorised into a practical traffic light system of three retention levels: High retention (GREEN), moderate retention (AMBER), and low retention (RED), based on the UDA score range. Using the UDA scores, the retention categories were translated into indicative retention bandings, as shown in Figure 8 on to which the indicative retention curves can be overlaid. Figure 8 – Indicative retention bandings The indicative retention bandings for the low, moderate and high retention levels displayed in Figure 8 define the CRA-T competence retention levels in Table 18. The retention level definitions are distinguished by the point at which 50% of a workforce would remain competent in applying the knowledge and/or skills after a specified period of time has elapsed since they were last applied. The indicative green retention banding, which denotes the high retention level indicates that greater than 50% of a workforce will be competent after 12 months (i.e., 52 weeks) has elapsed since the knowledge or skill was applied. Table 18 – Definition of retention levels The retention level definitions are fixed at the 50% point and cannot be adjusted, given the current level of validation for the CRA-T. The low (RED), moderate (AMBER) and high (GREEN) retention levels should be considered as indicative of when refresher training is required and not conclusive. This is because the CRA-T is based on the UDA predictive skills retention model, which was originally developed for tasks requiring the recall of procedures and stepped processes. In addition, although this predictive skills retention model has received some validation, it has not been widely validated and is known to be pessimistic. In general, the UDA predicts on average a smaller percentage of a workforce will be competent than the actual performance data would suggest. For some tasks, this difference has been as large as 30% (Rose, Czarnolewski et al., 1985). Although the retention levels in Table 18 are based on retention curves that may be pessimistic, they can be considered as representative of the worst-case scenario. This is in terms of the percentage of a workforce indicated to be competent after a period of non-practice or application. To date, the CRA-T is the only scientific methodology developed as a practical approach to predicting knowledge and skills retention at the workforce level. Further research and/or the collection of performance data is required to validate the indicative retention level definitions more widely. It is also required to develop definitions for the GREY (Not Known) retention levels for implicit knowledge and the complex cognitive skill domains. The CRA-T was designed to provide a framework to consider competence retention through training, in particular beyond the acquisition of the required knowledge and skills during initial training. The output from the CRA-T process provides information on competence retention because it is based on the psychological domains that underpin tasks."
  },
  {
    "id": "b3f29a16-a13f-4510-812b-c68afaeb1d86",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Prediction Limitations and Assumptions",
    "content": "Those applying the CRA-T should be aware that its existing retention levels (red, amber, and green) are based on decay curves generated by the application of the UDA model. Although the UDA is based on task-related factors that are known to influence the retention of explicit knowledge, physical and simple cognitive skills, the algorithm applied in the generation of its decay curves is based on the aggregation of individual performance data. Therefore, the decay curves represent the percentage of a workforce predicted to remain proficient after a period of time has elapsed since the knowledge or skill was last applied. Given the CRA-T extant retention levels are based on UDA-generated retention curves, they do not indicate knowledge and skill fade at the level of the individual. It follows that the CRA-T retention levels cannot be used to identify the point at which an individual’s performance would fall below criterion. The CRA-T retention bandings assume 100% of personnel within a workforce or unit are competent at the end of their last training session. They also assume that the workforce has received the same training, to the same standard, and that personnel meet the same level of proficiency at the time of skill acquisition. To address these limitations, new decay explanations of knowledge and skills retention must be based on individual retention of acquired knowledge and skills over an extended period of non-use. Key to the generation of individual skills retention curves is the requirement for a standardised approach where the same individuals: i) are at or above a criterion performance level; ii) have had equivalent training experience during acquisition; and iii) have been assessed at the point of acquisition and after a specified retent ion interval(s). Guidance for the collection of longitudinal empirical evidence is covered in a Top Tips document for the Planning, Conduct and Analysis of Future skill Fade research (Cahillane & Anderson, 2021). The UDA model decay curves predict retention out to 12 months. As the CRA-T extant retention levels are based on the UDA model, the CRA-T does not predict retention beyond 12 months. However, the CRA-T still has utility if the intent is to understand which task elements/KLPs and subtasks/EOs would be most and least prone to fade. If the ambition is to extend a refresher training interval to beyond 12 months, then performance data would need to be collected and analysed."
  },
  {
    "id": "b2d87606-0c1a-42d8-9e22-4f7d0d72fd83",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "New Insights",
    "content": "New insights into different types of current and future knowledge and skills were established during a programme of research commissioned by Dstl through the HSSRC framework (Cahillane et al., 2020). These are summarised in the following sections."
  },
  {
    "id": "62f78044-32e5-4a5c-af1d-51861bd4d78c",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "A Revised Taxonomy of Psychological Knowledge and Skill Domains",
    "content": "The current scientific literature, alongside defence case studies (Cahillane et al., 2020), provided the basis for the revised taxonomy of psychological knowledge and skill domains in Figure 9. It was developed due to concerns that the original may not reflect the knowledge and skills considered important by Defence today and in the future, given emerging roles (MacLean et al., 2015; Richards & Deighton, 2019). The re- classification of KSA in terms of the psychological knowledge and skill domains outlines knowledge, skills and attitudes in a manner that is consistent with advances in the psychological literature on human cognition (Green & Bavelier, 2015; Sanli & Carnaham, 2018; Stasielowicz, 2019). There are no attitudinal domains because attitudes do not decay over time. Nevertheless, there is a relationship between attitudes and skills retention, hence the taxonomy’s acknowledgement of Attitudes. Figure 9 – Revised Taxonomy of Psychological Knowledge and Skills Domains Understanding the retention of knowledge and skills is important to Defence because it is known that knowledge and skills are retained at different rates over time. Understanding the rate at which different types of knowledge and skills fade can inform training design and delivery decisions. Knowledge is organised into that which is explicit (knowing ‘what) and implicit (knowing ‘how’). Explicit knowledge refers to basic facts and principles, for example, safety regulations, including any procedures to be followed. Implicit knowledge refers to tacit (non-declarative), unconscious knowledge about ‘doing’. For example, when faced with complex situations, firefighters and incident commanders do not consciously articulate the knowledge they are using because it is implicit. Based on their experience, they automatically recognise salient situational cues which match a course of action. However, research shows that when prompted after an incident, firefighters and incident commanders can describe what they were thinking. The psychological skills domains are organised into Physical, Simple Cognitive, and Complex Cognitive categories. In terms of the Physical category, the Continuous Psychomotor skills domain refers to the ability to perform motor actions that do not have distinct beginnings or ends (for example driving or flying and manoeuvring an aircraft. Performing well trained sequences of motor actions with discrete beginnings and endings reflects discrete psychomotor skills, such as performing weapon handling drills. The Cognitive categories refer to mental skills and distinguish between simple and complex cognitive skills. Simple cognitive skills include the Procedural skills domain, which represents the ability to remember a sequence of steps and their order to execute a task. There are minimal physical demands. For example, when using a BIMS to create map overlays, the physical component only constitutes using a mouse and the procedural aspect dominates. This distinguishes procedural skills from discrete psychomotor skills such as weapon handling, which have greater physical demands and require the recall of a sequence of actions. Simple Decision-making involves a series of processes involving analysis and evaluation with discrete outputs that have a definite beginning and end and result in a decision. The options available during a simple decision- making process are usually binary, such as 'Yes' and ‘No’ when a decision tree is followed, for example, combat casualty drills. Complex cognitive skills include the Complex Decision-making, Adaptive Cognition and the Integrative domains. Complex decision-making involves an iteration of situational assessment, analysis and evaluation cycles that continue until an optimal decision is reached. Examples include carrying out an intelligence estimate or threat analysis and assessment. Adaptive Cognition reflects the ability to constantly monitor the discrepancies between the current and desired state and adapt behaviour to meet the demands of a new situation where the context changes. Problem-solving tasks represent an example where the ability to identify desired goal states (i.e., the need for a solution) and to apply and/or adapt existing strategies (derived from knowledge and experience) are required to arrive at a solution. The example of the US Airways Flight 1549 Hudson River plane crash provides an illustration of the use of adaptive cognition. The pilot, ‘Sully’ had to consider all of the conceptual components of the landing task and their relationships within a new context and adapt his existing learnt strategies to successfully land the plane in the Hudson River. The Integrative domain is a complex cognitive (i.e., mental) ‘meta-skill’. It sits above the other skill domains and represents the ability of an individual to manage their attention in order to perform within two or more different psychological skill domains concurrently. The Integrative domain is required for subtasks where the task elements match a combination of two or more different psychological skill domains that are performed concurrently (i.e., integrated). An example is a firefighter responsible for responding to an incident (simple decision-making) and deciding what and how information should be communicated to multiple agencies (complex decision-making), whilst managing events immediate to the scene of a fire (procedural skills). Note that the procedural skills and discrete psychomotor skills cannot be integrated (i.e., performed concurrently). This because discrete psychomotor skills involve the recall of a sequence of motor actions. Hence, higher motor demands are combined with moderate cognitive demands (i.e., procedural skill). An example of two simple cognitive skills that might be performed concurrently (i.e., integrated) are continuous psychomotor and adaptive cognition, for example, a UAS pilot having to adapt their thinking in order to drive behavioural, i.e., continuous psychomotor output. The UAS pilot has to adapt to constant changes in the information being fed back to them by the sensors, which they are simultaneously controlling. Although a high-level distinction between mental and physical skills is provided in JSP 822 Part 2 (2021), it does not define different types of mental skills that are consistent with advances in the psychological literature (e.g., simple and complex cognitive skills). The accurate consideration of competence acquisition and retention is constrained as a result. However, JSP 822 acknowledges the CRA-T as a process specifically designed to facilitate the retention of knowledge and skills. Based on the original CRA-T, Annex B to JSP 822 Part 2 provides definitions of the psychological knowledge and skill domains and illustrates the effect of task frequency on their retention. A summary of practical training ‘strategies’ are also presented."
  },
  {
    "id": "9fc691e2-c212-4df8-b258-79de285d238a",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Simple vs. Complex Cognitive Skills",
    "content": "The rate at which a skill decays is moderated by the type of skill involved (e.g., Cahillane et al., 2013; Cahillane et al., 2020; Richards & Deighton, 2019). Simple cognitive skills (procedural and simple decision-making) are known decay rapidly (e.g., Cahillane, MacLean & Smy, 2018; Cahillane & Morin, 2012). The rapid rate of decay observed for simple cognitive skills is explained by the fact that they have a combination of low physical demands and moderate cognitive (i.e., mental) demands. The moderate cognitive demand relates to the need to recall cognitive processes or explicit information. Retention is improved where the physical demand is higher. Skills are retained better when they require a combination of moderate to high physical demands and moderate cognitive demands, for example, discrete psychomotor skills such as weapon handling drills. These types of skills require rote memory for cognitive stepped processes and procedures, and their rehearsal to aid their acquisition and retention. Complex cognitive skills (complex decision-making and adaptive cognition) are also better retained than simple cognitive skills (Villado et al., 2013). Complex cognitive skills place much higher demands on cognition, irrespective of physical demand. The higher cognitive demands account for the reduced skill fade found to date for complex cognitive skills. To date, only one study (Sanli & Carnahan, 2018) has considered the retention rate of complex cognitive skills and reported retention up to 6 months after initial training. Hence, there is currently insufficient evidence to define retention levels for complex cognitive skills."
  },
  {
    "id": "aac3cf50-df8a-47fd-9e0e-c2e0bf602e01",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Defence and Security Task Cases",
    "content": "The revised taxonomy of psychological knowledge and skill domains (Figure 9) was incorporated into a systematic analysis of the following five Defence and Security task cases with SMEs (Cahillane et al., 2020): Larkhill - UAS Pilot role Task Case 1: Carry out decision-making in an emergency; Task Case 2: Control the Payload (Payload handling). RAF High Wycombe - Firefighter role Task Case 3: Operate as a Breathing Apparatus wearer; Task Case 4: Incident Commander - Respond to an incident. RAF Brize Norton - Multi-Engine pilot role Task Case 5: Conduct Natural Surface Operations with Night Vision Goggles. These task cases were down-selected in consultation with the Dstl as being representative of current and future Defence and Security skills. For each task, the revised taxonomy was applied at the subtask level of analysis to capture the psychological domains underpinning the subtask elements. Frequency counts for each psychological domain demonstrated the proportion of the domains involved in each task. For each task, the UDA model was applied at the whole task level. The weighted values associated with the selected responses to the ten questions from the UDA were summed producing a total UDA score. This was then fed into the UDA formula to generate a predictive retention curve out to 52 weeks (i.e., 12 months). Questions addressing additional moderators of skills retention (e.g., training and context-related) were also applied. However, responses to these only suggested how the retention rate predicted by the UDA may be improved given a lack of longitudinal empirical data and weighted values for the combined effects of these additional factors. There was evidence of complex cognitive skills underpinning all the Defence and Security tasks examined. Furthermore, multiple psychological domains were found to underpin current and future tasks and this reflected either a combination of skills or an integration of interdependent skills. Where the Integrative domain was identified, this reflected that two or more coordinated skill domains were integrated (i.e., performed concurrently). These findings highlighted gaps in the UDA and CRA-T models. A full description of the findings for all five task cases is provided in the HS1.004 Skill Fade Phase 1 Technical Report (Cahillane et al., 2020). Application of the UDA to the Royal Air Force (RAF) Firefighter task, ‘Incident Commander – Respond to an Incident’ resulted in no decay curve (UDA Total score 66.) Understanding the psychological domains that underpin this task provides an explanation for the lack of a curve. The pie chart in Figure 10 displays the proportion of the underlying psychological skill domains involved in performance of this task as a whole. 75% of the task involves complex cognitive skills. The remaining 25% draws on the Simple Decision-making domain, a simple cognitive skill relying on memory for discrete stepped processes. Figure 10 – Psychological domains underpinning RAF Firefighter role: ‘Incident Commander – Respond to an incident’. (Note: D-M = Decision-Making) SMEs perceived that the subtasks were underpinned by both explicit and implicit knowledge, with the latter being more complex. A probable explanation for this is that Incident Commanders make rapid intuitive decisions when faced with complex situations based upon patterns in associative memory (Klein, 1999). At the time, they do not consciously articulate the knowledge they are using and therefore it is implicit. However, research shows that when prompted after the incident, incident commanders can articulate their implicit knowledge. Rather than being determined by working memory capacity, the science indicates that the retention of complex cognitive skills and implicit knowledge is enhanced by the development of a mental model; in this case, patterns of incidents and cognitive (i.e., mental) responses stored in associative memory. The UDA, which underpins CRA’s retention levels (i.e., green, amber, and red) and corresponding retention level definitions, only considers working memory capacity for discrete stepped processes and procedures. Therefore, the UDA is only valid for physical skills (i.e., the Continuous Psychomotor and Discrete Psychomotor domains), simple cognitive skills (i.e., the Simple Decision-making and Procedural domains) and the Explicit Knowledge domain."
  },
  {
    "id": "56ebca1d-a0ac-41c9-a1ad-31fb5f9a5d13",
    "document": "HS 1.004 Skill Fade Competence Retention Analysis Handbook 2022 V3.0.docx",
    "section": "Simple vs. Complex Tasks",
    "content": "‘Simple’ tasks are underpinned by physical and/or simple cognitive skills and involve discrete subtasks/EOs that are performed separately. Such discrete subtasks/EOs can be performed in isolation from each other and there are no conceptual relationships between them. For example, weapon handling involves the Discrete Psychomotor domain. This underpins the ability to perform well trained sequences of motor actions with discrete beginnings and endings. These motor actions refer to the weapon handling drills. Explicit knowledge also underpins this task, as it does all tasks. As tasks become more complex, the psychological domains involved become more complex and they involve either combinations and/or an integration of psychological domains. Furthermore, resea rch indicates that task complexity and the combination of cognitive and physical demands are associated with the rate of skill decay (Wang et al., 2013). Therefore, to understand and manage the retention of complex tasks, tasks should not be thought of in a single psychological domain. Instead, they should be considered as involving a combination and/or integration of domains. Integration is understood by looking at the whole task. Some complex tasks can be partially integrated whereas other can be fully integrated. This is important to understand because the Integrative domain is used to control and coordinate the other psychological skill domains at the task element/KLP level. This provides the ‘glue’ that holds these elements together (Cahillane et al., 2020). If a task is fully integrated (all subtasks are underpinned by the integrative domain), then it should be practised and assessed at the whole task level. This ensures the integrative ‘glue’, essential for effective task completion, is addressed in the design of the training. If, however, a task is only partially integrated (some but not all of the subtasks are underpinned by the integrative domain), then it may be possible for some subtasks to be practised and assessed at the part task level. An example of a complex task that is partially integrated is the UAS Pilot task, ‘Control the payload’. This involves handling payloads which consist of Synthetic Aperture Radar, Ground Moving Target Indicator radar, and an Electrical Optical and Infrared camera. The matrix in Figure 11 shows the three subtasks on the left and the combinations of psychological domains that underpin these along the top (Cahillane et al., 2020). Figure 11 – UAS Pilot Task: ‘Control the payload’. (Note: D-M = Decision-Making) This task provides an example of how tasks are becoming more complex because they involve the use of more than one psychological domain within the subtasks. ‘Conduct Sensor Planning’ and ‘Conduct Image Processing’ are complex subtasks which use the combination of psychological domains separately. ‘Manipulate the Sensors’, however, uses the combination of the Continuous Psychomotor and Adaptive Cognition domains concurrently (i.e., they are integrated - as indicated by the selection of the Integrative domain in the matrix). Hence, the Integrative domain is used to manage attention to integrate and coordinate the other two psychological skill domains that underpin performance of this subtask. Therefore, this task represents a partially integrated complex task. An example of a fully integrated complex task is the RAF Firefighter task, ‘Incident Commander – Respond to an incident’. As illustrated by Figure 12, all subtasks involve the Integrative domain. Therefore, the Integrative domain sits at the whole task level and, in order to bring all components together, the task must be practised and assessed at the whole task level. Figure 12 – RAF Firefighter Task: ‘Incident Commander – Respond to an incident’. (Note D-M = Decision-Making) As Defence tasks become more cognitively complex, now and in the future, CRA provides a simple mechanism for identifying the psychological skill domains that underpin task and subtask/EO performance. -End of Document- Subject to Protective Marking, National Caveats and announcement or availability restrictions, the information provided in this form will be published outside UK government and should, where possible, be of a commercially non-sensitive nature. To aid completion notes can be found at the end of this form."
  },
  {
    "id": "c665bab7-4a6e-433f-9065-8606dde33544",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Uncategorised",
    "content": "Table of Contents"
  },
  {
    "id": "cb90debd-9151-48f1-8fcb-8021e988cf01",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "How to use this Volume",
    "content": "JSP 822, Volume 1 is an introduction to the policies contained in JSP 822 on Training and Education in Defence 1 . The volume contains Defence Learning and Development policies for Training and Education in Defence; where Defence Learning and Development policy sits outside of Volume 1, it is clearly referenced throughout the volume, and in the Document Information Chapter 7, Section 7.4. The volume is made up of Direction and Guidance: Policy Directives provides the Direction that must be followed in accordance with statute or policy mandated by Defence or on Defence by Central Government. Policy Guidance provides the Guidance and best practice that will assist the user to comply with the Directives. The volume employs ‘must’, ‘should’ and ‘could’ language as follows: Must: indicates that the policy direction is a legal or key policy requirement and is mandatory. Should: indicates the policy guidance is a recommendation. Although not compulsory, if a decision is made that any part of this policy cannot be complied with, then the Senior Responsible Owner who is ultimately responsible for that decision must thereby own and manage the inherent risks that arises. Could: indicates that the policy is good practice and encouraged. JSP 822 is the authoritative policy that directs and guides Defence people to ensure that Defence Learning (training and education) is appropriate, efficient, effective and, most importantly, safe. Organisations across Defence have their own policy documents which local policy teams populate and manage, based on their interpretation of the policy contained within JSP 822. Users should consult those policies and policy teams, within their organisation, prior to JSP 822 and the TSLD Training Policy Team that manages JSP 822. 1 Note that Organisational Learning is captured under the Defence Organisational Learning Structure (DOLS) Framework owned by Joint Warfare in STRATCOM and is not within the scope of JSP 822. The Pan Defence Skills Framework (PDSF) currently sits in Chapter 4 of JSP 755"
  },
  {
    "id": "195cd83b-42de-4dca-ab4a-b209bd94297e",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Defence Training Support Manuals",
    "content": "To support the understanding and implementation of the policy contained within this volume,  have been developed to provide additional guidance. MOD External stakeholders and contractors accessing DTSMs, and internal hyperlinks referenced within JSP 822. JSP 822 is published on  . If the Authority (customer) requires a supplier to have access to additional documentation that is not available on gov.uk, this should be captured within the contract and the onus is with the Authority to ensure that the provider has access to that documentation in accordance with the Information Security policy in JSP 440. If in doubt as to whether documents can be shared with external audiences, the owner of the document must be consulted."
  },
  {
    "id": "cab117ac-d209-4e95-addd-dbf8cc19506e",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Details",
    "content": "Context The Defence People Strategy states that ‘Defence exists to protect the people of the United Kingdom, prevent conflict and be ready to fight the United Kingdom’s enemies. People are the difference that gives Defence its edge’ 2 . To ensure operational success Defence must build, and maintain, a sustainable, diverse, and skilled workforce. A key route to achieving this is maximising the talent of Defence’s workforce through modern learning provision and making better use of skills across Defence. Learning and Development is the process by which the skills Defence requires from its workforce are developed and sustained."
  },
  {
    "id": "31c94f55-fc1d-4c71-9ab3-4b1bd20ebf3f",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Use of ‘Training’ Terminology",
    "content": "The terms ‘Learning’, ‘Training’ and ‘Education’ are used in their own right in the JSP. However, the term ‘training’ is frequently used throughout the JSP to avoid repetition and to match current terminology in use across Defence. In these instances, the term ‘training’ encompasses training, education, learning or development, both individual and collective. 2 Defence People Strategy Part 1, Mar 2020."
  },
  {
    "id": "1d11b762-a4db-47d7-be8c-90b16d441815",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Introduction",
    "content": "The Defence Learning Target Operating Model (TOM) conveys Defence’s future learning vision and provides a focus for Learning3 across the organisation, enabling coherence and implementation of actions required to improve the Defence learning ecosystem. The Defence Learning TOM applies to all Individual and Collective Learning across Defence4. The Defence Learning TOM consists of three levels: Level 1: Defence People Strategy (Found here) provides the vision and strategic direction for Learning across Defence. Level 2: Defence Learning Framework (DLF) (see Page 4 below) develops the Defence People Strategy’s direction to maximise the talent of Defence People, providing a high-level framework encompassing the span of Defence individual and collective learning. The DLF provides key principles across ten component areas, covering all aspects of the Defence Learning ‘ecosystem’5. These components and principles are to guide and cohere all Defence Learning decisions, investments, programmes and projects. The DLF expresses a ‘direction of travel’ for Defence Learning which should be followed but is deliberately broad to support diversity in FLC contexts, innovation initiatives and transformation programmes. Applying the DLF principles coherently will deliver the DLF Vision and Mission, enabling Joint Operational Excellence across Defence. Level 3: Defence Learning Maturity Model. These are the actions that will help to deliver the Defence Learning TOM, grouped across four spaces: Organisation; Data; Delivery; and Learning. In turn these are divided into Key Enabling Actions, DLMC Programme Actions and Optional Actions. These actions will evolve as progress is made towards achieving the Defence Learning TOM Vision. This level was previously known as ‘Building Blocks’. 3 Learning encompasses Training & Education (T&E). 4 This is different from Organisational Learning which is ‘a process by which individuals and groups within an organisation, both individually and collectively routinely, deliberately and critically reflect upon their activities, and act upon new insights gleaned to the benefit of the whole organisation’ (DOLS Road Map). The lead for Defence Organisational Learning is JW, StratCom. 5 The Defence Learning ‘ecosystem’ encompasses all aspects of individual and collective learning (training & education) pan-Defence. The intent of the Defence Learning TOM is to: Drive coherence and a collaborative approach to Learning across Defence. Enable collaboration on shared requirements and sharing of good practice, experience, and ideas. Support the Defence federated model by providing freedom within broad boundaries. Provide agility and flexibility to adjust in accordance with Defence requirements. The Defence Learning TOM will be governed by the 1* TSLD PAG, who in turn will be accountable for reporting progress on the Learning TOM to the 3* / 2* People Leadership Team (PLT) annually against progress from the 'As Is' to 'To Be' Pictures of Defence Learning. All Command Learning and Development Strategies should be developed with reference to and in support of the Defence Learning TOM, using the DLF as the higher authority and starting point. The DLF, set out below, is the critical element of the Defence Learning TOM and provides the high level ‘direction of travel’ for all individual and collective Defence learning. Policy: JSP 822 Defence Training and Education V7.0 (Feb 24)"
  },
  {
    "id": "e70b3119-5ae3-4cab-901c-2ca351eaa9a3",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Volume 1: Introduction",
    "content": "Volume version 3.0 (Feb 24)"
  },
  {
    "id": "7590105a-6129-4e47-a47f-09d28ee81a6e",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Introduction",
    "content": "The Defence Systems Approach to Training (DSAT) process comprises activities relating to the analysis, design, delivery, and assurance of all Defence training, both individual and collective, across the Whole Force6. Integral to these four Elements is the need to ensure that the DSAT process is properly managed and governed. These management and governance activities, along with the assurance activities themselves, combine together to create a Management of Training System (MTS). The purpose of these activities is to ensure that the training of our people contributes directly to Defence outputs and helps to mitigate risk inherent in conducting the training. When the analysis, design, and delivery Elements of DSAT are combined with a robust MTS, the result is a Training System that delivers training that meets the required DSAT Quality Management Standard (QMS) and is: Safe Risk-focused Accountable Appropriate to the training need Cost-effective In the context of this JSP, ‘training’ encompasses any training, education, learning or development, both individual and collective, that is designed to meet the needs of a Training Requirements Authority."
  },
  {
    "id": "52603434-2e8c-4d6c-bf6e-aa1840f18035",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "What is the DSAT Process",
    "content": "DSAT is the process that must be used by those who are involved in the analysis, design, delivery, assurance, management, and governance of training across Defence. DSAT is designed to generate a Training System that empowers trainers7 to deliver safe, risk-focused, appropriate, effective, efficient, and accountable training to trainees8 and training audiences. When new or changed equipment, technology, tactics, techniques, or procedures are developed, or when new or 6 The Whole Force encompasses Regular and Reserve personnel, MOD Civil Servants and civilians, including the Ministry of Defence Police and contractors. It is noted that training sourced through the pan- Governmental ‘Civil Service Learning / Government Campus’ is not subject to DSAT. Any other Civil Service training must be compliant with DSAT. 7 I.e. those engaged in delivering formal training across Defence, for both individual and collective training. 8 I.e. those across Defence undergoing individual and collective training, and encompasses such terms as ‘recruit’, ‘student’, ‘learner’, ‘exercising troops’ etc. These and other terms continue to be used in the wider Defence training community, particularly in Phase 1, Phase 2 and collective training. changed policy or legislation is brought in, the requirement for new or amended training must be examined. After initial analysis, it may be decided that training is not required. There could be a solution from any of the other Defence Lines of Development. If training is required, DSAT is merely a tool to deliver training that meets the needs of the TRA as well as the DSAT QMS mandated by Defence. DSAT is not a complicated process, but it is detailed and, therefore, to aid in its use, a process with 4 Elements has been designed to ask, or state: Element 1: Analysis. What is the requirement; is a new or amended training activity needed; and, if so, what kind? Element 2: Design. What should the training activity look like; who will deliver it, and with what resources? Element 3: Delivery. The training activity is delivered. Element 4: Assurance. Is the training activity being delivered correctly and does it meet the requirement? Is the whole Training System fit for purpose? Figure 1: The Four Elements of DSAT9 DSAT, as illustrated in Figure 1, is not linear. The process is iterative and assurance10 takes place regularly, and as part of all Elements. Whilst each of the DSAT Elements is mandated, the many activities that can be undertaken as part of each Element are not. This is because some training requirements are so simple that to complete all of the activities within each Element would be unnecessary and wasteful. The DSAT process is cyclical and flexible and should be applied intelligently rather than followed dogmatically. Users should select both the activities specific to their need and the order in which they are applied, to achieve the most appropriate Training System11. Individual Training and Team/Collective Training. The DSAT process must be applied to all individual and collective training pan-Defence and caters for both individual training and collective training needs. It has been designed to deliver 9 The colours chosen to differentiate between the 4 Elements in Figure 1 will be used throughout this JSP. Analysis activity is depicted in green; Design in pink; Delivery in orange and Assurance in purple. 10 Including Internal Validation (InVal), External Validation (ExVal), Audit, Inspection and Continuous Improvement. 11 Exceptions to the broad intent of the DSAT process, particularly where MTS and assurance activities are concerned, will require justification and risk management (if appropriate). either one, or the other, or both. As individual training is part of, and a building block to, collective training, it is considered likely that trainees will conduct individual training activities, followed by collective training activities, as a ‘training continuum’ (see Figure 2) before they can be considered able to contribute effectively to Defence outputs. Figure 2: Training Continuum – Individual/Team/Collective"
  },
  {
    "id": "c8e55f46-19e1-4665-aa13-b045f20a4544",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "What is the DSAT QMS?",
    "content": "The DSAT Quality Management Standard (DSAT QMS) is the standard that is met when the outputs of the DSAT Elements and the MTS activities are delivered correctly, i.e. iaw JSP 822. DSAT assurance activity needs to focus on the mandated requirements of individual training (Volume 2) or collective training (Volume 3)."
  },
  {
    "id": "963e7f99-3503-459a-8f12-79131a0ea400",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Roles",
    "content": "Main Stakeholders. There are many different users of the DSAT process who are pivotal to ensuring the MTS is fulfilled. Detailed information on these roles can be found in Volume 2, Chapter 2 for Individual Training, and Volume 3, Chapter 2 for Collective Training. Key personnel or roles include: Training Requirements Authority (TRA). The TRA represents the end-user of the trained output and is the ultimate authority for the derivation and maintenance of the Role/Team Performance Statement (Role/Team PS) and/or Framework. Training Delivery Authority (TDA). The TDA is the organisation responsible for training delivery, but not always for the conduct of the actual training itself. It must be distinct from the TRA. Training Provider (TP). The TP is the training school, college, organisation, establishment, unit, or group that delivers the training. Other Stakeholders. Whilst not directly involved in the process of generating training activities, there are other stakeholders who have an interest in the training provided and who will likely exert influence over the DSAT process in order to ensure that their needs are taken into account. These other stakeholders may include: Customer/Sponsor12. Likely to be the Service or Joint Command, or the fielded force (units, ships or groups) who are tasked with delivering Defence effect and who need trained personnel to fulfil a wide variety of Roles. Defence Contractor. Many training activities are carried out by Defence contractors, who are civilian personnel working for, and on behalf of, Defence. Training Audience. Also known as Target Audience or Target Population, this is the group of individuals or Teams expected to be the recipients of the training solution. 3rd Party Auditor or Inspector (e.g. Ofsted 13 or a National Governing Body). Roles in the Joint and Defence Environment. The principles for the governance, management, and assurance of Joint/Defence training requirements are the same as for individual and collective training. However, the Joint and Defence training environment is complex. Direction on this can be found in Volume 2, Chapter 2 for Individual Training, and Volume 3, Chapter 2 for Collective Training."
  },
  {
    "id": "f58ad9c1-9aee-4e9d-a844-293b3b3a1839",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Contracting out Elements of the DSAT Process",
    "content": "Where discrete elements of the DSAT process are outsourced to contractors, the exact requirement should be captured in the contract in order to ensure that DSAT activities that are undertaken by DSAT SQEP staff, are compliant with JSP 822 DSAT direction 14 . Outsourcing the provision of DSAT activity to commercial organisations can be an effective use of resources especially where capability or capacity shortfalls exist and where time imperatives or the need for concurrency demand it. 12 Individuals and organisations may consider themselves ‘Customers’ or ‘Sponsors’ of training but their requirements can only be represented by an identified TRA. TRAs are the only recognised ‘Customer’ at a CEB. Note also that Capability sponsors may own the T-DLoD through-life for a particular capability but usually handover the TRA role at an agreed point to an ‘in-service’ TRA. 13 Office for Standards in Education. 14 Existing contracts are not required to be amended to reflect the changes in terminology in this JSP. New contracts, or those undergoing significant contract amend, must reflect the changes."
  },
  {
    "id": "f9dca196-8a28-449d-a074-6b5aecda887a",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "DSAT Processes within the Acquisition Process",
    "content": "The Defence Acquisition System Operating Model defines how acquisition activities are to be conducted, including alignment to Finance and Military Capability (FinMilCap) and Service Command (SC) processes. Within this model sits the acquisition process of CADMID 15 and CADMIT 16 , which each Defence Line of Development (DLOD)17, including Training18, has to work within. Figure 3 describes how the training elements of capability fit within the CADMID/T lifecycle and what processes and outputs, including DSAT documentation, are required: FINMILCAP Processes. These financial planning processes ensure that pan- DLOD capabilities meet genuine needs, are affordable and compliant with Defence and SC policies and strategies. The cost of developing and delivering individual and collective training for new capabilities, as well as for updates and upgrades to existing, will be assured through the activities of the Personnel and Training DLODs engaging with capability sponsors and DE&S/ISS project teams. This includes developing through-life personnel and training costs within capability planning options, project initial and main gate business case cost models and project/in- service Procurement (P9) and Support (S9) funding lines19. Concepts & Doctrine Processes. Concept and doctrine documentation such as Concepts of Employment (CONEMP), Concepts of Use (CONUSE) and operational doctrine are integral parts of developing and delivering the right capabilities. Again, Personnel and Training DLODs must be considered in all these documents as they underpin the development of subsequent requirements documents. These concepts will be based on Defence and SCs’ policies and strategies for training. Requirements Processes. Within the Concept and Assessment phases of DE&S/ISS projects a User Requirement Document (URD) 20 and a System Requirement Document (SRD)21 are developed to enable the contracting of industry to deliver equipment and services. Within the Personnel and Training DLODs, DSAT Analysis processes can be used and documented to provide evidence in support of requirements for interim22 and steady state training solutions. This DSAT 15 Concept, Assessment, Demonstration, Manufacture, In-Service, Disposal. httpsidk 16 Concept, Assessment, Demonstration, Migration, In-Service, Termination. httpsidk 17 https://modgovuk.sharepoint.com/sites/DOM/SitePages/bGEN006.aspx 18 https://modgovuk.sharepoint.com/sites/DOM/SitePages/bGEN008.aspx 19 Note the Apache Programme example where the T-DLOD caused delays in delivering the capability: https://publications.parliament.uk/pa/cm200203/cmselect/cmpubacc/533/53303.htm. 20 httpsiok 21 httpsiok 22 When bringing into service new capabilities, training may be required before the formal in-service phase and hence interim training will be used to enable sufficient knowledge transfer to conduct trials & acceptance activities, doctrine development and train the trainers and training developers. Interim training Analysis will subsequently go forward to update in-service SOTRs and Performance Statements for both individual and collective training. Following the acceptance by the Department of recommendations in a National Audit Office report 23 it is mandated that where the provision of training is proposed, the business case is to be supported by DSAT Analysis. Deliver Processes. Within the Demonstration to Manufacture/Migration phases, capability solutions are contracted, developed, and delivered into service. During these phases training solutions will also be procured and/or legacy training systems will be updated to reflect the capability changes. Where new solutions are needed, requirements processes may have to be followed again to develop URD, SRD, Integrated Test Evaluation & Acceptance Plan (ITEAP) and Through-Life Management Plan (TLMP), as well as the new DSAT training design and delivery documentation. Where training systems are being updated, these documents should already exist (if not created) and be updated accordingly to reflect the capability changes. Once training solutions are in place, steady state training can commence in accordance with normal DSAT processes. does not have to comply with DSAT requirements due to its temporary nature and off-the-shelf availability but contracting against specific DSAT processes may provide opportunities to de-risk steady-state training development. 23   httpsao. Figure 3: DSAT Processes within the Acquisition System"
  },
  {
    "id": "24a3527a-af7a-4389-a718-f8a167d38776",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "DSAT and the Management of Risk",
    "content": "DSAT and the Management of Risk. In the context of limited resources and time, Customers, Training Requirements Authorities (TRAs), Training Delivery Authorities (TDAs) and Training Providers (TPs) must apply DSAT intelligently, and thereby own and manage the inherent risks that arise; they must comply with DSAT policy or explain why they are unable to do so and how they have mitigated the consequent risks. DSAT, applied intelligently, manages, and mitigates the risks inherent in the requirement setting, design, delivery and assurance of Individual and Collective Training."
  },
  {
    "id": "7e9ff6ba-7eb5-4cf7-9101-653497d15e73",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Applying a ‘One Defence Mindset’ to DSAT",
    "content": "A 'One Defence Mindset' is one where everyone works together to achieve Defence goals. This is respectful of the cultures and loyalties which exist across Defence but asks for us to approach the delivery of the Command Paper, in an integrated way and working as a wider Defence team. Recognising that when we work together, we are stronger than the sum of our parts. A ‘One Defence Mindset’ reduces the chance of mistakes and supports innovation because we consider the wider impacts of our actions. This could mean considering how our actions affect other parts of Defence, identifying how other parts of Defence can help us, and speaking with our colleagues to gather their views. It is therefore important, that whilst following the DSAT process, it should be followed with a ‘One Defence Mindset’. More information on the ‘One Defence Mindset’ can be"
  },
  {
    "id": "5f6c7036-c90f-4c25-8092-4c348ba1fc7d",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Introduction",
    "content": "This chapter of the JSP outlines the Defence Direction relating to Management of Training System (MTS), further detailed direction on MTS can be found in Volume 2 (Individual Training) and Volume 3 (Collective Training). It will also explain the purpose of the DSAT QMS and how a robust MTS will assist in meeting that standard."
  },
  {
    "id": "96bcccb8-7f3b-4f2a-b610-41242652626b",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "What is MTS?",
    "content": "Integral to the 4 Elements of analysis, design, delivery and assurance is the need to ensure that the DSAT process and the resultant Training System is properly governed and managed and meets the high standards required for training in Defence. The governance, management, and assurance (Element 4) of training are collectively known as an MTS. An MTS is an iterative mechanism (supported by documented products and processes) to ensure that the training being delivered remains meaningful and continues to contribute to delivering Defence effect. When delivered correctly, the outputs of the DSAT Elements, combined with the MTS, deliver a Training System that meets the required QMS. For the MTS to be effective, bodies such as boards and working groups must be established to ensure that the DSAT process remains on track and the Training System remains appropriate to the need. Key DSAT documentation (explained later in this Section) must also be produced. As an integral part of the MTS, activities that directly contribute to meeting the QMS are also embedded within each Element. The MTS mostly draws in products from the DSAT process in order to record and demonstrate that the QMS is being met and avoid duplication. All stakeholders in the Training System will have some involvement in the MTS."
  },
  {
    "id": "7598ec63-5c24-4034-b646-1324e9212e6d",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "What is a Training System?",
    "content": "A Training System, therefore, comprises the analysis, design and delivery of training along with the governance, management and assurance activities. Put another way: DSAT 4 Elements + governance and management = Training System When conducted correctly, the Training System delivers training that meets the DSAT QMS mandated by Defence. Figure 4 shows DSAT and MTS activities combining to generate a Training System. Figure 4: The DSAT Process Generating a Training System Defence requires its people to place themselves in harm’s way to deliver Defence effect. Defence people work in hazardous environments, under stressful conditions whilst conducting activities that carry a high risk to personal safety. Consequently, Defence must ensure that its Training Systems meet the very highest standards. Training must also be robust, realistic, and challenging if it is to prepare its personnel for the full spectrum of Defence Roles. However, there is a tendency, because of the risk, for Defence training organisations to provide more training than necessary in the misguided belief that this will make up for future uncertainties. And, in some cases, poorly designed or executed Training Systems can deliver insufficient training. The ideal then is a Training System that is designed to train its personnel to an optimal level so that they are equipped with the appropriate Knowledge, Skills, and Attitudes (KSA). Providing too much training costs money that will likely be taken from elsewhere in the training budget that could then result in insufficient training in other areas, which risks lives. Therefore, a Training System designed using a common process and that is governed and managed in accordance with the Defence mandated QMS, is vital to ensure that Defence people are best equipped to achieve Defence effect."
  },
  {
    "id": "9f3ebb63-e35d-434a-831b-bfd13a6a55f9",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Training Governance Activities",
    "content": "People Leadership Team (PLT) (5.16). This is a 3*/ 2* Defence level Board that is chaired by the Chief of Defence People (CDP). It is the highest-level governance body for training issues. Amongst other objectives, the PLT manages training strategic performance and risks, and provides the governance and management of Defence Training and Education. Talent, Skills, Learning and Development Policy and Assurance Group (TSLD PAG) (5.18). This is a 1* Defence level group chaired by Hd TSLD and provides strategic Direction on Defence Training, Education, Skills, Recruiting and Resettlement matters. It is the principal forum for the governance and assurance of such activities throughout Defence. Customer Executive Board (CEB) (5.19). For all training, CEBs form part of the MTS and are specific to the needs of that Training System. The general purpose of a CEB is to provide a mechanism for stakeholders to develop the scale and content of training to match the required Defence outputs within the available resources, and in accordance with relevant Defence and sS policies. Working groups/steering groups (WGs/SGs) (5.20). There are several standing Defence level WGs and SGs that assist with policy, assurance, and governance of training across Defence. Collective Training has an additional governance structure that sits outside of the structure mentioned above, detail on this structure is set out in Volume 3 of this JSP. Governance of Joint and Defence Training Requirements. In all instances, a CEB is to be formed as early as possible in the process to manage, govern and assure Joint and Defence training requirements. In many cases the roles are already agreed but where the nomination of Lead TRAs, TDAs and Training Providers cannot be agreed between Service/Joint Commands, this is to be referred to the TSLD PAG for resolution. The matrix of Lead TRAs and Lead TDAs for training in Joint and Defence training environments is held on the  . It is the responsibility of SCs to keep this matrix up to date."
  },
  {
    "id": "abe7eb28-b148-4369-ba11-5aee51caf6be",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Defence Direction on the Safe System of Training",
    "content": "In addition to the requirement for a Safe System of Work, a Safe System of Training (SST) must be employed within all training environments. A SST comprises of 4 key elements which Commanders and line managers must understand: Safe Persons Safe Equipment Safe Place Safe Practice This Direction applies to all Defence training. Commanders and managers must: ensure that all personnel in the training environment are provided with the appropriate information, instruction, and supervision. ensure that trainers and supervisors are competent and given an appropriate level of supervision to ensure that the delivery of training is appropriate to the ability of those being trained. ensure correct equipment is available, operated and maintained by competent and appropriately supervised individuals and associated training and maintenance records are kept. ensure that all risks have been assessed, recorded, and mitigated as far as reasonably practicable. ensure that all personnel are fully briefed on all necessary controls to be implemented. ensure that training practices be conducted strictly in accordance with drills, procedures and instructions and direction. identify, manage, record, and escalate cumulative risk. Ensure any change to training where the resultant risk has an impact on Safety that increases risk to life and could result in death or serious injury must be subject to an approved risk assessment by the Commander, Line Manager, or accountable person."
  },
  {
    "id": "2781b75c-fb8b-4f4c-a217-24e2f78db59a",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Introduction",
    "content": "Nothing in this chapter obviates the responsibilities of Commanders and those responsible for training to follow the direction and guidance set out in JSP375 for the Safe System of Work (SSW). The Safe System of Training (SST) does not replace Health and Safety legislation, nor the guidance offered by the Health and Safety Executive; rather, the SST should be read in conjunction with JSP375. The SST is derived from the Safe System of Work (SSW) and sets the conditions under which Defence training is to be conducted, ensuring personnel are provided with the appropriate information, instruction, and supervision. This enables Defence to meet the training imperative set by the Operational Requirement, whilst ensuring that personnel given the best possible preparation for the roles they may undertake. The SST enables Defence to maintain training risks at As Low As Reasonably Practicable (ALARP) by ensuring those who conduct the training are competent and that all risks, and associated mitigation measures have been considered. Further direction and guidance on SST policy is being developed and will be published as soon as practical. The SST differs from the SSoW as those undergoing training cannot be deemed competent until they have successfully completed training and have undertaken any required assessments, achieved qualifications, and have obtained the currency and experience24 to perform their duties. The SST is important as training units carry additional risk as many of their people, including staff, have not yet reached a specified level of competence. Commanders and Managers have the additional responsibility to ensure those in their charge can deliver and train safely. Training supervisors and deliverers must ensure that the training risks are recognised, communicated, and mitigated, and in conjunction with those in support of training, dynamically alter training as necessary. The SST sets the conditions under which training is to be conducted, ensuring those undergoing training are given appropriate information, instruction, and supervision. The levels of supervision and competency required of those delivering and supervising training will be directed by the relevant Training Authority. Trainees are to be fully briefed on all hazards they will face during training and must adhere to any instructions delivered before and/or during the training. 24Where experience is practice that might leave some residual KSAs. Currency is whether those KSAs are still relevant and/or meet an accepted standard that enable competent, safe and legal performance."
  },
  {
    "id": "9b06e885-1923-4116-b0b3-c878a5f67882",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "The 4 Elements of SST",
    "content": "A SST comprises of the 4 same elements as the SSoW (safe persons, safe equipment, safe place and safe practices) but contextualised with additional considerations / training elements:"
  },
  {
    "id": "788634b8-9d39-4320-b4e9-517f800535b6",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Safe Persons",
    "content": "There are 3 categories of people at risk in training: Personnel undergoing training and those personnel delivering it. Personnel including civilian staff and contractors in support of training. General public including those unaware of the military training activity and including any unauthorised individuals25. Commanders or line managers must ensure that trainers and those supervising the training are competent and given an appropriate level of supervision. Training must be at a level commensurate with the capability of the participants."
  },
  {
    "id": "70f96fa4-3d87-4785-b304-6a32228f1acf",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Safe Equipment",
    "content": "Any equipment including explosives and ammunition, brought into service following the Defence process for the production of a Safety Case, should have appropriate documentation defining the safe operation and maintenance of the equipment under service conditions. Commanders or where delegated, line managers must ensure their subordinates have available, and make proper use of, the correct equipment to carry out an activity in accordance with the appropriate Service Equipment Support Publications or similar set of instructions. They must ensure that only competent persons or those under appropriately supervised training are allowed to operate and/or maintain the equipment and the associated completed training and maintenance records are kept. 25 Any individual deemed to be trespassing or in an unauthorised location."
  },
  {
    "id": "1b7811d4-2b09-4aaf-9c8c-bffd41e54f92",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Safe Place",
    "content": "A place in which the controls, necessary to enable authorised training to be conducted safely, must have been identified by a site-specific risk assessment and directed through appropriate Standing Orders, such as Range Standing Orders. Commanders or line managers must ensure both trainers and those personnel under training are fully briefed on all necessary controls to be implemented in order to maintain the Safe Place."
  },
  {
    "id": "da126e3c-cf29-4cfa-86a6-936f8f667a44",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Safe Practices",
    "content": "Safe Practice includes the following of correct procedures, the provision of effective supervision and delivery of effective training, the briefings of all warnings, cautions and controls together with the use of appropriate Personal Protective Equipment (PPE). Practices must be conducted strictly in accordance with drills, procedures and instructions laid down by the Service authorities. These drills and procedures, taking into account the training imperative, are identified in the Safety Case and developed in accordance with the Defence Systems Approach to Training (DSAT). Training is only to be delivered by a qualified and competent person to ensure that procedures are strictly adhered to, and such instruction and training is closely supervised by the Chain of Command to ensure Safe Practice is implemented. All training must be monitored and/or supervised by a competent person to ensure that all procedures are adhered to and that safe working practices are maintained. Risks and control measures associated with the practice must be communicated to all participants."
  },
  {
    "id": "38e793f0-ab24-4d14-b395-705350e50323",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Risk Management",
    "content": "There are well established processes (JSP 375) and (JSP 892) for determining and assessing risks in place. In addition to Health and Safety requirements set out in (JSP 375). There is also a requirement for the Commanders Risk Assessment (CRA) pertaining to the care and welfare of trainees (Further information on the CRA can be found in volume 4). Risk/assumption management must start at the beginning of the DSAT process26. Risks/assumptions are to be held on risk/assumption registers at all levels (e.g. training establishment, SC or SC’s subordinate training HQ) and are to be managed iaw relevant Defence risk management policies. Risks/assumptions must be reviewed regularly during all Elements of the DSAT process and updated with any new and emerging risks. Training should be delivered as it was planned, with the correct training facilities, suitably qualified and experienced training staff and with the correct procedures and instructions. Undue pressure should not be put on managers or those delivering training to deviate from planned and endorsed training programmes. Those responsible for the management and delivery of training should have the ability to amend training as necessary, to meet changing environmental conditions (e.g. avoiding excessive heat), equipment deficiencies or shortfalls in resources. However, careful consideration must be given to the resultant risk, especially where it has an impact on safety that increases the risk to life and could result in death or serious injury. It is imperative that the delivery of training remains progressive and subject to a safe system of training throughout. Changes to planned training delivery such as truncating, accelerating or other variations (changing location, time, or content etc) can affect the rate at which training proficiency is achieved, potentially increasing the associated risk. In many cases certain proficiency criteria must be met by trainees to be able to perform tasks in a consistent, reliable, and repeatable manner that meets established standards, facilitating the progression in training and enabling post training activities. This is of paramount importance for any critical training which, if not conducted to the correct standard, increases the risk to life and could result in death or serious injury. Any change to the content, time, or resources available for such critical training must be subject to an approved risk assessment by the Commander, Line Manager or accountable person. Furthermore, for all training activities, dynamic risk assessments are to be conducted before or during activities in response to changing or unexpected conditions. This will allow training to be paused, amended, or stopped as necessary. 26 See JSP 892 for Defence Risk Management Policy."
  },
  {
    "id": "d49e49ac-bed8-41ae-b849-16a762784cb8",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Cumulative Risk",
    "content": "It is not sufficient to merely monitor risks, but all involved must be aware of the possibility and impact of cumulative risk. This may occur within a training day or training course as activities are changed and amended, with the trainer or supervisor required to keep track of the impact on safety as well as the training standard and welfare of all those involved. Cumulative risk incorporates other areas such as support and management, where there is no longer the capacity to maintain the existing training or update it to meet changing requirements (e.g. input standards) or fully implement the recommendations from reviews. For example, the informal act of a changing task (change in task complexity, omitting a particular step, changing the conditions set out in the planned activity) - although necessary, may have introduced additional risks that were not recognised- either in facilitating training, or in the need for suitable progression for the trainees. In addition, gapping in the training support area may mean this change is never updated in the DSAT mandated documentation and hence it is not reviewed and authorised. Operational pressures and resource constraints may then mean this shortfall is continually repeated in several areas and informal changes become normalised: the training delivered may be required but does not match the authorised and documented instructions and procedures being managed and resourced. Such cumulative risk must be recognised, escalated through the chain of command, and actioned as necessary."
  },
  {
    "id": "05dd2ba5-e5e9-4479-b57a-cc6b31fdae82",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Assurance",
    "content": "Assuring against the Safe System of Training is not mandated, and those involved in Assurance activities must follow the direction given in Volume 5 of this JSP. However, the Safe System of Training is useful reference for Auditors."
  },
  {
    "id": "410e9f8f-c5a3-49f8-a590-a15631835296",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Document Coverage",
    "content": "The contents of this policy supersede all previous MOD Policy on the same subject(s)."
  },
  {
    "id": "b14c4d1a-6507-41e4-bb50-45dacf5c237d",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Document Versions",
    "content": "MOD will review this Policy in three years, or when changes to legislation or best practice dictates."
  },
  {
    "id": "d5affdbc-1f31-4056-aa9a-878f67196c91",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Applicability",
    "content": "The policy contained in this Volume applies to the Whole Force which encompasses Regular and Reserve personnel27, MOD Civil Servants, and civilians, including the Ministry of Defence Police and contractors. It is noted that training sourced through the pan- Governmental ‘Civil Service Learning / Government Campus’ is not subject to the policies in this document. Any other Civil Service training must be compliant with the policies in this document. The policy in this document does not apply to training deemed ‘Informal’ or ‘On-the-Job’. Organisational Learning is captured under the Defence Organisational Learning Strategy (DOLS) Framework owned by Joint Warfare in UKStratCom and is not within the scope of JSP 822."
  },
  {
    "id": "aec2763c-bbef-40ca-8482-ec18b27c8063",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Diversity and Inclusion",
    "content": "MOD respects and values people of all backgrounds. The Individual Training policy is designed to ensure all employees are treated in a fair, transparent, and consistent manner. All those involved in the management of MOD employees must abide by legislation and should adhere to MOD policy. For more information on diversity and inclusion, please see the   on MODnet. This policy has been subject to an Equality Impact Assessment (EA)."
  },
  {
    "id": "550e23c9-ab40-4603-85b2-79c53e0ee1ef",
    "document": "JSP 822 V7.0 Vol 1 V3.0 Introduction.docx",
    "section": "Glossary",
    "content": "The Glossary of Definitions, Terms and Acronyms can be found on the   Sharepoint site. 27 This includes UTCs, and military personnel (Regular & FTRS) that instruct Cadets and CFAVs. This does not include non-military personnel that instruct Cadets and CFAVs."
  },
  {
    "id": "3e5eb570-a890-46e2-a491-66101e74422f",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Uncategorised",
    "content": "Table of Contents"
  },
  {
    "id": "de04c136-7a75-4961-b280-6c56aa289bf0",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The volume is made up of Direction and Guidance:",
    "content": "Policy Directives provides the Direction that must be followed in accordance with statute or policy mandated by Defence or on Defence by Central Government. Policy Guidance provides the Guidance and best practice that will assist the user to comply with the Directives."
  },
  {
    "id": "efa6431d-2338-4a66-9e1e-61986488aad4",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The volume employs ‘must’, ‘should’ and ‘could’ language as follows:",
    "content": "Must: indicates that the policy direction is a legal or key policy requirement and is mandatory. Should: indicates the policy guidance is a recommendation. Although not compulsory, if a decision is made that any part of this policy cannot be complied with, then the Senior Responsible Owner who is ultimately responsible for that decision must thereby own and manage the inherent risks that arises. Could: indicates that the policy is good practice and encouraged."
  },
  {
    "id": "8060d8fd-63b6-4c72-8d77-1bb89493347d",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Figure 1 on the next page displays all of the mandatory DSAT, Management and Governance activities that make up a Training System, and the order in which they are likely to be completed.",
    "content": "Figure 1: Inventory and Alignment of Mandatory ‘Must’   DSAT and MTS Activities that forms a Training System"
  },
  {
    "id": "43c256fb-8d14-4b71-a611-b051b05d5a71",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "DT is to be included in processes for managing, governing and assuring Individual Training.  It is to be correctly identified, resourced and managed, and be designed and developed, delivered and evaluated in accordance with Individual Training Direction and Guidance.  As with centrally provided Individual Training, all areas of Distributed Training must have a governance structure clearly defined within the MTS.  The MTS must also detail associated procedures, including the recording of completion of Training Objectives and the documentation of risk where DT cannot be effectively delivered.  DT must be a planned occurrence with authority from the relevant governing organisation to conduct it.  Clear agreement between TRA and TDA / Contractor is essential when moving Training between centralised and distributed delivery. Clearly articulated governance and management procedures include:",
    "content": "the delivery of the TPS by a TDA. the process for management of the TPS and/or WTS. the process for how TOs that cannot be delivered centrally will be achieved/managed. TRA involvement in contractor delivered training within the Service Commands. management by a TRA of DT delivered by Service Command units. management of Reservist DT. a clear audit trail exposing decisions regarding the responsibilities for DT including the process for all parts of design as well as ownership, authority for units to deliver courses, for assessment and for assurance."
  },
  {
    "id": "b540be2e-a501-4125-85a3-c5af35114e30",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The responsibility for the management and governance of DT is:",
    "content": "TRA. The TRA is responsible for: the governance and assurance of DT, unless otherwise formally agreed with a TDA or contractor. reviewing and ensuring that the Training Options Analysis and Methods and Media options of TNA Stage 2 consider distributing any or all of the training delivery, and that the TDA(s) and TP(s) are appropriately resourced to design, develop, administer and manage any DT identified.  They are also to ensure that a measure of effectiveness, including a cost-benefit analysis of any DT is factored into the Evaluation Strategy of the training. TDA.  Where agreed with the TRA, the TDA will design, develop, administer and manage DT be it within SC or through another TDA on behalf of the TRA. To ensure delivery quality, the TDA should conduct a programme of Quality Assurance visits to TPs. Such visits would incorporate regular/annual/biennial checks on the currency of training content, training qualification, use of training aids, delivery quality and the training environment. The roles and responsibilities of each organisation must be clearly articulated in the organisation’s MTS and/or contract. CEB.  DT and the outcomes of Quality Assurance visits must be reported on at the Customer Executive Boards (CEB)."
  },
  {
    "id": "a18a3b67-fc49-4727-8cdf-e4842172fe8f",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Customer Executive Board (CEB).  The purpose of the CEB is to provide a mechanism for stakeholders to develop the scale and content of training to match the Defence requirement within the available budget and in accordance with relevant Defence and sS policies.  In doing so, the CEB will:",
    "content": "hold all parties to account for the execution of their responsibilities in relation to the quantity, quality, timeliness and effectiveness of the training. hold the TRAs to account to provide a clear fully justified requirement and their priorities for training. endorse / sign off the TrAD. manage key DSAT / MTS documents which drive CEB business."
  },
  {
    "id": "ab0a6449-c4d3-4aa3-80ba-85b39cb3960e",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Element 1 is conducted broadly in 3 Stages:",
    "content": "Stage 1 Scoping Exercise. Stage 2 Analysis. Stage 3 Evaluation."
  },
  {
    "id": "3185c900-ffd7-40c4-9d80-001f6b1c3742",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Considerations.  Training activities should meet Defence outputs; and, should these change, the training need should be re-analysed, via a TNA, and if necessary, adapted to support the new requirement(s).  When a TNA is to be conducted, the user should consider:",
    "content": "The requirement being raised and the need to carry out a TNA. Forming a TNA Steering Group (TNASG). Assurance of the TNA process."
  },
  {
    "id": "dc38187a-b5ff-4920-bad7-c39469937a69",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Reasons for undertaking a TNA include:",
    "content": "Support for a new fielded force or training equipment or service. Support for an enhancement to any equipment or support system already in service. A change in policy/legislation. A change to the doctrine underpinning the deployment of a capability. Changes to organisational structure or changed competence requirements. Performance deficiencies. Training constraints or availability of new facilities."
  },
  {
    "id": "4541e4fa-16ee-4555-a6e0-d16958863abe",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Where, for organisational, contractual, or other reasons, activities are distributed and/or responsibilities delegated other than as recommended, then this should be agreed at the CEB and annotated on the TrAD.  In all cases, any variance from the MTS must still be DSAT QMS compliant and auditable.",
    "content": "Table 1: Mandatory Analysis DSAT Activities for New Training Requirements"
  },
  {
    "id": "414e86fa-0653-4768-85b7-f15a69a5decc",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Activities undertaken as part of the Scoping Exercise should include:",
    "content": "TNA Terms of Reference (ToR) – 1.2.1.  Clear TNA ToRs will guide the subsequent analysis stages.  They should be agreed and clearly understood by the TRA, stakeholders and the personnel undertaking the DSAT activities.    Although the layout of ToRs may be adjusted to meet specific circumstances there are a number of key areas that should be considered: The scope and size of the TNA. Constraints, risks and assumptions. Outputs and reporting procedures. Timescales. The methodology to be adopted. Resource allocation and provision TNA Plan.  In order to estimate the timescales for the TNA it may be necessary to generate a plan, for inclusion with the ToRs.  A plan should detail the milestone dates for each activity to enable reviews by the relevant stakeholders.  The TNASG is responsible for ensuring that these activities take place.  It need not be detailed but as a minimum it should include what is to be done, by whom and when. Training Audience (and Throughput) Description – 1.2.2.  An estimate of who will be affected by the new or changed Defence requirement is required to ensure that it is representative and to determine throughput and input standards. It should include an estimate of the population to be trained in terms of their personal characteristics, the annual throughput, and the input standard.  This information can then be used to inform and refine the SOTR (5.5). Constraints Analysis – 1.2.3.  Any constraints affecting the TNA need to be analysed and recorded. Constraints may be identified in strategic trends, doctrine, concept documents (e.g. the Concept of Employment for a capability) or can be determined through contextual analysis (such as via PESTLE or other frameworks).  They should also involve consideration of all the Defence Lines of Development (DLoDs).  Key constraints include: Policy. Cost. Time. Safety. Legal. Resource."
  },
  {
    "id": "c71705c5-e593-46ed-87d0-63f1ae3b30d4",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "It should include:",
    "content": "References to the relevant training policies. Assumptions, freedoms and constraints. The conclusions, outputs or recommendations of previous relevant studies (if any). Membership of TNASG that will oversee the subsequent analysis stage. Recommendation to continue with the TNA if appropriate. TNA outputs. TNA Terms of Reference (ToR). Confirmation (or otherwise) that there is a training requirement that will fulfil the SoR (if there is not, the DSAT process should then cease). Recommended possible training solution option(s) to be taken forward into the analysis and design stages. A section on risk."
  },
  {
    "id": "bbd13f84-5708-4f74-8604-958f9a774f94",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Role Analysis (RA) – 1.3.  The duties, tasks, sub-tasks and task-elements performed by an individual constitute ‘the Role’.  The RA is the process of examining a specific Role in detail, in order to identify all the component duties and tasks, the Conditions under which the Role is performed, and the Standards to be achieved when performing the Role.  The ‘person in the Role’ should also be considered (see also Detailed Audience Description). In this way, it will be possible to identify the Knowledge, Skills and Attitudes/behaviours necessary for effective performance.  The RA should consider:",
    "content": "Role objectives. Duties and tasks. Standards. Conditions. Responsibilities. Difficulties and distastes. Criticality. Role-related factors influencing skill fade."
  },
  {
    "id": "75a2ad03-33e0-43f1-94cb-8d39e0bddde3",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Activities undertaken as part of the Role Analysis should include:",
    "content": "Identification of Role – 1.3.1.  A Role does not exist in isolation but within the context of a particular organisation and situation.  This context may affect not only the way the RA is conducted but also the eventual design of the training solution. Production of Role Scalar – 1.3.2.  A Role Scalar is produced by analysing the duties, tasks, sub-tasks and task-elements (Performance) that have to be performed and recording them diagrammatically.  The Production of the Role Scalar is a key part of the RA process as it defines the minimum Performance to be achieved. DIF Analysis – 1.3.3.  DIF Analysis is a method of analysing Role information through the Difficulty, Importance and Frequency of tasks and sub-tasks, with the aim of enabling early training decisions, such as the generation of Initial Training Categories. KSA Analysis – 1.3.4.  A KSA Analysis is a systematic analysis of ‘Performance’ and/or ‘Standards’ in order to identify the necessary KSA required to perform a Role. Initial Training Categorisation – 1.3.5.  A thoroughly conducted RA will be wide ranging and will include consideration of levels of supervision, work conditions, task criticality, difficulties and distastes, frequency of task performance, Role-related skill fade factors, percentage of personnel performing the Role and consequences of inadequate performance.  All of this information, in conjunction with information on trainee entry standards, trainee throughput and knowledge of the likely training environment, can lead to conclusions regarding the balance between training delivered as part of the TPS and training delivered as part of the WTS.  These conclusions are expressed through the use of training categories.  A number of techniques may be used to derive training categories, with the main analytical tool being the DIF Analysis already conducted (1.3.3)."
  },
  {
    "id": "b1e8faef-092a-4072-8fb6-c2e4c6ed5856",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Role Performance Statement (Role PS) – 1.3.6.  A Role PS is produced and maintained by the TRA and is a detailed statement of the tasks, sub-tasks and so forth that are required to be undertaken by an individual to achieve the articulated workplace Performance. It includes the Conditions under which the tasks will be undertaken, the Standards that must be achieved, and adds an indication of the importance of the training required to achieve the task Performance.  It forms the basis for all subsequent work leading to the production of TOs.  This ensures that the need for training and associated resources is justified by the needs of the Role.  It also ensures that the training undertaken remains focused on the Role.  Whilst a single Role PS can be produced to cover all the duties associated with a Role, a Role PS may alternatively be written for a specific duty where it is shared across many Roles (such as the duty of firefighting).  The Role PS is developed using:",
    "content": "Performance. Conditions. Standards. Training category. Role Scalar."
  },
  {
    "id": "2f5d98e3-ac4a-4596-80bf-b5fbc2f6ca16",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Training Gap Analysis (TGA) – 1.4.  The purpose of the TGA is to identify the additional training requirement of the affected Role holders by determining the training gap between the Performance, as stated in the Role PS and/or Framework(s), and any existing training Performance Standard(s).  This analysis also enables the impact upon Defence capability to be assessed if the new or changed Defence capability is implemented without additional training.  The TGA should provide:",
    "content": "An update of the information contained in the Scoping Exercise Report and RA (if required). The additional learning requirements, if any, of the Role holders in terms of KSA at the sub-task and task-element levels. A summary statement of the tasks identified for training. Statements of Training Gaps 1.4.1. These are statements in terms of the Performance delta between the requirements of the Role PS and/or Framework(s) and any existing TOs and EOs, including associated specialist qualifications, for each affected Role holder. The decision whether to provide additional training or not, by providing a summary of the implications of the new Performance requirements when compared to existing training.  This should be presented as statements for each task, identifying additional workplace and/or unit training requirements with a statement of any associated penalties regarding reduction in capability.  If the option to continue existing training with existing resources is an acceptable risk for all Role PS and/or Framework(s) identified in the RA, then the TNA is complete and a TOA may not be required."
  },
  {
    "id": "852f7365-bdd6-43c7-8cf9-ca51dffa7d6e",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Activities undertaken as part of the Training Options Analysis should include:",
    "content": "Fidelity Analysis – 1.6.1.  The term ‘fidelity’ denotes how closely a set of procedures were implemented as they were supposed to have been.  Fidelity can be defined as, ‘the exact correspondence with fact or with a given quality, condition, or event; accuracy (e.g. the fidelity of the movie to the book or the degree to which an electronic system accurately reproduces the sound or image of its input signal)’.  This analysis should be conducted as a result of the production of a Role PS and/or Framework(s) derived from the RA, and include any existing Training Performance Standards. Fidelity Analysis considers each relevant Performance objective in the Role PS and/or Framework(s) to assess the extent to which the training environment should replicate the workplace (real) environment to enable training to be effective. Location/Environment implications – 1.6.2.  The training environment and implications of location may well impact on the suitability of different training solutions. For example expensive or scarce training resources including simulators, real equipment or specialist instructors may only be available in some locations.  It is therefore important to determine an estimate of where the balance between training to be delivered in a training establishment and workplace training will fall. Methods & Media options – 1.6.3.  The training Methods and Media options selected will depend upon the type of training, training policy, training throughput and good practice.  An assessment is required of the relative training effectiveness of each Method and Media option to bridge the training gaps (as determined in 1.4.1), based upon the TGA of each option and the Defence need. Cost Benefits Analysis (CBA) – 1.6.4.  It is important that costing and investment appraisal are undertaken strictly in accordance with the current Defence or TLB policies and conventions.  If training specialists become involved with costing or investment appraisal, they should obtain current advice from the TNASG or other authoritative body.  CBA activity does not start at this stage of the TNA but the result of it is included in the Training Needs Report hence its inclusion here.  Like many aspects of DSAT, CBA is an iterative process with initial activity commencing much earlier in the TNA process, as appropriate.  The CBA will likely be further refined during the Method & Media selection process in Element 2 (Design, Stage 2, 2.5).  An estimate of the financial risks and/or opportunities associated with each training solution option should be undertaken and will be a significant factor in selecting training solution options.  Training analysts are unlikely to be qualified to conduct financial risk analysis at anything other than a superficial level and should therefore seek specialist advice and support. Options Evaluation – 1.6.5.  The final activity of the TNA is to decide on training options.  To evaluate the merits of the training options (determined at 1.6.2A) one of them should be selected as a baseline.  The selection of a baseline will depend on the context, which then permits the construction of a table to display the relative merits of each option against the baseline.  Options can be assessed via several criteria: The extent to which the option meets the requirements. Through-life cost, including the costs of maintenance, trainers and integration with existing training locations/environments. Implementation time, which may prove important to meet an operational need or a RFTD (1.1.1). Trainer load, or any consideration of the availability and competence of trainers to support training. An assessment of the risk associated with the options. Flexibility, or the ease with which the new training can be integrated with existing and potential future training, as appropriate."
  },
  {
    "id": "4b2e395b-00ff-47d0-ac87-6dbb13b33628",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Training Needs Report – 1.7. The Training Needs Report specifies the training requirement and recommends a training solution through the evaluation of options.  It should include the resources required to design and support the training.  Training Needs Reports should collate all the information from the scoping exercise and analyses stages, adding an Implementation Plan and TNE strategy.  It should also include a description of the TNA methodology in terms of the data gathering and analysis techniques and clearly reference the data sources consulted.  The TNA can then be written up as a Training Needs Report that provides or supports detailed user and system requirements.  Training Needs Reports should include:",
    "content": "Identification of the Performance requirement: a Role PS and/or Framework(s) for each Role holder, as identified in the RA. Identification of the training requirement: the results of the TGA. A Role PS and/or Framework(s) for the Role(s) affected by the recommended training solution with recommended training categories and supportive notes to amplify specific requirements to be included as appropriate to assist designers with the production of the FTS (during Element 2, Design, 2.2). Implementation plan, including where responsibilities lie (e.g. conversion training, date of new legislation and/or policy change, and design).  At this stage the draft TOs endorsed by the TNASG should be available and expressed as Performance, Conditions and Standards to enable implementation by the design team.  Any recommendation regarding estimation of resources, timings and assessments should be clearly referenced to aid the design team. Input to inform or refine the SOTR (for formal endorsement), to focus and direct the design stages. TNE strategy. The TNASG endorsed training solution, resulting from the CBA (1.9.1) and final selection using the Options Evaluation (1.9.2).  Fidelity requirements and associated risks, assumptions, constraints should be included in the Report."
  },
  {
    "id": "2a441399-9970-4ea4-953f-57229fb36df3",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Training design is the process that derives achievable TOs from the outputs of the TNA, as agreed between the TRA, TDA and the Training Provider. It then establishes the assessment, Methods & Media and LSpec.  The 3 stages of Element 2 are:",
    "content": "Design Stage 1. TOs – 2.1.  A key activity is to determine the TOs (based upon the Performance, Condition, Standards criterion set out in the Role PS and/or Framework(s)), based upon the draft TOs produced during Element 1 (TNA Stage 2, 1.5A/B). FTS – 2.2.  The FTS details the totality of the training that must be achieved to meet the requirements articulated in the Role PS and/or Framework(s). EOs and KLPs – 2.3. To aid development of the Learning Scalar and LSpec, EOs and KLPs are produced. Design Stage 2. AStrat – 2.4.  The AStrat articulates the summative and formative assessments for the ‘how’, ‘when’ and ‘in what manner’ training is to be assessed. Selection of Methods & Media – 2.5.  This activity ensures the most appropriate, effective and efficient selection of training Methods & Media, including any constraints that may limit options. Design Stage 3. Learning Scalar and LSpecs – 2.6.  Design Stage 3 structures the TOs and their dependent EOs and KLPs in the Learning Scalar, and brings together the collective outputs of analysis and design in the production of LSpecs.  LSpecs enable the delivery of lessons for all training activities (including for workplace training).  This is the content required for the Training Provider to deliver lessons."
  },
  {
    "id": "fbc2e381-ca4d-41a2-bfa2-14a5f81e812e",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Responsibilities.  Both the TRA and TDA are ultimately responsible to the CEB and Customer for the work conducted during the Design Element:",
    "content": "It is expected that the TRA will take the lead on Design Stage 1, the TRA may wish to delegate specific tasks but will retain overall responsibility for them. The TDA is expected to take the lead on Design Stages 2 and 3 activities, processes and outputs, which are required to be completed during Element 2.  The TDA may wish to delegate specific tasks but will retain overall responsibility for them."
  },
  {
    "id": "287340e5-4f53-4283-8343-55eb5d279c98",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Where, for organisational, contractual, or other reasons, activities are distributed and/or responsibilities delegated other than as recommended, then this should be agreed at the CEB and annotated on the TrAD.  In all cases, any variance from the MTS must still be DSAT QMS compliant and auditable.",
    "content": "Table 2: Mandatory Design DSAT Activities for New Training Requirements"
  },
  {
    "id": "09c3c762-e127-4f4a-9f30-4d083b807f8f",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Formal Training Statement (FTS) – 2.2.  TOs are the key component of the subsequent training statements that form the FTS which should be made up of a Training Performance Statement (TPS), a Workplace Training Statement (WTS), and a Residual Training Gap Statement (RTGS).",
    "content": "TPS – 2.2.1.  The TPS details TOs (in terms of Performance, Conditions and Standards) to be attained by trainees.  The TPS TOs are managed and/or delivered by the TDA. WTS – 2.2.2.  The WTS details TOs (in terms of Performance, Conditions and Standards) to be attained by trainees following assignment to a Role.  The WTS TOs are managed and/or delivered by the employing unit. RTGS – 2.2.3.  The RTGS is the difference between the totality of the training received and the Role PS and/or Framework(s).  It is the gap where an element of the Role PS and/or Framework(s) has not been allocated a training activity.  The Residual Training Gap is expressed in terms of Performance, Conditions, and Standards.  The RTGS also states the reasons and consequences of any identified RTG, and management of any associated risks."
  },
  {
    "id": "cc5b842a-9b41-4156-958a-3d339c6c801b",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Activities conducted as part of a AStrat should include:",
    "content": "Refinement of Knowledge, Skills and Attitude (KSA) – 2.4.1.  Prior to the development of the ASpec, from the AStrat, it is important to revisit the KSA Analysis (1.3.4), which was conducted as part of Element 1.  Refinement of the KSA Analysis will ensure that the ASpec is appropriate to the requirement and ensures that assessment is developed taking into account what is to be assessed. Assessment Specification (ASpec) – 2.4.2.  While the AStrat gives an overview of the training assessment, where testing is required, the detail is provided in the ASpec.  An ASpec is defined as a specification describing the organisation, type of test, marking details, pass/fail criteria for the assessment of TOs and the consequences of failure.  It provides practical details required to assess the achievement of the Standards specified by an associated TO."
  },
  {
    "id": "5ccd1ca9-e2f9-4e83-98d2-0f8a5ac7101e",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Selection of Methods & Media – 2.5.  It is important to consider the most appropriate and effective blend of training Methods & Media that provides the most effective balance of performance, cost and time in achieving the required KSA.  During Element 1 Methods & Media options (1.6.3) were developed and considered as part of the CBA (1.7.1), in order to ensure that the Options Analysis (1.7.2) recommended a training solution with realistic Methods & Media options.  These options should now be further refined as part of the Design process by exploring, in order:",
    "content": "Methods.  These are the strategies or techniques used to achieve the required KSA. Media.  These are the tools and means used to apply the Methods selected."
  },
  {
    "id": "77ae0735-3975-4641-a359-ee1cceaa7987",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Where, for organisational, contractual, or other reasons, activities are distributed and/or responsibilities delegated other than as recommended, then this should be agreed at the CEB and annotated on the TrAD.  In all cases, any variance from the MTS must still be DSAT QMS compliant and auditable.",
    "content": "Table 3: Mandatory Delivery DSAT Activities for New Training Requirements"
  },
  {
    "id": "89e4db96-070e-45a7-beaf-5080ecf50fa6",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Assessment of learning – 3.1.2.  Assessment is an essential aspect of any training which must be properly understood and applied.  Assessment requires the trainer to determine whether learning has occurred which requires making a judgement on trainee Performance and progress, then to decide whether the trainee is sufficiently competent in a particular Role or Task to be qualified for employment and/or work with or without supervision.  The proper conduct of assessment in training can have a major impact on training time and resources, but ultimately will contribute directly to Defence outputs.  Trainers should be able to administer assessments in training in a fair, valid and reliable manner in accordance with the AStrat and ASpecs.  This is achieved through the use of an up-to-date ASpec when planning an assessment; assessing all of the EOs and KLPs as specified in the ASpec and not make any changes that alter these; as well as the standardisation of conduct and moderation of marking:",
    "content": "Standardisation.  Standardisation is achieved by adhering to the direction given in the AStrat and ASpecs.  If an assessment is conducted using the same instructions every time, all trainees should receive exactly the same assessment, regardless of when, where and by whom the assessment is conducted. Moderation.  Moderation of marking can help to ensure that the marking of assessments by different trainers is equitable and fair. For example, by having a proportion of assessments marked for a second time by a different trainer without first seeing the original score or grades awarded; the resulting scores are then compared for consistency.  Where scores do not agree, trainers should consult with other trainers, and as a team, identify where the problem may lie. Any problems with the marking criteria should be highlighted to the DTS, DTM or Chain of Command."
  },
  {
    "id": "55f73af6-5557-432c-ac9a-3a085f6265bd",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Programming training – 3.3.  The Training Provider should produce and maintain an annual programme of all training activities.  Any changes which arise within the current Training Year (TY) should also be reflected in the annual programme of training activities.  There is no suggested methodology for programming; A common sense approach should be used and a clear understanding of the freedoms and constraints available to programmers will ensure that training activities:",
    "content": "Use available resources efficiently and to maximum effect; Match the most effective and efficient Method & Media to the desired learning outcome; Generate variety, stimulation and interest; Programme different activities intelligently (such as not programming a lecture directly after a session of PT) and build progressively; Build in time for movement, administration, rest, meals and breaks; Consider environmental, seasonal, weather or light factors if required (for outdoor practical training); Use a standardised programming format that builds routine and publish changes to the norm early; Simulate, replicate or use realistic or real Conditions; Have a method of informing trainees and trainers of unavoidable, short notice changes to the programme; Minimise the administrative or non-training burden to the trainee."
  },
  {
    "id": "fe455f82-1d04-45ba-bc91-17435956f8bc",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Resourcing training – 3.3.  Resourcing the training activity is intimately tied into its programming and scheduling.  The Training Provider, supported by the TDA and other stakeholders, should ensure that the activity is properly resourced.  This is in order to implement and maintain the Training System, continuously strive to improve its effectiveness, and enhance Customer satisfaction by meeting the TRA’s training requirements. Resources include:",
    "content": "Human resource.  The personnel involved in all aspects of DSAT, particularly in the delivery and evaluation of the training activity should be trained and competent to carry out their Roles.  It is the responsibility of the TDA, enforced by the Training Provider, to ensure that all training staff are provided with the appropriate training and have relevant experience. Infrastructure and environment.  The Training Provider, supported by the stakeholders, should also determine, provide and maintain the infrastructure and working environment needed to achieve the trained output, which includes: buildings, workspaces and associated utilities; training equipment and support equipment (both hardware and software) and training estates (with associated facilities); supporting services."
  },
  {
    "id": "6873600e-84a0-452b-b18d-ab2e4533ac88",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "There should be 3 stages to the pilot, they are:",
    "content": "One-to-One Trial. Small Group Trial. Field Trial."
  },
  {
    "id": "5a6a6ecc-859d-4d8f-a57d-0bcecaeea9c8",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Where, for organisational, contractual, or other reasons, activities are distributed and/or responsibilities delegated other than as recommended, then this should be agreed at the CEB and annotated on the TrAD.  In all cases, any variance from the MTS must still be DSAT QMS compliant and auditable.",
    "content": "Table 4: Mandatory Assurance DSAT Activities for ALL Training Requirements"
  },
  {
    "id": "07b92b03-6ce8-484c-87bd-655aa431eddd",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "InVal – 4.1.1.  InVal is a process used by the Training Provider to determine the efficiency and effectiveness of training delivery.  To achieve this, InVal measures:",
    "content": "The immediate reaction of a trainee to a training activity. The learning transfer achieved by the training activity."
  },
  {
    "id": "e49ba34a-04d7-4388-a04b-2b1f2e0225d8",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "COTEs will be held to account for ensuring that:",
    "content": "the Training Quality Manual (TQM) reflects the structure of the organisation and the monitoring and development procedures for Defence Trainers. people under their command who are engaged in training delivery or have contact with trainees are appropriately trained and qualified in accordance with this Direction and also have any additional necessary competences. there are sufficient Defence Trainers, DTSs and DTMs and the command structure within which they operate is configured to ensure that the requirements of this policy direction are achieved. their FLC TRA is informed via the TDA of any risks and/or issues relating to the DTC so that these can be raised at the appropriate governance meeting."
  },
  {
    "id": "6b469e1a-b7a0-4f73-8b1c-2c29d423b1d8",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Contractor",
    "content": "CONTRACTOR STAFF DELIVERING, SUPERVISING OR MANAGING DTC TRAINING INTERVENTIONS"
  },
  {
    "id": "d3beb720-a0b7-4ae7-842d-bf99b1cacf2e",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Defence Direction on Remedial Training in Initial Training",
    "content": "Policy Sponsor: TSLD, CDP"
  },
  {
    "id": "d2ba0253-a2da-4abc-932b-2614c943b957",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The vision for Defence initial training (Phase 1 and 2) is to create an environment that attracts and retains high-quality people through the provision of training that, whilst stressing the importance of the team and team ethos, is focused on the individual from recruitment to entering productive Service.  Training is by necessity challenging – it has to transform civilians into professional Service personnel (SP) capable of operating in the harshest of global environments and pressured situations.  It must imbue SP with an attitude of responsibility, self-discipline and selflessness: fundamental components of military ethos that are essential to maintaining operational effectiveness.  The two principle components of initial training are to:",
    "content": "ensure that recruits and trainees learn the skills and knowledge, appropriate to their trade/branch/specialism, so that they are suitably equipped and prepared to enter productive Service. inculcate the right attitudes in terms of military ethos, values and standards required of a SP and ensure that all recruits and trainees embrace the disciplinary, personal and communal standards that constitute that ethos."
  },
  {
    "id": "7e742aff-ba2b-4426-a993-af17e9b7cb70",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "In accordance with JSP 833, measures must not contain any of the following: unreasonableness; public humiliation; sustained and oppressive treatment which amounts to or could reasonably be construed as harassment, including any form of bullying; sleep deprivation or deliberate infliction of pain; or work for any other benefit than that of the Service or individual’s rehabilitation.",
    "content": "SCOPE"
  },
  {
    "id": "ccb472f2-e66a-4472-88df-56d09792f75c",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "This Defence Direction applies to all Phase 1 and 2 training, and any period between these two Phases when trainees may be awaiting entry into a training module or phase.",
    "content": "AIM"
  },
  {
    "id": "921aad6e-cf70-4e62-adcc-47752a1c801d",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Deficiency of Skill, Knowledge or Physical Fitness. A trainer’s judgement of a recruit or trainee whose performance is below par should include consideration as to whether the individual may have Specific Learning Differences (SpLD) and, if appropriate, assessment to determine such.  When the shortcoming is in part or wholly caused by a lack of skill, knowledge or physical fitness, then the appropriate RT to address the deficiency is:",
    "content": "Deficiency of skill or knowledge.  To repeat the training serial or to give additional instruction that will bring the recruit or trainee up to the required standard. Deficiency of physical fitness.  To provide additional physical fitness training to reduce any physical fitness deficiency."
  },
  {
    "id": "24a101b9-70a6-4c74-aad5-c11461213b68",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "RT to address inappropriate behaviour or attitude.  RT undertaken to address substandard performance during initial training is not punishment and must not be used or treated as such.  RT measures to address unacceptable attitude or behaviour during training are separated into 2 categories:",
    "content": "Tier 1 measures.  These are short, sharp measures to achieve short-term behavioural change and can be implemented by the trainer without reference to a higher authority.  Each training establishment, in conjunction with their sS policy, is to issue Direction on what Tier 1 measures are appropriate to their situation.  These can include: Verbal rebuke.  A short, sharp verbal rebuke by the trainer to highlight the attitudinal or behavioural shortcomings. ‘Wake up’ exercises.  These are short, sharp exercises designed to re-focus trainees on the training that is being undertaken.  TDAs are to publish clear instructions on the scale and type of exercises that can be awarded and supervised by non-PT qualified trainers.  It is stressed that ‘wake up’ exercises are short in duration and designed to refocus the recruit or trainee on the current training objective and are not to become an ‘activity’ in their own right. Immediate repetition of a training activity.  This is a measure to demonstrate to a recruit or trainee that their attitude or application on first attempt was unacceptable and should normally be conducted without interruption to the training programme. Minor additional tasks.  These will be tasks directly related to observed levels of unacceptable behaviour, which must be undertaken immediately and without interruption to the training programme. Tier 2 measures.  These are more onerous measures which are aimed at addressing longer-term attitudinal or behavioural shortcomings, but which do not merit initiating disciplinary action.  These will usually be undertaken outside of the normal training programme. Training establishments are to issue instructions defining the nature and scope of Tier 2 measures and the procedures for managing them, including who can authorise such measures.  The only Tier 2 measures are: additional training event. additional duties. show parade."
  },
  {
    "id": "1ca96881-118c-4fec-8401-160c9a9a14eb",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Tier 1 and 2 measures are one part of the process of achieving attitudinal improvement.  When a trainer judges that it is necessary to use Tier 1 or 2 measures they must be:",
    "content": "justifiable due to an observed shortfall in behaviour or attitude. in proportion to the nature and scale of the shortcoming in attitude or behaviour. achievable without compromising other aspects of the training programme. undertaken quickly to establish the link between the shortcoming and the RT. compatible with current Direction on bullying and harassment.  There is clear distinction between bullying and/or harassing behaviour and RT measures. designed to avoid causing injury or psychological damage to the recruit or trainee where this is reasonably foreseeable (the recruit or trainee’s limitations and medical condition must be taken into account and physical activity is not to be imposed against medical advice). undertaken routinely within the working day or out of normal instructional hours or at weekends, if necessary, and if it meets all the requirements of this Direction and sS policies. supervised by an appropriate member of training staff who is both qualified and experienced to impose the measures. communicated effectively to the trainee, explaining the deficiency observed, taking account of any excuse offered.  It may be that a formal interview is appropriate depending on the nature of the shortcoming, the stage of training and the progress of the recruit or trainee.  This is often useful in identifying the underlying problem."
  },
  {
    "id": "3c8b1822-ab24-4110-9e85-9ed60b9e1d3b",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Action taken to remedy substandard performance may involve both additional instruction and Tier 1 or 2 measures, with the balance and scale of each being based on the trainer’s analysis of the cause of the problem.  The application and implementation of RT, in relation to disciplinary, administrative and withdrawal action is shown at Figure 2.",
    "content": "Figure 2: Application and Implementation of Remedial Training"
  },
  {
    "id": "6fd7a4bf-3522-4aab-9e5b-7669ba96eeba",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Recording of RT. The effective management of substandard performance relies on the experience and judgement of trainers employed within initial training establishments, who are fully supported by the Chain of Command.  With the exception of verbal rebukes, all RT measures used to rectify performance issues are to be recorded, and include:",
    "content": "the recruit or trainee’s name and Service number. the deficiency, the date and the relevant TO, if appropriate. the action taken. the trainer and the supervisor of the RT. any other relevant information, such as that which demonstrates how the RT meets the requirements of this Direction and achieved the modification in behaviour or improvement in knowledge or skill."
  },
  {
    "id": "c126aa17-2951-4f2c-aa92-b2b2bc1bcf05",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The method and format for record keeping is to be determined by sS but an auditable process linking this Direction to the actions taken by trainers is required.  Formal interviews should also be recorded.  Records are to be scrutinised weekly by a responsible officer and monthly by the Chain of Command.  All records are to be stored and maintained within training establishment for 2 years and are to be available for scrutiny by assurance bodies such as sS Inspectorates and Ofsted.",
    "content": "GOVERNANCE"
  },
  {
    "id": "55ed8cb7-201b-4835-82a7-e1654f95663d",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "TRAs.  A degree of sS variation is required in the application of this Direction to reflect the operational role and diversity of the training population.  Via the CEB process, TRAs are to ensure:",
    "content": "through their TDAs, that a consistent approach to RT is applied across all subordinate Defence training establishments iaw this Direction. they have oversight of instructions issued by initial training establishments (through TDAs) that implements this Direction.  The instructions will normally be contained within the Trg Quality Manual which is endorsed by the TRA at the CEB. that all initial training establishments and TDAs have an appropriate recording system."
  },
  {
    "id": "c5d855c2-cbc5-49b7-86c3-8c9f7113ed34",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Defence Direction on Robust Training",
    "content": "Policy Sponsor: TSLD, CDP"
  },
  {
    "id": "cdd2c3fc-cd69-4746-b9bb-7057d4536f87",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Purpose and Application.  The purpose of Robust Training is to progressively develop a Service Person’s (SPs) resilience to enable them to perform effectively in any operational environment.  The degree to which Robust Training is employed within an Initial training programme should reflect the employment of that SP in both specialist and generic tasks.  Emphasis should be placed upon the need for SP to perform in the most demanding conditions in which they may realistically expect to find themselves if deployed to high-tempo and/or high-threat operational environments.  As Defence transitions to a contingent posture, the non-linear nature of the Contemporary Operating Environment (COE) will inevitably expose SP from support functions to higher risks than would have traditionally been the case.  It is therefore no longer acceptable to have a situation where combat personnel and support or service support personnel sit at distant ends of a wide spectrum of individual resilience.  This gap should be narrowed if all SP are to be best prepared for operational service.  This requires moral courage to implement and there is a need for a coherence of approach across Defence and single Service (sS) training establishments to ensure that Robust Training is systematic, progressive and appropriately contextualised.",
    "content": "PRINCIPLES"
  },
  {
    "id": "6588f345-2e87-4f7a-aa64-a5a3b421783d",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Tailored.  Due to the wide range of training in Defence and the breadth of job specifications within both commissioned and non-commissioned ranks, what could be defined as Robust Training for one training cohort may not be suitable or appropriate for another.  While many operational conditions are similar for all, it is unlikely that any but the most generic of Robust Training events will be appropriate across Defence.  Robust Training must be designed to be relevant to the roles and duties of the recruit or trainee and likely employment on operations.  Robustness comes in many forms, both physical and mental.  sS and Defence training establishments need to implement a ‘continuum of robustness’ that threads through all phases of training, and which must be:",
    "content": "Relevant.  sS training has spent the last decade or more delivering capability to defined operational theatres with (largely) understood threats.  As Defence returns to contingency the certainty of future operational environments and the threats that emerge may be less defined and less clearly understood.  This uncertainty requires a refinement within training if we are to produce a new generation of robust, self-sufficient and capable SP. Contextualised.  sS training needs to provide ‘immersive’ scenarios to allow recruits and trainees to contextualise their training.  It is necessary to replicate the physical and mental pressures of operations that are specific to Service and role, noting the need to ensure that supporting personnel should also build resilience through Robust Training.  If all SP are to be best prepared for operational service, training needs to focus on the increased resilience end of the spectrum and where possible enhance the psychological stressors in training (e.g. increased use of battle simulation, additional night training scenarios) and the physical stressors (e.g. extending training days, more time living ‘in the field’ or austere simulated operational conditions). Delivered to defined standards.  The ability to measure how successfully sS deliver training that challenges a recruit or trainee to develop physical and mental resilience should be achieved via measures of performance whilst in Initial training, and through measures of effect once SP join their respective Commands.  Detailed assessment through both InVal and ExVal will be essential in determining the degree to which Robust Training is succeeding. Delivered with calculated risk.  The acceptance of risk is important, and its application must be understood at all levels of training delivery.  It must be proportionate to the delivery of the defined operational output.  There is both a moral obligation to prepare recruits and trainees appropriately for the rigours of operational Service, and a need to recognise that a Robust Training regime may lead to injury, increased wastage rates or litigation.  These factors are not mutually opposing or irreconcilable.  Robust Training can be delivered during all phases of training whilst successfully discharging Defence’s welfare and Duty of Care responsibilities.  The risks associated with Robust Training must be identified, assessed and addressed with a view to enabling this important element of training.  A culture of risk aversion must be avoided as it merely transfers risk to the Commands and is morally unjustifiable.  It is incumbent upon Commanders, their staff and trainers to be conversant with the principles and application of risk assessment at their respective levels of training command.  Intelligent risk management must be led by the Commander and understood by all staff involved in training delivery.  The first step in developing risk management locally will be through the CRA/SCD process.  Detailed briefing on local procedures must be included in staff/trainer induction training and understanding must be developed further through regular study periods Appropriate supervision.  The level and style of supervision needs to be tailored to the level of risk, the type of training and the ability and confidence of the recruits or trainees. Trust in the Chain of Command.  The application of Robust Training may be compromised, at least in part, by a mutual lack of trust between training staff and their Chains of Command.  This can be compounded by a perception amongst trainers that there has been a shift in emphasis to the recruit’s or trainee’s care needs that conflict with challenging, engaging and robust training.  Recruits and trainees must be empowered to ask questions and appropriately challenge the ‘recruiting promise.’  This should not, however, be viewed as a challenge to the core tenets of sS Values, Standards and Ethos, or the Chain of Command.  Trust needs to be established early so that there is an understanding of what is required and the rationale behind Robust Training."
  },
  {
    "id": "b98a1482-ce56-4a94-aa20-cdd9a8f3d2df",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "The following pressures could contribute to training being classified as robust.  The list is not intended to be prescriptive but, rather, provide examples.  Equally, the list is not exhaustive, and it must be read in conjunction with the points made above.  Some examples of Robust Training activity are at Table 8.  This list is intended to be illustrative rather than exhaustive:",
    "content": "Psychological pressures. rapidly and or frequently changing priorities introduction of extra information or introduction of situations in which there is incomplete information. reduction in time allocated for a task. dislocation of expectations. enhanced perception of danger/risk and consequence of failure. realistic simulation of operational challenges and operational ‘friction’. significantly increased responsibility. Physical pressures. climatic injuries and other environmental factors – heat / cold / wet / darkness. exertion and physical effort. tiredness/controlled sleep deprivation. Table 5: Examples of Robust Training"
  },
  {
    "id": "6383b915-cf60-4c93-a5a3-595e864897ac",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Document Coverage",
    "content": "The contents of this policy supersede all previous MOD Policy on Defence Individual Training."
  },
  {
    "id": "c6ae6555-f8bb-4c85-b9ff-96b74aa3e982",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Document Versions",
    "content": "MOD will review this Policy in three years, or when changes to legislation or best practice dictates."
  },
  {
    "id": "fd5e04e0-a637-40ff-bc21-a995f89b406d",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Applicability",
    "content": "The policy contained in this Volume applies to the Whole Force which encompasses Regular and Reserve personnel, MOD Civil Servants, and civilians, including the Ministry of Defence Police and contractors. It is noted that training sourced through the pan-Governmental ‘Civil Service Learning / Government Campus’ is not subject to the policies in this document. Any other Civil Service training must be compliant with the policies in this document. The policy in this document does not apply to training deemed ‘Informal’ or ‘On-the-Job’. Organisational Learning is captured under the Defence Organisational Learning Strategy (DOLS) Framework owned by Joint Warfare in UKStratCom and is not within the scope of JSP 822."
  },
  {
    "id": "0da285c4-0fe6-4d5a-a74e-36cfa4df551c",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Diversity and Inclusion",
    "content": "MOD respects and values people of all backgrounds. The Individual Training policy is designed to ensure all employees are treated in a fair, transparent, and consistent manner. All those involved in the management of MOD employees must abide by legislation and should adhere to MOD policy. For more information on diversity and inclusion, please see the  on MODnet. This policy has been subject to an Equality Impact Assessment (EA)."
  },
  {
    "id": "57b9b595-b68f-4aa4-adaa-cd5aec5c5db9",
    "document": "JSP 822 V7.0 Vol 2 V3.0 Defence Individual Training.docx",
    "section": "Glossary",
    "content": "The Glossary of Definitions, Terms and Acronyms can be found on the  Sharepoint site."
  },
  {
    "id": "724bd055-e4e1-49fc-9758-3a280d2b245f",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Uncategorised",
    "content": "JSP 912 Human Factors Integration for Defence Systems Part 1: Directive Version 3.0 Mar 2024"
  },
  {
    "id": "d259f86c-c4fd-4e89-8eda-1e0ffa08e7cd",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Foreword",
    "content": "Capability is not just a function of equipment performance, but depends on a combination of interacting elements. Some of the most difficult issues to address lie in the Human Component of Capability. The equipment and systems have to be operated in a demanding and diverse military context in circumstances of fatigue, hunger, stress and even fear. Ultimately their usability in these demanding environments will determine our operational success. The types of equipment and systems we are now specifying and procuring will also shape the roles, responsibilities and career paths of future service personnel who we recruit, and our ability to retain them. Approaching our Defence needs from a capability direction, rather than a platform, system or equipment one, heightens the need for Human Factors Integration (HFI) of Defence systems. We must set out to deliver solutions that enhance our capability aspirations with a more sophisticated understanding of the role of people in the operation, maintenance and support of our future systems. The challenge is to integrate the people provided by the Armed Forces (including Reservists), with the equipment developed by industry and delivered by the Ministry of Defence, in a way that maximises capability within the real operational environment. Joint Service Publication 912 promulgates the policy requirements and comprehensive practical guidance for undertaking HFI. This Part 1 of JSP 912 provides the direction that is mandated by Defence, and is sponsored by the Defence Authority for Technical and Quality Assurance. It provides policy-compliant business practices that should be adopted in the absence of any contradicting instruction. I commend it to you and your staff. Stephen Wilcock Director, Engineering & Safety Defence Functional Authority for Technical, Quality & Standardization"
  },
  {
    "id": "74740869-5510-4332-9bdd-3e5e176292af",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "How to use this JSP",
    "content": "JSP 912 mandates the application of Human Factors Integration (HFI) in all Defence acquisition projects. It is designed to be used by MOD staff responsible for HFI. This JSP contains the policy and direction for the application of HFI and guidance on the processes involved and best practice to apply HFI in Defence Systems. This JSP will be reviewed every two years. The JSP is structured in two parts: Part 1 - Directive, which provides the direction that must be followed in accordance with statute or policy mandated by Defence or on Defence by Central Government. Part 2 - Guidance, which provides the guidance and best practice that will assist the user to comply with the Directive(s) detailed in Part 1. In particular, the guidance summarises HFI processes that are available in the MOD’s Human Factors Integration Management System ()1."
  },
  {
    "id": "360109c2-921e-41d8-b567-95fe009b59e0",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Coherence with other Policy and Guidance",
    "content": "Where this document contains references to policies, publications and other JSPs which are published by other Functions, these Functions have been consulted in the formulation of the policy and guidance detailed in this publication."
  },
  {
    "id": "9b91ac90-a0c8-45e5-9a31-1b68339cf914",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Training",
    "content": "For training applicable to HFI, consult the following: Human Factors Integration - Making The Most of People in Systems (available through the Defence Learning Environment): HFI Awareness Training (available on e-solutions2): 1 HuFIMS is hosted on the MOD’s Knowledge in Defence (KiD) website: 2 If you do not have access to e-Solutions but wish to attend the Awareness Training please contact:"
  },
  {
    "id": "e790b599-ccb5-4c2b-98c7-57d90e6dd654",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Further Advice and Feedback – Contacts",
    "content": "The owner of this JSP is the Defence Functional Authority for Technical, Quality & Standardization and it is managed by the Defence Equipment & Support (DE&S) Engineering Function HFI Team. For further information or advice on any aspect of this publication or to provide feedback on the content, contact: Contents"
  },
  {
    "id": "5856f3ec-2d01-45c3-9f03-25e676eccd8d",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Policy",
    "content": "The terms ‘Human Factors (HF)’, ‘Human Factors Engineering (HFE)’ and ‘Human Factors Integration’ are often confused. ‘Human Factors’ refers to a range of disciplines (principally scientific), which relate to the study of human capabilities, limitations, characteristics and behaviour in the broadest possible sense. It includes the study of human interactions with technologies and social interactions and draws on many scientific disciplines, including ergonomics, psychology (and neuropsychology), physiology, biology, anthropometry and biomechanics. It provides the knowledge base from which Human Factors Engineering draws. HFE is concerned with the application of this knowledge in the design, development, assessment, fielding, in-service support and disposal of products – equipment, sub-systems, systems and platforms. In contrast, HFI is a management activity, which includes a systematic process for identifying, tracking and resolving people-related considerations (especially risks and issues), to ensure a balanced development of both technological and human aspects of capability. It is imperative to understand that HFI is more than HFE. It comprises the following five domains: Personnel. Training. Human Factors Engineering. System Safety & Health Hazards. Organisational & Social. Details of these domains are included in Part 2 (Guidance) of this JSP. The HFI Domains span a number of different technical disciplines and are not entirely owned by the Human Factors Specialist. For effective Human Factors Integration, a number of different, but related disciplines need to interact in order to ‘deliver’ HFI. The multi-disciplinary nature of HFI and how specific disciplines need to work together is illustrated in Table 1. Table 1: Mapping of HFI Domains to Discipline Owners It is only through the effective integration of the disciplines representing these domains that the full benefits of HFI will be realised. For this reason, it is MOD Policy that HFI shall be applied to all defence acquisition activities, across the range of programme and project types: Development Items, Non-Development Items and Off-The-Shelf Items as well as technology demonstrators, and upgrades to existing items. In all systems that provide Defence Capability, the Equipment Component and the Human Component shall be satisfactorily integrated such that: the roles assigned to people in the Solution enable the required capability performance to be achieved under all predicted conditions of use. the design and realisation of the Solution: makes best use of Human capabilities (physical, psychological and social characteristics). recognises and provides for Human needs. provides mitigations for Human limitations. applies to all people (‘End Users’) involved in fielding of the system including, but not limited to, operators and maintainers. utilises people in ways that maximise system safety. utilises people cost-effectively. controls through-life costs (e.g. through minimising the need for training and the personnel associated with operation and maintenance). This JSP prescribes a set of high-level HFI activities that are applicable to all types of Defence Capability Acquisition projects. However, given the range and diversity of such projects, this JSP does not prescribe a single set of detailed HFI activities. HFI activities undertaken by Solution Providers shall be contracted against Defence Standard 00-251, Human Factors Integration for Defence Systems [1]."
  },
  {
    "id": "d1f662bf-0610-4b35-a43d-7b108a92e8e8",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Scope",
    "content": "The scope, extent, depth, complexity and thoroughness of all HFI activities to be undertaken, shall be determined against considerations of risk to the project and programme outcomes presented by people-related considerations. These will be typically assessed in terms of capability goals, objectives, cost, time, system performance, system safety and system usability."
  },
  {
    "id": "8c0df11f-9679-4359-81a5-bf1fccc7ba5d",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Applicability",
    "content": "This HFI Policy shall be implemented from the outset of all Defence Capability development, where early decisions on MOD requirements, concepts of use, system design, system constraints and assumptions will determine the ultimate effectiveness of the system. The Policy shall be applied throughout the life of the capability. This JSP shall apply to all MOD staff in all phases of the system life cycle, from Pre- Concept through to equipment disposal / service termination, but especially the following capability stakeholders: Customers\t(capability\tplanners,\tcapability\tsponsors\tand\trequirements managers). Delivery Agents (Project / Delivery Teams). Defence Line of Development (DLOD) owners. Trials Units/Organisations. Specialist Engineering Functions. End Users3. 3 End Users is an all-encompassing term to include all users of a capability, regardless of Armed Service, rank or role. It includes operators, maintainers, trainers, support personnel, and so forth."
  },
  {
    "id": "4d036937-44de-43a2-92b3-4a474fbaff75",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Associated Standards and Guidance",
    "content": "The primary standard for HFI and HFE is Defence Standard 00-251 Human Factors Integration for Defence Systems [1]. Other Defence Standards do provide some guidance on HFI/HFE, but Defence Standard 00-251 is the primary document for contracting purposes. Other relevant standards and guidance: Human Factors Integration Management System () including the HFI Technical Guides [2]. Defence Standard 23-009, Generic Vehicle Architecture (GVA) [3]. System Readiness Levels [4]. Guide to Engineering Activities and Reviews (GEAR) [5]. Defence Standard 00-600, Integrated Logistics Support Requirements for MOD Projects [6]. The terms used in this JSP are defined in the Glossary in Part 2."
  },
  {
    "id": "07e8e697-4a96-4436-9f6c-142c72597ab4",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "HFI Process Goals",
    "content": "In all MOD Capability Acquisition projects, the following HFI goals shall be fully pursued to achieve satisfactory outcomes. All HFI activities that are undertaken shall relate to and support one or more of the itemised goals: ensure that all people-related Risks, Assumptions, Issues, Dependencies and Opportunities (RAIDO) are identified and managed from the very outset of a project, and throughout the rest of life cycle. ensure that all Human Factors Process Requirements (HFPRs) are specified, thereby assuring that HFI processes are properly and adequately undertaken. ensure that Human Factors System Requirements (HFSRs) are specified, thereby assuring that people-related technical aspects of the Solution are properly and sufficiently addressed (based on the identified RAIDO). ensure that a human-centred design approach is adopted, involving the End Users in system and equipment design and evaluation. ensure that established Human Factors principles, accepted best practice, and suitable methods, tools, techniques and data are used. ensure that the HFI programme is designed to align and integrate effectively with the project life cycle. ensure that people-related considerations of the Solution undergo formal scrutiny, assessment and acceptance."
  },
  {
    "id": "4e77b56c-ac1e-484c-80cc-eee65257cc67",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "HFI Process Activities",
    "content": "This JSP prescribes a set of HFI technical and management activities that are applicable to all types of Capability Acquisition project. The six, top-level process stages4 span all stages of a project – Pre-Concept, Concept, Assessment, Design, Manufacture, In- service, Disposal (CADMID) – as shown in . MOD Staff or contracted representatives shall organise and conduct tailored HFI activities systematically, and these activities shall be commensurate with the actual project phase, size and complexity. A detailed description of the HFI process and individual activities can be found in JSP 912 Part 2 [7]. Guidance concerning how to comply with the HFI Policy, including Product Descriptions for the minimum content of key HFI deliverables can be found on  [2]. This JSP assumes HFI processes are aligned with a generic, Systems Engineering life cycle, e.g. International Standards Organisation / International Electrotechnical Commission (ISO/IEC) 15288:2023 [8], as widely used by MOD and Industry. 4 Note HFI in the Disposal phase will normally follow HFI process stages 1-6 on a much smaller scale Figure 1: HFI Process Activities"
  },
  {
    "id": "9686a249-3831-4e98-9eca-886a7aba4aa8",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Tailoring",
    "content": "Tailoring is fundamental to the cost-effective application of HFI on a project. It is the process of identifying and specifying the range and depth of HFI activities that should be carried out and depends on the scope, size, complexity, life cycle phase and contractual arrangements of any given project. Prior to Outline Business Case (OBC), the Authority shall consider internally the range and depth of HFI activities that it expects to be carried out, and tailor them accordingly. This should include a pan-DLOD consideration of the areas of greatest perceived HFI risk, as identified by an Early Human Factors Analysis (EHFA). This process shall be revisited during the tender preparation phase, to ensure that the earlier tailoring assumptions and considerations remain valid. The results of the tailoring process shall be reflected in the documentation issued to the tenderers, who will be expected to respond accordingly. Further tailoring may take place following Contract Award. This shall be conducted jointly by the Solution Provider and the Project Team (PT) or Delivery Team (DT), with agreement from key stakeholders5. The final decision as to whether tailoring is acceptable must be made by the MOD. The acquisition strategy will influence the extent and scale of HFI activities that should be undertaken. Related issues will include: How will the system be developed? Is it completely new, modified or an existing system? Will the Authority buy just the equipment, a complete capability package, or lease the system? The PT is responsible for tailoring the HFI activities by considering the amount of design freedom and the availability and applicability of information in all the HFI domains. Efforts should then be concentrated on the areas where most benefit can be achieved and/or risk avoided (as identified in the people-related considerations). Guidance concerning tailoring of the HFI process is available from the DE&S HFI Team ( ). 5 Key stakeholders will usually be represented at meetings of the HFI Working Group."
  },
  {
    "id": "45993729-a502-45f3-b11b-f03d77ce0f3c",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Project Team Leader",
    "content": "The Project Team Leader (PT Leader) shall have prime responsibility for ensuring that HFI is successfully managed in a project, and that satisfactory HFI outcomes are achieved. The PT Leader shall ensure that MOD Staff who undertake HFI management activities are provided with sufficient and suitable information and training to enable them to undertake their responsibilities. The PT Leader shall ensure that the System Requirements Document (SRD) used by the Solution Provider includes sufficient HFSRs (although the development of these HFSRs will normally be the responsibility of the Human Factors Integration Focus (PT))."
  },
  {
    "id": "58458d64-bd88-463f-bf84-fe7ecebb2493",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Human Factors Integration Focus",
    "content": "The HFI Focus is responsible for coordinating HFI activities throughout the life cycle of the project. However, in practice the ‘HFI Focus’ covers two separate roles: HFI Focus within the Front Line Command / Capability (FLC/Cap) community, hereafter referred to as HFI Focus(Cap); and HFI Focus within the DE&S Project Team (PT) or Delivery Team (DT), hereafter referred to as HFI Focus(PT). The HFI Focus(Cap) is responsible for managing the HFI activities during the Pre- Concept and Concept stages of development, with particular emphasis on the FLC activities associated with defining the Human Factors User Requirements (HFURs) for the capability. Consideration should be given to each of the DLODs to identify potential HFI issues and risks associated with the required Capability and the activities that will be required to address them. At this stage of procurement, the HFI Focus(Cap) is unlikely to be an exclusive or full- time role. Where DE&S is involved in the Pre-Concept / Concept Phase, the responsibilities of the HFIF(Cap) may be adopted by the HFI Focus(PT). The HFI Focus(PT) is a member of the PT/DT (nominated by the PT Leader) who has responsibility for the day-to-day management of HFI activities that are carried out by DE&S or by others on DE&S’s behalf. The HFI Focus(PT) is responsible for tailoring the DE&S HFI activities. Production of plans and reports are a costly and time-consuming exercise for all concerned. Over- specifying the requirement will lead to the production of valueless reports rather than the completion of useful analysis. The HFI Focus(PT) must strike a balance between having evidence of sufficient quality of the Solution Provider’s (SP) work, to satisfy assurance and audit trail requirements and giving the Solution Provider the freedom to get on with the job. Where there is insufficient HFI/HFE expertise within the Project Team, the HFI Focus(PT) should request support using the ."
  },
  {
    "id": "2d15e34c-350b-4f0d-80db-7cb95f1fa1d1",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Requirements Management",
    "content": "It is the responsibility of the PT/DT to manage the system requirements and ensure that they are managed across the DLODs. The HFSRs shall be derived from the User Requirements Document (URD) and incorporated within the SRD. Candidate, generic HFSRs are provided in Defence Standard 00-251. Additionally, the  accompanying Def Stan 00-251 provide more detailed, domain-specific technical requirements. These may be tailored to meet specific project requirements."
  },
  {
    "id": "c9fcb534-2dec-43f0-8c01-ad3a4552c8c9",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Capability Sponsor",
    "content": "The Capability Sponsor is responsible for capability at the programme level, leading the overall capability change planning process, and identifying the equipment and support requirements6. The Capability Sponsor operates as the decision-maker (‘Decider’) in providing new equipment and equipment support on behalf of the MOD. In the case of major programmes, the Senior Responsible Owner (SRO) shall ensure that the programme addresses all the relevant Defence Lines of Development (DLOD) on a through-life basis and takes account of issues concerning process and culture or behavioural change."
  },
  {
    "id": "d90a910b-cc38-49c0-8c8f-0d8a6ab6b865",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Capability Integration Working Group",
    "content": "The Capability Integration Working Group (CIWG) shall ensure integration across the DLODs so as to deliver the overall military capability. The CIWG chairperson shall ensure that the Human Components of Capability (i.e. over and above issues emerging under Training, Equipment and Organisation) are adequately captured, defined, analysed and tested. It is recommended that the HFI Focus(Cap) and HFI Focus(PT) are members of the CIWG."
  },
  {
    "id": "7852edee-effa-4710-a098-ffc87d909467",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "HFI Support Function",
    "content": "The DE&S Engineering Group (EG) shall provide HFI information, guidance and support to MOD PTs7. Although DE&S is only responsible for Equipment and Logistics (at the project level), HFI needs to be applied across all the DLODs and through-life. HFI spans the Engineering and Support domains, and as such must be considered from both Engineering and Support perspectives. Therefore, Project and Delivery Teams shall engage the HFI Policy team (Defence Functional Authority for HFI) early and throughout the programme. This will ensure that the capability being developed adequately addresses Core Development Area 2 (CDA2)8, as part of the  (SSE) from a Support perspective and  from an Engineering perspective. Any tailoring of the HFI Process must be agreed with the . The PT (and Cap Branch) shall agree a method to generate a requirements set (HFURs, HFSRs and HFPRs) that addresses the Human Component of Capability, seeking advice and support from the EG HFI team where appropriate. It is essential that this set is generated so as to ensure the successful realisation of the project capability. 6 See Capability Management Practitioners’ Guide (Volume 4: Deliver): 7 There are two teams within EG that are able to provide HFI services – the Internal Technical Support (ITS) Team and the Engineering Services Team, both of which may be approached for guidance and support. 8 CDA 2 (Human Factors Integration) replaced Governing Policy 2.9 (GP2.9 Human Factors Integration) through the SSE betterment programme."
  },
  {
    "id": "e0c03e11-77f7-4f81-b372-57302944202e",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "MOD Staff HFI Competencies",
    "content": "Every member of MOD staff undertaking HFI activities shall be a Suitably Qualified and Experienced Person (SQEP), as defined through reference to the Human Factors Integration Functional Competence Framework [9]. This document provides a detailed description of the functional competencies for HFI. The HFIF(Cap) shall have, as a minimum, the competence of ‘Awareness’, gained through basic training and study of available materials. The target competence for the HFIF(Cap) shall be ‘Practitioner’ level9. The HFIF(PT) shall have, as a minimum, the competence of ‘Practitioner’, and ideally be a Technical or Registered Member of the Chartered Institute of Ergonomics and Human Factors (CIEHF). Where this is not possible, the PT Leader shall appoint or request a SQEP, who holds a minimum of Technical Membership of the CIEHF, to support the HFIF(PT) in this role from the DE&S ITS HFI Team or Engineering Delivery Partner using the Engineering Services - Single Front Door. In addition, as the HFIF(Cap) and HFIF(PT) are HFI ‘management’ roles, awareness and experience of Systems Engineering processes and products is recommended."
  },
  {
    "id": "d9a46aaf-88b5-4636-a9d9-c6c970e4b44c",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Solution Provider HFI Competencies",
    "content": "All HFI activities carried out by a Solution Provider shall be carried out by SQEP, namely professional Ergonomists / Human Factors Engineers, and/or persons with considerable experience of undertaking HFI in a Defence context. Additionally, all Solution Provider HFE personnel should hold or be working towards Registered Membership of the CIEHF10."
  },
  {
    "id": "2c8142a0-26a5-4e3b-bfcf-2388abb2312b",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Research Ethics",
    "content": "The HFI processes conducted across the CADMID or Systems Engineering life cycles (see ) might involve research trials, experiments, tests, surveys or other forms of assessment with human participants. In such cases, the research activities shall comply with JSP 536 [10]."
  },
  {
    "id": "2d7d31d6-a586-41e7-8e58-de80bdd1a2e0",
    "document": "JSP 912 Human Factors Integration in Defence Systems (Part 1 Directive).docx",
    "section": "Conduct and Behaviour",
    "content": "HFI research activities may need to conform to the Code of Human Research Ethics of the British Psychological Society [11] and the Code of Professional Conduct of the CIEHF [12]. In such cases, the involvement of SQEP is essential. 9 A Practitioner should have sufficient knowledge and understanding of good practice, and sufficient demonstrated experience, to be able to work on tasks with only minimal supervision. A Practitioner should maintain their knowledge and be aware of the current developments in the context in which they work. Someone with ‘Awareness’ should demonstrate a holistic understanding of the purpose and aim of the HFI process, sufficient to provide appropriate input, participation and review. 10 It is recognised that the Solution Provider itself, as a company, might not be registered with the CIEHF (i.e. as a ‘Registered Consultancy’). However, the MOD expects that the Solution Provider’s employees will include staff individually registered with the CIEHF."
  }
]